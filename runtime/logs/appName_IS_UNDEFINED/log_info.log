2023-07-20 11:25:32.220 [main] INFO  o.a.f.r.taskexecutor.TaskExecutorResourceUtils - The configuration option taskmanager.cpu.cores required for local execution is not set, setting it to the maximal possible value.
2023-07-20 11:25:32.226 [main] INFO  o.a.f.r.taskexecutor.TaskExecutorResourceUtils - The configuration option taskmanager.memory.task.heap.size required for local execution is not set, setting it to the maximal possible value.
2023-07-20 11:25:32.226 [main] INFO  o.a.f.r.taskexecutor.TaskExecutorResourceUtils - The configuration option taskmanager.memory.task.off-heap.size required for local execution is not set, setting it to the maximal possible value.
2023-07-20 11:25:32.228 [main] INFO  o.a.f.r.taskexecutor.TaskExecutorResourceUtils - The configuration option taskmanager.memory.network.min required for local execution is not set, setting it to its default value 64 mb.
2023-07-20 11:25:32.229 [main] INFO  o.a.f.r.taskexecutor.TaskExecutorResourceUtils - The configuration option taskmanager.memory.network.max required for local execution is not set, setting it to its default value 64 mb.
2023-07-20 11:25:32.229 [main] INFO  o.a.f.r.taskexecutor.TaskExecutorResourceUtils - The configuration option taskmanager.memory.managed.size required for local execution is not set, setting it to its default value 128 mb.
2023-07-20 11:25:32.258 [main] INFO  org.apache.flink.runtime.minicluster.MiniCluster - Starting Flink Mini Cluster
2023-07-20 11:25:32.260 [main] INFO  org.apache.flink.runtime.minicluster.MiniCluster - Starting Metrics Registry
2023-07-20 11:25:32.311 [main] INFO  o.apache.flink.runtime.metrics.MetricRegistryImpl - No metrics reporter configured, no metrics will be exposed/reported.
2023-07-20 11:25:32.311 [main] INFO  org.apache.flink.runtime.minicluster.MiniCluster - Starting RPC Service(s)
2023-07-20 11:25:32.577 [main] INFO  o.a.flink.runtime.rpc.akka.AkkaRpcServiceUtils - Trying to start local actor system
2023-07-20 11:25:32.957 [flink-akka.actor.default-dispatcher-2] INFO  akka.event.slf4j.Slf4jLogger - Slf4jLogger started
2023-07-20 11:25:33.040 [main] INFO  o.a.flink.runtime.rpc.akka.AkkaRpcServiceUtils - Actor system started at akka://flink
2023-07-20 11:25:33.050 [main] INFO  o.a.flink.runtime.rpc.akka.AkkaRpcServiceUtils - Trying to start local actor system
2023-07-20 11:25:33.057 [flink-metrics-2] INFO  akka.event.slf4j.Slf4jLogger - Slf4jLogger started
2023-07-20 11:25:33.085 [main] INFO  o.a.flink.runtime.rpc.akka.AkkaRpcServiceUtils - Actor system started at akka://flink-metrics
2023-07-20 11:25:33.093 [main] INFO  org.apache.flink.runtime.rpc.akka.AkkaRpcService - Starting RPC endpoint for org.apache.flink.runtime.metrics.dump.MetricQueryService at akka://flink-metrics/user/rpc/MetricQueryService .
2023-07-20 11:25:33.141 [main] INFO  org.apache.flink.runtime.minicluster.MiniCluster - Starting high-availability services
2023-07-20 11:25:33.288 [main] INFO  org.apache.flink.runtime.blob.BlobServer - Created BLOB server storage directory C:\Users\DELL\AppData\Local\Temp\blobStore-9a1f7316-86d7-4610-ada4-0ea74cc4d216
2023-07-20 11:25:33.292 [main] INFO  org.apache.flink.runtime.blob.BlobServer - Started BLOB server at 0.0.0.0:64896 - max concurrent requests: 50 - max backlog: 1000
2023-07-20 11:25:33.298 [main] INFO  org.apache.flink.runtime.blob.PermanentBlobCache - Created BLOB cache storage directory C:\Users\DELL\AppData\Local\Temp\blobStore-d0b4e392-5aba-476c-b715-43c32b80374b
2023-07-20 11:25:33.299 [main] INFO  org.apache.flink.runtime.blob.TransientBlobCache - Created BLOB cache storage directory C:\Users\DELL\AppData\Local\Temp\blobStore-996a7961-05ad-4baf-9e8b-4a8ff54d5482
2023-07-20 11:25:33.299 [main] INFO  org.apache.flink.runtime.minicluster.MiniCluster - Starting 1 TaskManger(s)
2023-07-20 11:25:33.302 [main] INFO  o.a.flink.runtime.taskexecutor.TaskManagerRunner - Starting TaskManager with ResourceID: 5596afe2-4430-4de9-aaf9-d2ce4824b53c
2023-07-20 11:25:33.321 [main] INFO  o.a.flink.runtime.taskexecutor.TaskManagerServices - Temporary file directory 'C:\Users\DELL\AppData\Local\Temp': total 237 GB, usable 97 GB (40.93% usable)
2023-07-20 11:25:33.323 [main] INFO  o.a.flink.runtime.io.disk.FileChannelManagerImpl - FileChannelManager uses directory C:\Users\DELL\AppData\Local\Temp\flink-io-3e595dfa-97fb-4723-9d00-552e9a3b2bfc for spill files.
2023-07-20 11:25:33.328 [main] INFO  o.a.flink.runtime.io.disk.FileChannelManagerImpl - FileChannelManager uses directory C:\Users\DELL\AppData\Local\Temp\flink-netty-shuffle-5967d670-c686-44cb-88e7-c1ee40be4959 for spill files.
2023-07-20 11:25:33.352 [main] INFO  o.a.f.runtime.io.network.buffer.NetworkBufferPool - Allocated 64 MB for network buffer pool (number of memory segments: 2048, bytes per segment: 32768).
2023-07-20 11:25:33.363 [main] INFO  o.a.f.runtime.io.network.NettyShuffleEnvironment - Starting the network environment and its components.
2023-07-20 11:25:33.364 [main] INFO  o.apache.flink.runtime.taskexecutor.KvStateService - Starting the kvState service and its components.
2023-07-20 11:25:33.380 [main] INFO  org.apache.flink.runtime.rpc.akka.AkkaRpcService - Starting RPC endpoint for org.apache.flink.runtime.taskexecutor.TaskExecutor at akka://flink/user/rpc/taskmanager_0 .
2023-07-20 11:25:33.388 [flink-akka.actor.default-dispatcher-3] INFO  o.a.f.runtime.taskexecutor.DefaultJobLeaderService - Start job leader service.
2023-07-20 11:25:33.389 [flink-akka.actor.default-dispatcher-3] INFO  org.apache.flink.runtime.filecache.FileCache - User file cache uses directory C:\Users\DELL\AppData\Local\Temp\flink-dist-cache-965353f3-b7a4-440e-ab65-93c6e12a389c
2023-07-20 11:25:33.416 [main] INFO  o.a.f.runtime.dispatcher.DispatcherRestEndpoint - Starting rest endpoint.
2023-07-20 11:25:33.417 [main] INFO  o.a.f.runtime.dispatcher.DispatcherRestEndpoint - Failed to load web based job submission extension. Probable reason: flink-runtime-web is not in the classpath.
2023-07-20 11:25:34.007 [main] INFO  o.a.f.runtime.dispatcher.DispatcherRestEndpoint - Rest endpoint listening at localhost:64947
2023-07-20 11:25:34.008 [main] INFO  o.a.f.r.h.nonha.embedded.EmbeddedLeaderService - Proposing leadership to contender http://localhost:64947
2023-07-20 11:25:34.009 [mini-cluster-io-thread-1] INFO  o.a.f.runtime.dispatcher.DispatcherRestEndpoint - http://localhost:64947 was granted leadership with leaderSessionID=4a68afe5-d178-404e-aa08-23d363d09a63
2023-07-20 11:25:34.009 [mini-cluster-io-thread-1] INFO  o.a.f.r.h.nonha.embedded.EmbeddedLeaderService - Received confirmation of leadership for leader http://localhost:64947 , session=4a68afe5-d178-404e-aa08-23d363d09a63
2023-07-20 11:25:34.019 [main] INFO  org.apache.flink.runtime.rpc.akka.AkkaRpcService - Starting RPC endpoint for org.apache.flink.runtime.resourcemanager.StandaloneResourceManager at akka://flink/user/rpc/resourcemanager_1 .
2023-07-20 11:25:34.029 [main] INFO  o.a.f.r.h.nonha.embedded.EmbeddedLeaderService - Proposing leadership to contender LeaderContender: DefaultDispatcherRunner
2023-07-20 11:25:34.029 [flink-akka.actor.default-dispatcher-3] INFO  o.a.f.r.h.nonha.embedded.EmbeddedLeaderService - Proposing leadership to contender LeaderContender: StandaloneResourceManager
2023-07-20 11:25:34.030 [flink-akka.actor.default-dispatcher-3] INFO  o.a.f.r.resourcemanager.StandaloneResourceManager - ResourceManager akka://flink/user/rpc/resourcemanager_1 was granted leadership with fencing token a0d72fb6d19cdd053d10c1fc36aa43d9
2023-07-20 11:25:34.032 [main] INFO  org.apache.flink.runtime.minicluster.MiniCluster - Flink Mini Cluster started successfully
2023-07-20 11:25:34.032 [flink-akka.actor.default-dispatcher-3] INFO  o.a.f.r.r.slotmanager.SlotManagerImpl - Starting the SlotManager.
2023-07-20 11:25:34.033 [mini-cluster-io-thread-2] INFO  o.a.f.r.d.runner.SessionDispatcherLeaderProcess - Start SessionDispatcherLeaderProcess.
2023-07-20 11:25:34.034 [mini-cluster-io-thread-5] INFO  o.a.f.r.d.runner.SessionDispatcherLeaderProcess - Recover all persisted job graphs.
2023-07-20 11:25:34.034 [mini-cluster-io-thread-5] INFO  o.a.f.r.d.runner.SessionDispatcherLeaderProcess - Successfully recovered 0 persisted job graphs.
2023-07-20 11:25:34.035 [mini-cluster-io-thread-6] INFO  o.a.f.r.h.nonha.embedded.EmbeddedLeaderService - Received confirmation of leadership for leader akka://flink/user/rpc/resourcemanager_1 , session=3d10c1fc-36aa-43d9-a0d7-2fb6d19cdd05
2023-07-20 11:25:34.037 [flink-akka.actor.default-dispatcher-3] INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor - Connecting to ResourceManager akka://flink/user/rpc/resourcemanager_1(a0d72fb6d19cdd053d10c1fc36aa43d9).
2023-07-20 11:25:34.040 [mini-cluster-io-thread-5] INFO  org.apache.flink.runtime.rpc.akka.AkkaRpcService - Starting RPC endpoint for org.apache.flink.runtime.dispatcher.StandaloneDispatcher at akka://flink/user/rpc/dispatcher_2 .
2023-07-20 11:25:34.045 [mini-cluster-io-thread-5] INFO  o.a.f.r.h.nonha.embedded.EmbeddedLeaderService - Received confirmation of leadership for leader akka://flink/user/rpc/dispatcher_2 , session=5c6b6a43-c486-4f77-8d42-157a4e934673
2023-07-20 11:25:34.049 [flink-akka.actor.default-dispatcher-2] INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor - Resolved ResourceManager address, beginning registration
2023-07-20 11:25:34.054 [flink-akka.actor.default-dispatcher-4] INFO  o.a.f.r.resourcemanager.StandaloneResourceManager - Registering TaskManager with ResourceID 5596afe2-4430-4de9-aaf9-d2ce4824b53c (akka://flink/user/rpc/taskmanager_0) at ResourceManager
2023-07-20 11:25:34.055 [flink-akka.actor.default-dispatcher-4] INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor - Successful registration at resource manager akka://flink/user/rpc/resourcemanager_1 under registration id a55ab97fe55052bde344d73934601142.
2023-07-20 11:25:34.057 [flink-akka.actor.default-dispatcher-3] INFO  o.a.flink.runtime.dispatcher.StandaloneDispatcher - Received JobGraph submission 3391af44eb5fc6d426c4166bcc89d020 (kafka-flink-start).
2023-07-20 11:25:34.057 [flink-akka.actor.default-dispatcher-3] INFO  o.a.flink.runtime.dispatcher.StandaloneDispatcher - Submitting job 3391af44eb5fc6d426c4166bcc89d020 (kafka-flink-start).
2023-07-20 11:25:34.068 [mini-cluster-io-thread-12] INFO  o.a.f.r.h.nonha.embedded.EmbeddedLeaderService - Proposing leadership to contender LeaderContender: JobManagerRunnerImpl
2023-07-20 11:25:34.073 [mini-cluster-io-thread-12] INFO  org.apache.flink.runtime.rpc.akka.AkkaRpcService - Starting RPC endpoint for org.apache.flink.runtime.jobmaster.JobMaster at akka://flink/user/rpc/jobmanager_3 .
2023-07-20 11:25:34.078 [mini-cluster-io-thread-12] INFO  org.apache.flink.runtime.jobmaster.JobMaster - Initializing job kafka-flink-start (3391af44eb5fc6d426c4166bcc89d020).
2023-07-20 11:25:34.089 [mini-cluster-io-thread-12] INFO  org.apache.flink.runtime.jobmaster.JobMaster - Using restart back off time strategy NoRestartBackoffTimeStrategy for kafka-flink-start (3391af44eb5fc6d426c4166bcc89d020).
2023-07-20 11:25:34.117 [mini-cluster-io-thread-12] INFO  org.apache.flink.runtime.jobmaster.JobMaster - Running initialization on master for job kafka-flink-start (3391af44eb5fc6d426c4166bcc89d020).
2023-07-20 11:25:34.117 [mini-cluster-io-thread-12] INFO  org.apache.flink.runtime.jobmaster.JobMaster - Successfully ran initialization on master in 0 ms.
2023-07-20 11:25:34.127 [mini-cluster-io-thread-12] INFO  o.a.f.r.scheduler.adapter.DefaultExecutionTopology - Built 12 pipelined regions in 0 ms
2023-07-20 11:25:34.136 [mini-cluster-io-thread-12] INFO  org.apache.flink.runtime.jobmaster.JobMaster - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2023-07-20 11:25:34.143 [mini-cluster-io-thread-12] INFO  o.a.flink.runtime.checkpoint.CheckpointCoordinator - No checkpoint found during restore.
2023-07-20 11:25:34.145 [mini-cluster-io-thread-12] INFO  org.apache.flink.runtime.jobmaster.JobMaster - Using failover strategy org.apache.flink.runtime.executiongraph.failover.flip1.RestartPipelinedRegionFailoverStrategy@7541b223 for kafka-flink-start (3391af44eb5fc6d426c4166bcc89d020).
2023-07-20 11:25:34.151 [mini-cluster-io-thread-12] INFO  o.a.flink.runtime.jobmaster.JobManagerRunnerImpl - JobManager runner for job kafka-flink-start (3391af44eb5fc6d426c4166bcc89d020) was granted leadership with session id 77476c9b-f45d-4c5a-bbe9-459b39110f69 at akka://flink/user/rpc/jobmanager_3.
2023-07-20 11:25:34.152 [flink-akka.actor.default-dispatcher-4] INFO  org.apache.flink.runtime.jobmaster.JobMaster - Starting execution of job kafka-flink-start (3391af44eb5fc6d426c4166bcc89d020) under job master id bbe9459b39110f6977476c9bf45d4c5a.
2023-07-20 11:25:34.153 [flink-akka.actor.default-dispatcher-4] INFO  org.apache.flink.runtime.jobmaster.JobMaster - Starting scheduling with scheduling strategy [org.apache.flink.runtime.scheduler.strategy.PipelinedRegionSchedulingStrategy]
2023-07-20 11:25:34.153 [flink-akka.actor.default-dispatcher-4] INFO  o.a.flink.runtime.executiongraph.ExecutionGraph - Job kafka-flink-start (3391af44eb5fc6d426c4166bcc89d020) switched from state CREATED to RUNNING.
2023-07-20 11:25:34.157 [flink-akka.actor.default-dispatcher-4] INFO  o.a.flink.runtime.executiongraph.ExecutionGraph - Source: Custom Source -> Map -> Sink: Print to Std. Out (1/12) (06b46774af4e2cd402280bd56b2859c8) switched from CREATED to SCHEDULED.
2023-07-20 11:25:34.164 [flink-akka.actor.default-dispatcher-4] INFO  o.a.flink.runtime.jobmaster.slotpool.SlotPoolImpl - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{9ab1cbd3b095f46f417f8a39da6f4386}]
2023-07-20 11:25:34.169 [flink-akka.actor.default-dispatcher-4] INFO  o.a.flink.runtime.executiongraph.ExecutionGraph - Source: Custom Source -> Map -> Sink: Print to Std. Out (2/12) (58809d64463bd3d3cb7eccafa2d5146b) switched from CREATED to SCHEDULED.
2023-07-20 11:25:34.170 [flink-akka.actor.default-dispatcher-4] INFO  o.a.flink.runtime.jobmaster.slotpool.SlotPoolImpl - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{6ca62c15bffa4007fc9d89dc1e3f431a}]
2023-07-20 11:25:34.170 [flink-akka.actor.default-dispatcher-4] INFO  o.a.flink.runtime.executiongraph.ExecutionGraph - Source: Custom Source -> Map -> Sink: Print to Std. Out (3/12) (e13c6c371665bbeac4ef411df29cb612) switched from CREATED to SCHEDULED.
2023-07-20 11:25:34.170 [flink-akka.actor.default-dispatcher-4] INFO  o.a.flink.runtime.jobmaster.slotpool.SlotPoolImpl - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{61c1e4864b5c79b1ba42d93f5af576bc}]
2023-07-20 11:25:34.170 [flink-akka.actor.default-dispatcher-4] INFO  o.a.flink.runtime.executiongraph.ExecutionGraph - Source: Custom Source -> Map -> Sink: Print to Std. Out (4/12) (d153777326e67cbb2a9c2a3ac7af29ab) switched from CREATED to SCHEDULED.
2023-07-20 11:25:34.170 [flink-akka.actor.default-dispatcher-4] INFO  o.a.flink.runtime.jobmaster.slotpool.SlotPoolImpl - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{fa8fd51bf681513ec81110cf72983610}]
2023-07-20 11:25:34.170 [flink-akka.actor.default-dispatcher-4] INFO  o.a.flink.runtime.executiongraph.ExecutionGraph - Source: Custom Source -> Map -> Sink: Print to Std. Out (5/12) (0f878fa4791a43e60fdb14074e3701f9) switched from CREATED to SCHEDULED.
2023-07-20 11:25:34.170 [flink-akka.actor.default-dispatcher-4] INFO  o.a.flink.runtime.jobmaster.slotpool.SlotPoolImpl - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{23f437d641c86237f353dc9fc36d8d8e}]
2023-07-20 11:25:34.170 [flink-akka.actor.default-dispatcher-4] INFO  o.a.flink.runtime.executiongraph.ExecutionGraph - Source: Custom Source -> Map -> Sink: Print to Std. Out (6/12) (ec3492a40eb26a07764df9451eb319aa) switched from CREATED to SCHEDULED.
2023-07-20 11:25:34.171 [flink-akka.actor.default-dispatcher-4] INFO  o.a.flink.runtime.jobmaster.slotpool.SlotPoolImpl - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{bfd45d3532f27654d32a4ce80fe58500}]
2023-07-20 11:25:34.171 [flink-akka.actor.default-dispatcher-4] INFO  o.a.flink.runtime.executiongraph.ExecutionGraph - Source: Custom Source -> Map -> Sink: Print to Std. Out (7/12) (60bb8c1c9b38e2e28198c1a4d2c1a0a8) switched from CREATED to SCHEDULED.
2023-07-20 11:25:34.171 [flink-akka.actor.default-dispatcher-4] INFO  o.a.flink.runtime.jobmaster.slotpool.SlotPoolImpl - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{2f4978bd567d98062359b67f9616b608}]
2023-07-20 11:25:34.171 [flink-akka.actor.default-dispatcher-4] INFO  o.a.flink.runtime.executiongraph.ExecutionGraph - Source: Custom Source -> Map -> Sink: Print to Std. Out (8/12) (f960da4a895dfcddaa6dfe2396fe2aaf) switched from CREATED to SCHEDULED.
2023-07-20 11:25:34.171 [flink-akka.actor.default-dispatcher-4] INFO  o.a.flink.runtime.jobmaster.slotpool.SlotPoolImpl - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{beb07d784880f4ee656c2366b8c73297}]
2023-07-20 11:25:34.172 [flink-akka.actor.default-dispatcher-4] INFO  o.a.flink.runtime.executiongraph.ExecutionGraph - Source: Custom Source -> Map -> Sink: Print to Std. Out (9/12) (3a615b06031e23aeb98087b28f99931f) switched from CREATED to SCHEDULED.
2023-07-20 11:25:34.172 [flink-akka.actor.default-dispatcher-4] INFO  o.a.flink.runtime.jobmaster.slotpool.SlotPoolImpl - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{cc290a74273290644ffc533f213bbb77}]
2023-07-20 11:25:34.172 [flink-akka.actor.default-dispatcher-4] INFO  o.a.flink.runtime.executiongraph.ExecutionGraph - Source: Custom Source -> Map -> Sink: Print to Std. Out (10/12) (cabee4fea2749a549b9de415986bca12) switched from CREATED to SCHEDULED.
2023-07-20 11:25:34.172 [flink-akka.actor.default-dispatcher-4] INFO  o.a.flink.runtime.jobmaster.slotpool.SlotPoolImpl - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{4155673fac80c5f1ee514bce2e4746c3}]
2023-07-20 11:25:34.172 [flink-akka.actor.default-dispatcher-4] INFO  o.a.flink.runtime.executiongraph.ExecutionGraph - Source: Custom Source -> Map -> Sink: Print to Std. Out (11/12) (a0849148e22b604a960f950f2cacdeb1) switched from CREATED to SCHEDULED.
2023-07-20 11:25:34.172 [flink-akka.actor.default-dispatcher-4] INFO  o.a.flink.runtime.jobmaster.slotpool.SlotPoolImpl - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{816d90732f699bd5b4ab797eda54d66a}]
2023-07-20 11:25:34.173 [flink-akka.actor.default-dispatcher-4] INFO  o.a.flink.runtime.executiongraph.ExecutionGraph - Source: Custom Source -> Map -> Sink: Print to Std. Out (12/12) (4747991b52a7b5fa339fb5bb4783dac3) switched from CREATED to SCHEDULED.
2023-07-20 11:25:34.173 [flink-akka.actor.default-dispatcher-4] INFO  o.a.flink.runtime.jobmaster.slotpool.SlotPoolImpl - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{3cf7542578f9e58237e55fddff659eaf}]
2023-07-20 11:25:34.173 [jobmanager-future-thread-1] INFO  o.a.f.r.h.nonha.embedded.EmbeddedLeaderService - Received confirmation of leadership for leader akka://flink/user/rpc/jobmanager_3 , session=77476c9b-f45d-4c5a-bbe9-459b39110f69
2023-07-20 11:25:34.173 [flink-akka.actor.default-dispatcher-4] INFO  org.apache.flink.runtime.jobmaster.JobMaster - Connecting to ResourceManager akka://flink/user/rpc/resourcemanager_1(a0d72fb6d19cdd053d10c1fc36aa43d9)
2023-07-20 11:25:34.174 [flink-akka.actor.default-dispatcher-6] INFO  org.apache.flink.runtime.jobmaster.JobMaster - Resolved ResourceManager address, beginning registration
2023-07-20 11:25:34.175 [flink-akka.actor.default-dispatcher-6] INFO  o.a.f.r.resourcemanager.StandaloneResourceManager - Registering job manager bbe9459b39110f6977476c9bf45d4c5a@akka://flink/user/rpc/jobmanager_3 for job 3391af44eb5fc6d426c4166bcc89d020.
2023-07-20 11:25:34.178 [flink-akka.actor.default-dispatcher-6] INFO  o.a.f.r.resourcemanager.StandaloneResourceManager - Registered job manager bbe9459b39110f6977476c9bf45d4c5a@akka://flink/user/rpc/jobmanager_3 for job 3391af44eb5fc6d426c4166bcc89d020.
2023-07-20 11:25:34.179 [flink-akka.actor.default-dispatcher-2] INFO  org.apache.flink.runtime.jobmaster.JobMaster - JobManager successfully registered at ResourceManager, leader id: a0d72fb6d19cdd053d10c1fc36aa43d9.
2023-07-20 11:25:34.180 [flink-akka.actor.default-dispatcher-2] INFO  o.a.flink.runtime.jobmaster.slotpool.SlotPoolImpl - Requesting new slot [SlotRequestId{9ab1cbd3b095f46f417f8a39da6f4386}] and profile ResourceProfile{UNKNOWN} with allocation id b4b57e742c1e361ea949da20053d7cab from resource manager.
2023-07-20 11:25:34.181 [flink-akka.actor.default-dispatcher-6] INFO  o.a.f.r.resourcemanager.StandaloneResourceManager - Request slot with profile ResourceProfile{UNKNOWN} for job 3391af44eb5fc6d426c4166bcc89d020 with allocation id b4b57e742c1e361ea949da20053d7cab.
2023-07-20 11:25:34.181 [flink-akka.actor.default-dispatcher-2] INFO  o.a.flink.runtime.jobmaster.slotpool.SlotPoolImpl - Requesting new slot [SlotRequestId{6ca62c15bffa4007fc9d89dc1e3f431a}] and profile ResourceProfile{UNKNOWN} with allocation id ad03fde429c12587f66027072531f485 from resource manager.
2023-07-20 11:25:34.181 [flink-akka.actor.default-dispatcher-2] INFO  o.a.flink.runtime.jobmaster.slotpool.SlotPoolImpl - Requesting new slot [SlotRequestId{61c1e4864b5c79b1ba42d93f5af576bc}] and profile ResourceProfile{UNKNOWN} with allocation id d5a016017aafa305b1c1eb979337bcca from resource manager.
2023-07-20 11:25:34.181 [flink-akka.actor.default-dispatcher-2] INFO  o.a.flink.runtime.jobmaster.slotpool.SlotPoolImpl - Requesting new slot [SlotRequestId{fa8fd51bf681513ec81110cf72983610}] and profile ResourceProfile{UNKNOWN} with allocation id f3bfc3cfad8248254a6fa8d99820cc9e from resource manager.
2023-07-20 11:25:34.181 [flink-akka.actor.default-dispatcher-2] INFO  o.a.flink.runtime.jobmaster.slotpool.SlotPoolImpl - Requesting new slot [SlotRequestId{23f437d641c86237f353dc9fc36d8d8e}] and profile ResourceProfile{UNKNOWN} with allocation id 3ff7a87005665645c9bc2042d47e314a from resource manager.
2023-07-20 11:25:34.181 [flink-akka.actor.default-dispatcher-2] INFO  o.a.flink.runtime.jobmaster.slotpool.SlotPoolImpl - Requesting new slot [SlotRequestId{bfd45d3532f27654d32a4ce80fe58500}] and profile ResourceProfile{UNKNOWN} with allocation id f4f54a5ab8be988eedbdc0a084f04350 from resource manager.
2023-07-20 11:25:34.182 [flink-akka.actor.default-dispatcher-2] INFO  o.a.flink.runtime.jobmaster.slotpool.SlotPoolImpl - Requesting new slot [SlotRequestId{2f4978bd567d98062359b67f9616b608}] and profile ResourceProfile{UNKNOWN} with allocation id bbc5a6ec0f9bf121b56f7d3d3a9c98bf from resource manager.
2023-07-20 11:25:34.182 [flink-akka.actor.default-dispatcher-2] INFO  o.a.flink.runtime.jobmaster.slotpool.SlotPoolImpl - Requesting new slot [SlotRequestId{beb07d784880f4ee656c2366b8c73297}] and profile ResourceProfile{UNKNOWN} with allocation id 6b34d81f9715059094e5733c926048c9 from resource manager.
2023-07-20 11:25:34.182 [flink-akka.actor.default-dispatcher-2] INFO  o.a.flink.runtime.jobmaster.slotpool.SlotPoolImpl - Requesting new slot [SlotRequestId{cc290a74273290644ffc533f213bbb77}] and profile ResourceProfile{UNKNOWN} with allocation id d55bd29fa307be8f5f5c014a6faa5492 from resource manager.
2023-07-20 11:25:34.182 [flink-akka.actor.default-dispatcher-2] INFO  o.a.flink.runtime.jobmaster.slotpool.SlotPoolImpl - Requesting new slot [SlotRequestId{4155673fac80c5f1ee514bce2e4746c3}] and profile ResourceProfile{UNKNOWN} with allocation id 8c3d7ffe59468eeab82e35718253494a from resource manager.
2023-07-20 11:25:34.182 [flink-akka.actor.default-dispatcher-2] INFO  o.a.flink.runtime.jobmaster.slotpool.SlotPoolImpl - Requesting new slot [SlotRequestId{816d90732f699bd5b4ab797eda54d66a}] and profile ResourceProfile{UNKNOWN} with allocation id 5ca4b93edadeb5bae52ab54e56846f7d from resource manager.
2023-07-20 11:25:34.183 [flink-akka.actor.default-dispatcher-4] INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor - Receive slot request b4b57e742c1e361ea949da20053d7cab for job 3391af44eb5fc6d426c4166bcc89d020 from resource manager with leader id a0d72fb6d19cdd053d10c1fc36aa43d9.
2023-07-20 11:25:34.183 [flink-akka.actor.default-dispatcher-2] INFO  o.a.flink.runtime.jobmaster.slotpool.SlotPoolImpl - Requesting new slot [SlotRequestId{3cf7542578f9e58237e55fddff659eaf}] and profile ResourceProfile{UNKNOWN} with allocation id 4188e598a143efd3ea8c84675c121ba9 from resource manager.
2023-07-20 11:25:34.183 [flink-akka.actor.default-dispatcher-6] INFO  o.a.f.r.resourcemanager.StandaloneResourceManager - Request slot with profile ResourceProfile{UNKNOWN} for job 3391af44eb5fc6d426c4166bcc89d020 with allocation id ad03fde429c12587f66027072531f485.
2023-07-20 11:25:34.183 [flink-akka.actor.default-dispatcher-6] INFO  o.a.f.r.resourcemanager.StandaloneResourceManager - Request slot with profile ResourceProfile{UNKNOWN} for job 3391af44eb5fc6d426c4166bcc89d020 with allocation id d5a016017aafa305b1c1eb979337bcca.
2023-07-20 11:25:34.184 [flink-akka.actor.default-dispatcher-6] INFO  o.a.f.r.resourcemanager.StandaloneResourceManager - Request slot with profile ResourceProfile{UNKNOWN} for job 3391af44eb5fc6d426c4166bcc89d020 with allocation id f3bfc3cfad8248254a6fa8d99820cc9e.
2023-07-20 11:25:34.184 [flink-akka.actor.default-dispatcher-6] INFO  o.a.f.r.resourcemanager.StandaloneResourceManager - Request slot with profile ResourceProfile{UNKNOWN} for job 3391af44eb5fc6d426c4166bcc89d020 with allocation id 3ff7a87005665645c9bc2042d47e314a.
2023-07-20 11:25:34.184 [flink-akka.actor.default-dispatcher-6] INFO  o.a.f.r.resourcemanager.StandaloneResourceManager - Request slot with profile ResourceProfile{UNKNOWN} for job 3391af44eb5fc6d426c4166bcc89d020 with allocation id f4f54a5ab8be988eedbdc0a084f04350.
2023-07-20 11:25:34.184 [flink-akka.actor.default-dispatcher-6] INFO  o.a.f.r.resourcemanager.StandaloneResourceManager - Request slot with profile ResourceProfile{UNKNOWN} for job 3391af44eb5fc6d426c4166bcc89d020 with allocation id bbc5a6ec0f9bf121b56f7d3d3a9c98bf.
2023-07-20 11:25:34.185 [flink-akka.actor.default-dispatcher-6] INFO  o.a.f.r.resourcemanager.StandaloneResourceManager - Request slot with profile ResourceProfile{UNKNOWN} for job 3391af44eb5fc6d426c4166bcc89d020 with allocation id 6b34d81f9715059094e5733c926048c9.
2023-07-20 11:25:34.185 [flink-akka.actor.default-dispatcher-6] INFO  o.a.f.r.resourcemanager.StandaloneResourceManager - Request slot with profile ResourceProfile{UNKNOWN} for job 3391af44eb5fc6d426c4166bcc89d020 with allocation id d55bd29fa307be8f5f5c014a6faa5492.
2023-07-20 11:25:34.185 [flink-akka.actor.default-dispatcher-6] INFO  o.a.f.r.resourcemanager.StandaloneResourceManager - Request slot with profile ResourceProfile{UNKNOWN} for job 3391af44eb5fc6d426c4166bcc89d020 with allocation id 8c3d7ffe59468eeab82e35718253494a.
2023-07-20 11:25:34.186 [flink-akka.actor.default-dispatcher-6] INFO  o.a.f.r.resourcemanager.StandaloneResourceManager - Request slot with profile ResourceProfile{UNKNOWN} for job 3391af44eb5fc6d426c4166bcc89d020 with allocation id 5ca4b93edadeb5bae52ab54e56846f7d.
2023-07-20 11:25:34.186 [flink-akka.actor.default-dispatcher-6] INFO  o.a.f.r.resourcemanager.StandaloneResourceManager - Request slot with profile ResourceProfile{UNKNOWN} for job 3391af44eb5fc6d426c4166bcc89d020 with allocation id 4188e598a143efd3ea8c84675c121ba9.
2023-07-20 11:25:34.186 [flink-akka.actor.default-dispatcher-4] INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor - Allocated slot for b4b57e742c1e361ea949da20053d7cab.
2023-07-20 11:25:34.187 [flink-akka.actor.default-dispatcher-4] INFO  o.a.f.runtime.taskexecutor.DefaultJobLeaderService - Add job 3391af44eb5fc6d426c4166bcc89d020 for job leader monitoring.
2023-07-20 11:25:34.189 [mini-cluster-io-thread-18] INFO  o.a.f.runtime.taskexecutor.DefaultJobLeaderService - Try to register at job manager akka://flink/user/rpc/jobmanager_3 with leader id 77476c9b-f45d-4c5a-bbe9-459b39110f69.
2023-07-20 11:25:34.189 [flink-akka.actor.default-dispatcher-4] INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor - Receive slot request ad03fde429c12587f66027072531f485 for job 3391af44eb5fc6d426c4166bcc89d020 from resource manager with leader id a0d72fb6d19cdd053d10c1fc36aa43d9.
2023-07-20 11:25:34.189 [flink-akka.actor.default-dispatcher-4] INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor - Allocated slot for ad03fde429c12587f66027072531f485.
2023-07-20 11:25:34.189 [flink-akka.actor.default-dispatcher-4] INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor - Receive slot request d5a016017aafa305b1c1eb979337bcca for job 3391af44eb5fc6d426c4166bcc89d020 from resource manager with leader id a0d72fb6d19cdd053d10c1fc36aa43d9.
2023-07-20 11:25:34.189 [flink-akka.actor.default-dispatcher-4] INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor - Allocated slot for d5a016017aafa305b1c1eb979337bcca.
2023-07-20 11:25:34.189 [flink-akka.actor.default-dispatcher-3] INFO  o.a.f.runtime.taskexecutor.DefaultJobLeaderService - Resolved JobManager address, beginning registration
2023-07-20 11:25:34.189 [flink-akka.actor.default-dispatcher-4] INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor - Receive slot request f3bfc3cfad8248254a6fa8d99820cc9e for job 3391af44eb5fc6d426c4166bcc89d020 from resource manager with leader id a0d72fb6d19cdd053d10c1fc36aa43d9.
2023-07-20 11:25:34.190 [flink-akka.actor.default-dispatcher-4] INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor - Allocated slot for f3bfc3cfad8248254a6fa8d99820cc9e.
2023-07-20 11:25:34.190 [flink-akka.actor.default-dispatcher-4] INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor - Receive slot request 3ff7a87005665645c9bc2042d47e314a for job 3391af44eb5fc6d426c4166bcc89d020 from resource manager with leader id a0d72fb6d19cdd053d10c1fc36aa43d9.
2023-07-20 11:25:34.190 [flink-akka.actor.default-dispatcher-4] INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor - Allocated slot for 3ff7a87005665645c9bc2042d47e314a.
2023-07-20 11:25:34.190 [flink-akka.actor.default-dispatcher-4] INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor - Receive slot request f4f54a5ab8be988eedbdc0a084f04350 for job 3391af44eb5fc6d426c4166bcc89d020 from resource manager with leader id a0d72fb6d19cdd053d10c1fc36aa43d9.
2023-07-20 11:25:34.191 [flink-akka.actor.default-dispatcher-4] INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor - Allocated slot for f4f54a5ab8be988eedbdc0a084f04350.
2023-07-20 11:25:34.191 [flink-akka.actor.default-dispatcher-4] INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor - Receive slot request bbc5a6ec0f9bf121b56f7d3d3a9c98bf for job 3391af44eb5fc6d426c4166bcc89d020 from resource manager with leader id a0d72fb6d19cdd053d10c1fc36aa43d9.
2023-07-20 11:25:34.191 [flink-akka.actor.default-dispatcher-4] INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor - Allocated slot for bbc5a6ec0f9bf121b56f7d3d3a9c98bf.
2023-07-20 11:25:34.191 [flink-akka.actor.default-dispatcher-4] INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor - Receive slot request 6b34d81f9715059094e5733c926048c9 for job 3391af44eb5fc6d426c4166bcc89d020 from resource manager with leader id a0d72fb6d19cdd053d10c1fc36aa43d9.
2023-07-20 11:25:34.191 [flink-akka.actor.default-dispatcher-4] INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor - Allocated slot for 6b34d81f9715059094e5733c926048c9.
2023-07-20 11:25:34.192 [flink-akka.actor.default-dispatcher-4] INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor - Receive slot request d55bd29fa307be8f5f5c014a6faa5492 for job 3391af44eb5fc6d426c4166bcc89d020 from resource manager with leader id a0d72fb6d19cdd053d10c1fc36aa43d9.
2023-07-20 11:25:34.192 [flink-akka.actor.default-dispatcher-4] INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor - Allocated slot for d55bd29fa307be8f5f5c014a6faa5492.
2023-07-20 11:25:34.192 [flink-akka.actor.default-dispatcher-4] INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor - Receive slot request 8c3d7ffe59468eeab82e35718253494a for job 3391af44eb5fc6d426c4166bcc89d020 from resource manager with leader id a0d72fb6d19cdd053d10c1fc36aa43d9.
2023-07-20 11:25:34.192 [flink-akka.actor.default-dispatcher-4] INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor - Allocated slot for 8c3d7ffe59468eeab82e35718253494a.
2023-07-20 11:25:34.192 [flink-akka.actor.default-dispatcher-4] INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor - Receive slot request 5ca4b93edadeb5bae52ab54e56846f7d for job 3391af44eb5fc6d426c4166bcc89d020 from resource manager with leader id a0d72fb6d19cdd053d10c1fc36aa43d9.
2023-07-20 11:25:34.192 [flink-akka.actor.default-dispatcher-4] INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor - Allocated slot for 5ca4b93edadeb5bae52ab54e56846f7d.
2023-07-20 11:25:34.193 [flink-akka.actor.default-dispatcher-4] INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor - Receive slot request 4188e598a143efd3ea8c84675c121ba9 for job 3391af44eb5fc6d426c4166bcc89d020 from resource manager with leader id a0d72fb6d19cdd053d10c1fc36aa43d9.
2023-07-20 11:25:34.193 [flink-akka.actor.default-dispatcher-4] INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor - Allocated slot for 4188e598a143efd3ea8c84675c121ba9.
2023-07-20 11:25:34.193 [flink-akka.actor.default-dispatcher-2] INFO  o.a.f.runtime.taskexecutor.DefaultJobLeaderService - Successful registration at job manager akka://flink/user/rpc/jobmanager_3 for job 3391af44eb5fc6d426c4166bcc89d020.
2023-07-20 11:25:34.194 [flink-akka.actor.default-dispatcher-2] INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor - Establish JobManager connection for job 3391af44eb5fc6d426c4166bcc89d020.
2023-07-20 11:25:34.196 [flink-akka.actor.default-dispatcher-2] INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor - Offer reserved slots to the leader of job 3391af44eb5fc6d426c4166bcc89d020.
2023-07-20 11:25:34.200 [flink-akka.actor.default-dispatcher-4] INFO  o.a.flink.runtime.executiongraph.ExecutionGraph - Source: Custom Source -> Map -> Sink: Print to Std. Out (1/12) (06b46774af4e2cd402280bd56b2859c8) switched from SCHEDULED to DEPLOYING.
2023-07-20 11:25:34.200 [flink-akka.actor.default-dispatcher-4] INFO  o.a.flink.runtime.executiongraph.ExecutionGraph - Deploying Source: Custom Source -> Map -> Sink: Print to Std. Out (1/12) (attempt #0) with attempt id 06b46774af4e2cd402280bd56b2859c8 to 5596afe2-4430-4de9-aaf9-d2ce4824b53c @ activate.navicat.com (dataPort=-1) with allocation id d5a016017aafa305b1c1eb979337bcca
2023-07-20 11:25:34.204 [flink-akka.actor.default-dispatcher-4] INFO  o.a.flink.runtime.executiongraph.ExecutionGraph - Source: Custom Source -> Map -> Sink: Print to Std. Out (2/12) (58809d64463bd3d3cb7eccafa2d5146b) switched from SCHEDULED to DEPLOYING.
2023-07-20 11:25:34.204 [flink-akka.actor.default-dispatcher-4] INFO  o.a.flink.runtime.executiongraph.ExecutionGraph - Deploying Source: Custom Source -> Map -> Sink: Print to Std. Out (2/12) (attempt #0) with attempt id 58809d64463bd3d3cb7eccafa2d5146b to 5596afe2-4430-4de9-aaf9-d2ce4824b53c @ activate.navicat.com (dataPort=-1) with allocation id 4188e598a143efd3ea8c84675c121ba9
2023-07-20 11:25:34.204 [flink-akka.actor.default-dispatcher-2] INFO  o.a.f.runtime.taskexecutor.slot.TaskSlotTableImpl - Activate slot d5a016017aafa305b1c1eb979337bcca.
2023-07-20 11:25:34.204 [flink-akka.actor.default-dispatcher-4] INFO  o.a.flink.runtime.executiongraph.ExecutionGraph - Source: Custom Source -> Map -> Sink: Print to Std. Out (3/12) (e13c6c371665bbeac4ef411df29cb612) switched from SCHEDULED to DEPLOYING.
2023-07-20 11:25:34.204 [flink-akka.actor.default-dispatcher-4] INFO  o.a.flink.runtime.executiongraph.ExecutionGraph - Deploying Source: Custom Source -> Map -> Sink: Print to Std. Out (3/12) (attempt #0) with attempt id e13c6c371665bbeac4ef411df29cb612 to 5596afe2-4430-4de9-aaf9-d2ce4824b53c @ activate.navicat.com (dataPort=-1) with allocation id ad03fde429c12587f66027072531f485
2023-07-20 11:25:34.204 [flink-akka.actor.default-dispatcher-4] INFO  o.a.flink.runtime.executiongraph.ExecutionGraph - Source: Custom Source -> Map -> Sink: Print to Std. Out (4/12) (d153777326e67cbb2a9c2a3ac7af29ab) switched from SCHEDULED to DEPLOYING.
2023-07-20 11:25:34.205 [flink-akka.actor.default-dispatcher-4] INFO  o.a.flink.runtime.executiongraph.ExecutionGraph - Deploying Source: Custom Source -> Map -> Sink: Print to Std. Out (4/12) (attempt #0) with attempt id d153777326e67cbb2a9c2a3ac7af29ab to 5596afe2-4430-4de9-aaf9-d2ce4824b53c @ activate.navicat.com (dataPort=-1) with allocation id f4f54a5ab8be988eedbdc0a084f04350
2023-07-20 11:25:34.205 [flink-akka.actor.default-dispatcher-4] INFO  o.a.flink.runtime.executiongraph.ExecutionGraph - Source: Custom Source -> Map -> Sink: Print to Std. Out (5/12) (0f878fa4791a43e60fdb14074e3701f9) switched from SCHEDULED to DEPLOYING.
2023-07-20 11:25:34.205 [flink-akka.actor.default-dispatcher-4] INFO  o.a.flink.runtime.executiongraph.ExecutionGraph - Deploying Source: Custom Source -> Map -> Sink: Print to Std. Out (5/12) (attempt #0) with attempt id 0f878fa4791a43e60fdb14074e3701f9 to 5596afe2-4430-4de9-aaf9-d2ce4824b53c @ activate.navicat.com (dataPort=-1) with allocation id bbc5a6ec0f9bf121b56f7d3d3a9c98bf
2023-07-20 11:25:34.205 [flink-akka.actor.default-dispatcher-4] INFO  o.a.flink.runtime.executiongraph.ExecutionGraph - Source: Custom Source -> Map -> Sink: Print to Std. Out (6/12) (ec3492a40eb26a07764df9451eb319aa) switched from SCHEDULED to DEPLOYING.
2023-07-20 11:25:34.205 [flink-akka.actor.default-dispatcher-4] INFO  o.a.flink.runtime.executiongraph.ExecutionGraph - Deploying Source: Custom Source -> Map -> Sink: Print to Std. Out (6/12) (attempt #0) with attempt id ec3492a40eb26a07764df9451eb319aa to 5596afe2-4430-4de9-aaf9-d2ce4824b53c @ activate.navicat.com (dataPort=-1) with allocation id d55bd29fa307be8f5f5c014a6faa5492
2023-07-20 11:25:34.205 [flink-akka.actor.default-dispatcher-4] INFO  o.a.flink.runtime.executiongraph.ExecutionGraph - Source: Custom Source -> Map -> Sink: Print to Std. Out (7/12) (60bb8c1c9b38e2e28198c1a4d2c1a0a8) switched from SCHEDULED to DEPLOYING.
2023-07-20 11:25:34.206 [flink-akka.actor.default-dispatcher-4] INFO  o.a.flink.runtime.executiongraph.ExecutionGraph - Deploying Source: Custom Source -> Map -> Sink: Print to Std. Out (7/12) (attempt #0) with attempt id 60bb8c1c9b38e2e28198c1a4d2c1a0a8 to 5596afe2-4430-4de9-aaf9-d2ce4824b53c @ activate.navicat.com (dataPort=-1) with allocation id 5ca4b93edadeb5bae52ab54e56846f7d
2023-07-20 11:25:34.206 [flink-akka.actor.default-dispatcher-4] INFO  o.a.flink.runtime.executiongraph.ExecutionGraph - Source: Custom Source -> Map -> Sink: Print to Std. Out (8/12) (f960da4a895dfcddaa6dfe2396fe2aaf) switched from SCHEDULED to DEPLOYING.
2023-07-20 11:25:34.206 [flink-akka.actor.default-dispatcher-4] INFO  o.a.flink.runtime.executiongraph.ExecutionGraph - Deploying Source: Custom Source -> Map -> Sink: Print to Std. Out (8/12) (attempt #0) with attempt id f960da4a895dfcddaa6dfe2396fe2aaf to 5596afe2-4430-4de9-aaf9-d2ce4824b53c @ activate.navicat.com (dataPort=-1) with allocation id 8c3d7ffe59468eeab82e35718253494a
2023-07-20 11:25:34.206 [flink-akka.actor.default-dispatcher-4] INFO  o.a.flink.runtime.executiongraph.ExecutionGraph - Source: Custom Source -> Map -> Sink: Print to Std. Out (9/12) (3a615b06031e23aeb98087b28f99931f) switched from SCHEDULED to DEPLOYING.
2023-07-20 11:25:34.206 [flink-akka.actor.default-dispatcher-4] INFO  o.a.flink.runtime.executiongraph.ExecutionGraph - Deploying Source: Custom Source -> Map -> Sink: Print to Std. Out (9/12) (attempt #0) with attempt id 3a615b06031e23aeb98087b28f99931f to 5596afe2-4430-4de9-aaf9-d2ce4824b53c @ activate.navicat.com (dataPort=-1) with allocation id b4b57e742c1e361ea949da20053d7cab
2023-07-20 11:25:34.206 [flink-akka.actor.default-dispatcher-4] INFO  o.a.flink.runtime.executiongraph.ExecutionGraph - Source: Custom Source -> Map -> Sink: Print to Std. Out (10/12) (cabee4fea2749a549b9de415986bca12) switched from SCHEDULED to DEPLOYING.
2023-07-20 11:25:34.206 [flink-akka.actor.default-dispatcher-4] INFO  o.a.flink.runtime.executiongraph.ExecutionGraph - Deploying Source: Custom Source -> Map -> Sink: Print to Std. Out (10/12) (attempt #0) with attempt id cabee4fea2749a549b9de415986bca12 to 5596afe2-4430-4de9-aaf9-d2ce4824b53c @ activate.navicat.com (dataPort=-1) with allocation id 3ff7a87005665645c9bc2042d47e314a
2023-07-20 11:25:34.207 [flink-akka.actor.default-dispatcher-4] INFO  o.a.flink.runtime.executiongraph.ExecutionGraph - Source: Custom Source -> Map -> Sink: Print to Std. Out (11/12) (a0849148e22b604a960f950f2cacdeb1) switched from SCHEDULED to DEPLOYING.
2023-07-20 11:25:34.207 [flink-akka.actor.default-dispatcher-4] INFO  o.a.flink.runtime.executiongraph.ExecutionGraph - Deploying Source: Custom Source -> Map -> Sink: Print to Std. Out (11/12) (attempt #0) with attempt id a0849148e22b604a960f950f2cacdeb1 to 5596afe2-4430-4de9-aaf9-d2ce4824b53c @ activate.navicat.com (dataPort=-1) with allocation id 6b34d81f9715059094e5733c926048c9
2023-07-20 11:25:34.207 [flink-akka.actor.default-dispatcher-4] INFO  o.a.flink.runtime.executiongraph.ExecutionGraph - Source: Custom Source -> Map -> Sink: Print to Std. Out (12/12) (4747991b52a7b5fa339fb5bb4783dac3) switched from SCHEDULED to DEPLOYING.
2023-07-20 11:25:34.207 [flink-akka.actor.default-dispatcher-4] INFO  o.a.flink.runtime.executiongraph.ExecutionGraph - Deploying Source: Custom Source -> Map -> Sink: Print to Std. Out (12/12) (attempt #0) with attempt id 4747991b52a7b5fa339fb5bb4783dac3 to 5596afe2-4430-4de9-aaf9-d2ce4824b53c @ activate.navicat.com (dataPort=-1) with allocation id f3bfc3cfad8248254a6fa8d99820cc9e
2023-07-20 11:25:34.219 [flink-akka.actor.default-dispatcher-2] INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor - Received task Source: Custom Source -> Map -> Sink: Print to Std. Out (1/12)#0 (06b46774af4e2cd402280bd56b2859c8), deploy into slot with allocation id d5a016017aafa305b1c1eb979337bcca.
2023-07-20 11:25:34.219 [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/12)#0] INFO  org.apache.flink.runtime.taskmanager.Task - Source: Custom Source -> Map -> Sink: Print to Std. Out (1/12)#0 (06b46774af4e2cd402280bd56b2859c8) switched from CREATED to DEPLOYING.
2023-07-20 11:25:34.221 [flink-akka.actor.default-dispatcher-2] INFO  o.a.f.runtime.taskexecutor.slot.TaskSlotTableImpl - Activate slot 4188e598a143efd3ea8c84675c121ba9.
2023-07-20 11:25:34.222 [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/12)#0] INFO  org.apache.flink.runtime.taskmanager.Task - Loading JAR files for task Source: Custom Source -> Map -> Sink: Print to Std. Out (1/12)#0 (06b46774af4e2cd402280bd56b2859c8) [DEPLOYING].
2023-07-20 11:25:34.223 [flink-akka.actor.default-dispatcher-2] INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor - Received task Source: Custom Source -> Map -> Sink: Print to Std. Out (2/12)#0 (58809d64463bd3d3cb7eccafa2d5146b), deploy into slot with allocation id 4188e598a143efd3ea8c84675c121ba9.
2023-07-20 11:25:34.223 [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/12)#0] INFO  org.apache.flink.runtime.taskmanager.Task - Source: Custom Source -> Map -> Sink: Print to Std. Out (2/12)#0 (58809d64463bd3d3cb7eccafa2d5146b) switched from CREATED to DEPLOYING.
2023-07-20 11:25:34.223 [flink-akka.actor.default-dispatcher-2] INFO  o.a.f.runtime.taskexecutor.slot.TaskSlotTableImpl - Activate slot ad03fde429c12587f66027072531f485.
2023-07-20 11:25:34.223 [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/12)#0] INFO  org.apache.flink.runtime.taskmanager.Task - Loading JAR files for task Source: Custom Source -> Map -> Sink: Print to Std. Out (2/12)#0 (58809d64463bd3d3cb7eccafa2d5146b) [DEPLOYING].
2023-07-20 11:25:34.223 [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/12)#0] INFO  org.apache.flink.runtime.taskmanager.Task - Registering task at network: Source: Custom Source -> Map -> Sink: Print to Std. Out (1/12)#0 (06b46774af4e2cd402280bd56b2859c8) [DEPLOYING].
2023-07-20 11:25:34.224 [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/12)#0] INFO  org.apache.flink.runtime.taskmanager.Task - Registering task at network: Source: Custom Source -> Map -> Sink: Print to Std. Out (2/12)#0 (58809d64463bd3d3cb7eccafa2d5146b) [DEPLOYING].
2023-07-20 11:25:34.224 [flink-akka.actor.default-dispatcher-2] INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor - Received task Source: Custom Source -> Map -> Sink: Print to Std. Out (3/12)#0 (e13c6c371665bbeac4ef411df29cb612), deploy into slot with allocation id ad03fde429c12587f66027072531f485.
2023-07-20 11:25:34.224 [flink-akka.actor.default-dispatcher-2] INFO  o.a.f.runtime.taskexecutor.slot.TaskSlotTableImpl - Activate slot f4f54a5ab8be988eedbdc0a084f04350.
2023-07-20 11:25:34.224 [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/12)#0] INFO  org.apache.flink.runtime.taskmanager.Task - Source: Custom Source -> Map -> Sink: Print to Std. Out (3/12)#0 (e13c6c371665bbeac4ef411df29cb612) switched from CREATED to DEPLOYING.
2023-07-20 11:25:34.224 [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/12)#0] INFO  org.apache.flink.runtime.taskmanager.Task - Loading JAR files for task Source: Custom Source -> Map -> Sink: Print to Std. Out (3/12)#0 (e13c6c371665bbeac4ef411df29cb612) [DEPLOYING].
2023-07-20 11:25:34.225 [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/12)#0] INFO  org.apache.flink.runtime.taskmanager.Task - Registering task at network: Source: Custom Source -> Map -> Sink: Print to Std. Out (3/12)#0 (e13c6c371665bbeac4ef411df29cb612) [DEPLOYING].
2023-07-20 11:25:34.226 [flink-akka.actor.default-dispatcher-2] INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor - Received task Source: Custom Source -> Map -> Sink: Print to Std. Out (4/12)#0 (d153777326e67cbb2a9c2a3ac7af29ab), deploy into slot with allocation id f4f54a5ab8be988eedbdc0a084f04350.
2023-07-20 11:25:34.226 [flink-akka.actor.default-dispatcher-2] INFO  o.a.f.runtime.taskexecutor.slot.TaskSlotTableImpl - Activate slot bbc5a6ec0f9bf121b56f7d3d3a9c98bf.
2023-07-20 11:25:34.226 [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/12)#0] INFO  org.apache.flink.runtime.taskmanager.Task - Source: Custom Source -> Map -> Sink: Print to Std. Out (4/12)#0 (d153777326e67cbb2a9c2a3ac7af29ab) switched from CREATED to DEPLOYING.
2023-07-20 11:25:34.226 [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/12)#0] INFO  org.apache.flink.runtime.taskmanager.Task - Loading JAR files for task Source: Custom Source -> Map -> Sink: Print to Std. Out (4/12)#0 (d153777326e67cbb2a9c2a3ac7af29ab) [DEPLOYING].
2023-07-20 11:25:34.227 [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/12)#0] INFO  org.apache.flink.runtime.taskmanager.Task - Registering task at network: Source: Custom Source -> Map -> Sink: Print to Std. Out (4/12)#0 (d153777326e67cbb2a9c2a3ac7af29ab) [DEPLOYING].
2023-07-20 11:25:34.227 [flink-akka.actor.default-dispatcher-2] INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor - Received task Source: Custom Source -> Map -> Sink: Print to Std. Out (5/12)#0 (0f878fa4791a43e60fdb14074e3701f9), deploy into slot with allocation id bbc5a6ec0f9bf121b56f7d3d3a9c98bf.
2023-07-20 11:25:34.227 [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/12)#0] INFO  org.apache.flink.runtime.taskmanager.Task - Source: Custom Source -> Map -> Sink: Print to Std. Out (5/12)#0 (0f878fa4791a43e60fdb14074e3701f9) switched from CREATED to DEPLOYING.
2023-07-20 11:25:34.227 [flink-akka.actor.default-dispatcher-2] INFO  o.a.f.runtime.taskexecutor.slot.TaskSlotTableImpl - Activate slot d55bd29fa307be8f5f5c014a6faa5492.
2023-07-20 11:25:34.227 [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/12)#0] INFO  org.apache.flink.runtime.taskmanager.Task - Loading JAR files for task Source: Custom Source -> Map -> Sink: Print to Std. Out (5/12)#0 (0f878fa4791a43e60fdb14074e3701f9) [DEPLOYING].
2023-07-20 11:25:34.228 [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/12)#0] INFO  org.apache.flink.runtime.taskmanager.Task - Registering task at network: Source: Custom Source -> Map -> Sink: Print to Std. Out (5/12)#0 (0f878fa4791a43e60fdb14074e3701f9) [DEPLOYING].
2023-07-20 11:25:34.229 [flink-akka.actor.default-dispatcher-2] INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor - Received task Source: Custom Source -> Map -> Sink: Print to Std. Out (6/12)#0 (ec3492a40eb26a07764df9451eb319aa), deploy into slot with allocation id d55bd29fa307be8f5f5c014a6faa5492.
2023-07-20 11:25:34.229 [flink-akka.actor.default-dispatcher-2] INFO  o.a.f.runtime.taskexecutor.slot.TaskSlotTableImpl - Activate slot 5ca4b93edadeb5bae52ab54e56846f7d.
2023-07-20 11:25:34.229 [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/12)#0] INFO  org.apache.flink.runtime.taskmanager.Task - Source: Custom Source -> Map -> Sink: Print to Std. Out (6/12)#0 (ec3492a40eb26a07764df9451eb319aa) switched from CREATED to DEPLOYING.
2023-07-20 11:25:34.229 [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/12)#0] INFO  org.apache.flink.runtime.taskmanager.Task - Loading JAR files for task Source: Custom Source -> Map -> Sink: Print to Std. Out (6/12)#0 (ec3492a40eb26a07764df9451eb319aa) [DEPLOYING].
2023-07-20 11:25:34.230 [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/12)#0] INFO  org.apache.flink.runtime.taskmanager.Task - Registering task at network: Source: Custom Source -> Map -> Sink: Print to Std. Out (6/12)#0 (ec3492a40eb26a07764df9451eb319aa) [DEPLOYING].
2023-07-20 11:25:34.231 [flink-akka.actor.default-dispatcher-2] INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor - Received task Source: Custom Source -> Map -> Sink: Print to Std. Out (7/12)#0 (60bb8c1c9b38e2e28198c1a4d2c1a0a8), deploy into slot with allocation id 5ca4b93edadeb5bae52ab54e56846f7d.
2023-07-20 11:25:34.232 [flink-akka.actor.default-dispatcher-2] INFO  o.a.f.runtime.taskexecutor.slot.TaskSlotTableImpl - Activate slot 8c3d7ffe59468eeab82e35718253494a.
2023-07-20 11:25:34.232 [Source: Custom Source -> Map -> Sink: Print to Std. Out (7/12)#0] INFO  org.apache.flink.runtime.taskmanager.Task - Source: Custom Source -> Map -> Sink: Print to Std. Out (7/12)#0 (60bb8c1c9b38e2e28198c1a4d2c1a0a8) switched from CREATED to DEPLOYING.
2023-07-20 11:25:34.232 [Source: Custom Source -> Map -> Sink: Print to Std. Out (7/12)#0] INFO  org.apache.flink.runtime.taskmanager.Task - Loading JAR files for task Source: Custom Source -> Map -> Sink: Print to Std. Out (7/12)#0 (60bb8c1c9b38e2e28198c1a4d2c1a0a8) [DEPLOYING].
2023-07-20 11:25:34.233 [Source: Custom Source -> Map -> Sink: Print to Std. Out (7/12)#0] INFO  org.apache.flink.runtime.taskmanager.Task - Registering task at network: Source: Custom Source -> Map -> Sink: Print to Std. Out (7/12)#0 (60bb8c1c9b38e2e28198c1a4d2c1a0a8) [DEPLOYING].
2023-07-20 11:25:34.233 [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/12)#0] INFO  o.apache.flink.streaming.runtime.tasks.StreamTask - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2023-07-20 11:25:34.233 [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/12)#0] INFO  o.apache.flink.streaming.runtime.tasks.StreamTask - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2023-07-20 11:25:34.233 [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/12)#0] INFO  o.apache.flink.streaming.runtime.tasks.StreamTask - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2023-07-20 11:25:34.233 [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/12)#0] INFO  o.apache.flink.streaming.runtime.tasks.StreamTask - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2023-07-20 11:25:34.233 [Source: Custom Source -> Map -> Sink: Print to Std. Out (7/12)#0] INFO  o.apache.flink.streaming.runtime.tasks.StreamTask - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2023-07-20 11:25:34.233 [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/12)#0] INFO  o.apache.flink.streaming.runtime.tasks.StreamTask - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2023-07-20 11:25:34.233 [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/12)#0] INFO  o.apache.flink.streaming.runtime.tasks.StreamTask - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2023-07-20 11:25:34.234 [flink-akka.actor.default-dispatcher-2] INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor - Received task Source: Custom Source -> Map -> Sink: Print to Std. Out (8/12)#0 (f960da4a895dfcddaa6dfe2396fe2aaf), deploy into slot with allocation id 8c3d7ffe59468eeab82e35718253494a.
2023-07-20 11:25:34.234 [Source: Custom Source -> Map -> Sink: Print to Std. Out (8/12)#0] INFO  org.apache.flink.runtime.taskmanager.Task - Source: Custom Source -> Map -> Sink: Print to Std. Out (8/12)#0 (f960da4a895dfcddaa6dfe2396fe2aaf) switched from CREATED to DEPLOYING.
2023-07-20 11:25:34.235 [flink-akka.actor.default-dispatcher-2] INFO  o.a.f.runtime.taskexecutor.slot.TaskSlotTableImpl - Activate slot b4b57e742c1e361ea949da20053d7cab.
2023-07-20 11:25:34.235 [Source: Custom Source -> Map -> Sink: Print to Std. Out (8/12)#0] INFO  org.apache.flink.runtime.taskmanager.Task - Loading JAR files for task Source: Custom Source -> Map -> Sink: Print to Std. Out (8/12)#0 (f960da4a895dfcddaa6dfe2396fe2aaf) [DEPLOYING].
2023-07-20 11:25:34.235 [Source: Custom Source -> Map -> Sink: Print to Std. Out (8/12)#0] INFO  org.apache.flink.runtime.taskmanager.Task - Registering task at network: Source: Custom Source -> Map -> Sink: Print to Std. Out (8/12)#0 (f960da4a895dfcddaa6dfe2396fe2aaf) [DEPLOYING].
2023-07-20 11:25:34.236 [Source: Custom Source -> Map -> Sink: Print to Std. Out (8/12)#0] INFO  o.apache.flink.streaming.runtime.tasks.StreamTask - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2023-07-20 11:25:34.236 [flink-akka.actor.default-dispatcher-2] INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor - Received task Source: Custom Source -> Map -> Sink: Print to Std. Out (9/12)#0 (3a615b06031e23aeb98087b28f99931f), deploy into slot with allocation id b4b57e742c1e361ea949da20053d7cab.
2023-07-20 11:25:34.237 [Source: Custom Source -> Map -> Sink: Print to Std. Out (9/12)#0] INFO  org.apache.flink.runtime.taskmanager.Task - Source: Custom Source -> Map -> Sink: Print to Std. Out (9/12)#0 (3a615b06031e23aeb98087b28f99931f) switched from CREATED to DEPLOYING.
2023-07-20 11:25:34.237 [flink-akka.actor.default-dispatcher-2] INFO  o.a.f.runtime.taskexecutor.slot.TaskSlotTableImpl - Activate slot 3ff7a87005665645c9bc2042d47e314a.
2023-07-20 11:25:34.237 [Source: Custom Source -> Map -> Sink: Print to Std. Out (9/12)#0] INFO  org.apache.flink.runtime.taskmanager.Task - Loading JAR files for task Source: Custom Source -> Map -> Sink: Print to Std. Out (9/12)#0 (3a615b06031e23aeb98087b28f99931f) [DEPLOYING].
2023-07-20 11:25:34.238 [Source: Custom Source -> Map -> Sink: Print to Std. Out (9/12)#0] INFO  org.apache.flink.runtime.taskmanager.Task - Registering task at network: Source: Custom Source -> Map -> Sink: Print to Std. Out (9/12)#0 (3a615b06031e23aeb98087b28f99931f) [DEPLOYING].
2023-07-20 11:25:34.238 [Source: Custom Source -> Map -> Sink: Print to Std. Out (9/12)#0] INFO  o.apache.flink.streaming.runtime.tasks.StreamTask - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2023-07-20 11:25:34.239 [flink-akka.actor.default-dispatcher-2] INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor - Received task Source: Custom Source -> Map -> Sink: Print to Std. Out (10/12)#0 (cabee4fea2749a549b9de415986bca12), deploy into slot with allocation id 3ff7a87005665645c9bc2042d47e314a.
2023-07-20 11:25:34.239 [flink-akka.actor.default-dispatcher-2] INFO  o.a.f.runtime.taskexecutor.slot.TaskSlotTableImpl - Activate slot 6b34d81f9715059094e5733c926048c9.
2023-07-20 11:25:34.239 [Source: Custom Source -> Map -> Sink: Print to Std. Out (10/12)#0] INFO  org.apache.flink.runtime.taskmanager.Task - Source: Custom Source -> Map -> Sink: Print to Std. Out (10/12)#0 (cabee4fea2749a549b9de415986bca12) switched from CREATED to DEPLOYING.
2023-07-20 11:25:34.239 [Source: Custom Source -> Map -> Sink: Print to Std. Out (9/12)#0] INFO  org.apache.flink.runtime.taskmanager.Task - Source: Custom Source -> Map -> Sink: Print to Std. Out (9/12)#0 (3a615b06031e23aeb98087b28f99931f) switched from DEPLOYING to RUNNING.
2023-07-20 11:25:34.239 [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/12)#0] INFO  org.apache.flink.runtime.taskmanager.Task - Source: Custom Source -> Map -> Sink: Print to Std. Out (3/12)#0 (e13c6c371665bbeac4ef411df29cb612) switched from DEPLOYING to RUNNING.
2023-07-20 11:25:34.239 [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/12)#0] INFO  org.apache.flink.runtime.taskmanager.Task - Source: Custom Source -> Map -> Sink: Print to Std. Out (6/12)#0 (ec3492a40eb26a07764df9451eb319aa) switched from DEPLOYING to RUNNING.
2023-07-20 11:25:34.239 [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/12)#0] INFO  org.apache.flink.runtime.taskmanager.Task - Source: Custom Source -> Map -> Sink: Print to Std. Out (2/12)#0 (58809d64463bd3d3cb7eccafa2d5146b) switched from DEPLOYING to RUNNING.
2023-07-20 11:25:34.239 [Source: Custom Source -> Map -> Sink: Print to Std. Out (10/12)#0] INFO  org.apache.flink.runtime.taskmanager.Task - Loading JAR files for task Source: Custom Source -> Map -> Sink: Print to Std. Out (10/12)#0 (cabee4fea2749a549b9de415986bca12) [DEPLOYING].
2023-07-20 11:25:34.239 [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/12)#0] INFO  org.apache.flink.runtime.taskmanager.Task - Source: Custom Source -> Map -> Sink: Print to Std. Out (1/12)#0 (06b46774af4e2cd402280bd56b2859c8) switched from DEPLOYING to RUNNING.
2023-07-20 11:25:34.239 [Source: Custom Source -> Map -> Sink: Print to Std. Out (7/12)#0] INFO  org.apache.flink.runtime.taskmanager.Task - Source: Custom Source -> Map -> Sink: Print to Std. Out (7/12)#0 (60bb8c1c9b38e2e28198c1a4d2c1a0a8) switched from DEPLOYING to RUNNING.
2023-07-20 11:25:34.239 [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/12)#0] INFO  org.apache.flink.runtime.taskmanager.Task - Source: Custom Source -> Map -> Sink: Print to Std. Out (5/12)#0 (0f878fa4791a43e60fdb14074e3701f9) switched from DEPLOYING to RUNNING.
2023-07-20 11:25:34.239 [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/12)#0] INFO  org.apache.flink.runtime.taskmanager.Task - Source: Custom Source -> Map -> Sink: Print to Std. Out (4/12)#0 (d153777326e67cbb2a9c2a3ac7af29ab) switched from DEPLOYING to RUNNING.
2023-07-20 11:25:34.239 [Source: Custom Source -> Map -> Sink: Print to Std. Out (8/12)#0] INFO  org.apache.flink.runtime.taskmanager.Task - Source: Custom Source -> Map -> Sink: Print to Std. Out (8/12)#0 (f960da4a895dfcddaa6dfe2396fe2aaf) switched from DEPLOYING to RUNNING.
2023-07-20 11:25:34.240 [Source: Custom Source -> Map -> Sink: Print to Std. Out (10/12)#0] INFO  org.apache.flink.runtime.taskmanager.Task - Registering task at network: Source: Custom Source -> Map -> Sink: Print to Std. Out (10/12)#0 (cabee4fea2749a549b9de415986bca12) [DEPLOYING].
2023-07-20 11:25:34.240 [Source: Custom Source -> Map -> Sink: Print to Std. Out (10/12)#0] INFO  o.apache.flink.streaming.runtime.tasks.StreamTask - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2023-07-20 11:25:34.240 [Source: Custom Source -> Map -> Sink: Print to Std. Out (10/12)#0] INFO  org.apache.flink.runtime.taskmanager.Task - Source: Custom Source -> Map -> Sink: Print to Std. Out (10/12)#0 (cabee4fea2749a549b9de415986bca12) switched from DEPLOYING to RUNNING.
2023-07-20 11:25:34.240 [flink-akka.actor.default-dispatcher-6] INFO  o.a.flink.runtime.executiongraph.ExecutionGraph - Source: Custom Source -> Map -> Sink: Print to Std. Out (6/12) (ec3492a40eb26a07764df9451eb319aa) switched from DEPLOYING to RUNNING.
2023-07-20 11:25:34.241 [flink-akka.actor.default-dispatcher-2] INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor - Received task Source: Custom Source -> Map -> Sink: Print to Std. Out (11/12)#0 (a0849148e22b604a960f950f2cacdeb1), deploy into slot with allocation id 6b34d81f9715059094e5733c926048c9.
2023-07-20 11:25:34.241 [flink-akka.actor.default-dispatcher-6] INFO  o.a.flink.runtime.executiongraph.ExecutionGraph - Source: Custom Source -> Map -> Sink: Print to Std. Out (9/12) (3a615b06031e23aeb98087b28f99931f) switched from DEPLOYING to RUNNING.
2023-07-20 11:25:34.241 [flink-akka.actor.default-dispatcher-2] INFO  o.a.f.runtime.taskexecutor.slot.TaskSlotTableImpl - Activate slot f3bfc3cfad8248254a6fa8d99820cc9e.
2023-07-20 11:25:34.241 [Source: Custom Source -> Map -> Sink: Print to Std. Out (11/12)#0] INFO  org.apache.flink.runtime.taskmanager.Task - Source: Custom Source -> Map -> Sink: Print to Std. Out (11/12)#0 (a0849148e22b604a960f950f2cacdeb1) switched from CREATED to DEPLOYING.
2023-07-20 11:25:34.241 [flink-akka.actor.default-dispatcher-6] INFO  o.a.flink.runtime.executiongraph.ExecutionGraph - Source: Custom Source -> Map -> Sink: Print to Std. Out (3/12) (e13c6c371665bbeac4ef411df29cb612) switched from DEPLOYING to RUNNING.
2023-07-20 11:25:34.241 [Source: Custom Source -> Map -> Sink: Print to Std. Out (11/12)#0] INFO  org.apache.flink.runtime.taskmanager.Task - Loading JAR files for task Source: Custom Source -> Map -> Sink: Print to Std. Out (11/12)#0 (a0849148e22b604a960f950f2cacdeb1) [DEPLOYING].
2023-07-20 11:25:34.241 [flink-akka.actor.default-dispatcher-6] INFO  o.a.flink.runtime.executiongraph.ExecutionGraph - Source: Custom Source -> Map -> Sink: Print to Std. Out (2/12) (58809d64463bd3d3cb7eccafa2d5146b) switched from DEPLOYING to RUNNING.
2023-07-20 11:25:34.241 [flink-akka.actor.default-dispatcher-6] INFO  o.a.flink.runtime.executiongraph.ExecutionGraph - Source: Custom Source -> Map -> Sink: Print to Std. Out (1/12) (06b46774af4e2cd402280bd56b2859c8) switched from DEPLOYING to RUNNING.
2023-07-20 11:25:34.241 [flink-akka.actor.default-dispatcher-6] INFO  o.a.flink.runtime.executiongraph.ExecutionGraph - Source: Custom Source -> Map -> Sink: Print to Std. Out (7/12) (60bb8c1c9b38e2e28198c1a4d2c1a0a8) switched from DEPLOYING to RUNNING.
2023-07-20 11:25:34.242 [flink-akka.actor.default-dispatcher-6] INFO  o.a.flink.runtime.executiongraph.ExecutionGraph - Source: Custom Source -> Map -> Sink: Print to Std. Out (5/12) (0f878fa4791a43e60fdb14074e3701f9) switched from DEPLOYING to RUNNING.
2023-07-20 11:25:34.242 [flink-akka.actor.default-dispatcher-6] INFO  o.a.flink.runtime.executiongraph.ExecutionGraph - Source: Custom Source -> Map -> Sink: Print to Std. Out (4/12) (d153777326e67cbb2a9c2a3ac7af29ab) switched from DEPLOYING to RUNNING.
2023-07-20 11:25:34.242 [flink-akka.actor.default-dispatcher-6] INFO  o.a.flink.runtime.executiongraph.ExecutionGraph - Source: Custom Source -> Map -> Sink: Print to Std. Out (8/12) (f960da4a895dfcddaa6dfe2396fe2aaf) switched from DEPLOYING to RUNNING.
2023-07-20 11:25:34.242 [flink-akka.actor.default-dispatcher-6] INFO  o.a.flink.runtime.executiongraph.ExecutionGraph - Source: Custom Source -> Map -> Sink: Print to Std. Out (10/12) (cabee4fea2749a549b9de415986bca12) switched from DEPLOYING to RUNNING.
2023-07-20 11:25:34.242 [Source: Custom Source -> Map -> Sink: Print to Std. Out (11/12)#0] INFO  org.apache.flink.runtime.taskmanager.Task - Registering task at network: Source: Custom Source -> Map -> Sink: Print to Std. Out (11/12)#0 (a0849148e22b604a960f950f2cacdeb1) [DEPLOYING].
2023-07-20 11:25:34.242 [Source: Custom Source -> Map -> Sink: Print to Std. Out (11/12)#0] INFO  o.apache.flink.streaming.runtime.tasks.StreamTask - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2023-07-20 11:25:34.242 [Source: Custom Source -> Map -> Sink: Print to Std. Out (11/12)#0] INFO  org.apache.flink.runtime.taskmanager.Task - Source: Custom Source -> Map -> Sink: Print to Std. Out (11/12)#0 (a0849148e22b604a960f950f2cacdeb1) switched from DEPLOYING to RUNNING.
2023-07-20 11:25:34.243 [flink-akka.actor.default-dispatcher-4] INFO  o.a.flink.runtime.executiongraph.ExecutionGraph - Source: Custom Source -> Map -> Sink: Print to Std. Out (11/12) (a0849148e22b604a960f950f2cacdeb1) switched from DEPLOYING to RUNNING.
2023-07-20 11:25:34.243 [flink-akka.actor.default-dispatcher-2] INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor - Received task Source: Custom Source -> Map -> Sink: Print to Std. Out (12/12)#0 (4747991b52a7b5fa339fb5bb4783dac3), deploy into slot with allocation id f3bfc3cfad8248254a6fa8d99820cc9e.
2023-07-20 11:25:34.244 [flink-akka.actor.default-dispatcher-2] INFO  o.a.f.runtime.taskexecutor.slot.TaskSlotTableImpl - Activate slot d5a016017aafa305b1c1eb979337bcca.
2023-07-20 11:25:34.244 [flink-akka.actor.default-dispatcher-2] INFO  o.a.f.runtime.taskexecutor.slot.TaskSlotTableImpl - Activate slot 4188e598a143efd3ea8c84675c121ba9.
2023-07-20 11:25:34.244 [Source: Custom Source -> Map -> Sink: Print to Std. Out (12/12)#0] INFO  org.apache.flink.runtime.taskmanager.Task - Source: Custom Source -> Map -> Sink: Print to Std. Out (12/12)#0 (4747991b52a7b5fa339fb5bb4783dac3) switched from CREATED to DEPLOYING.
2023-07-20 11:25:34.244 [flink-akka.actor.default-dispatcher-2] INFO  o.a.f.runtime.taskexecutor.slot.TaskSlotTableImpl - Activate slot ad03fde429c12587f66027072531f485.
2023-07-20 11:25:34.244 [flink-akka.actor.default-dispatcher-2] INFO  o.a.f.runtime.taskexecutor.slot.TaskSlotTableImpl - Activate slot f4f54a5ab8be988eedbdc0a084f04350.
2023-07-20 11:25:34.244 [flink-akka.actor.default-dispatcher-2] INFO  o.a.f.runtime.taskexecutor.slot.TaskSlotTableImpl - Activate slot bbc5a6ec0f9bf121b56f7d3d3a9c98bf.
2023-07-20 11:25:34.244 [flink-akka.actor.default-dispatcher-2] INFO  o.a.f.runtime.taskexecutor.slot.TaskSlotTableImpl - Activate slot d55bd29fa307be8f5f5c014a6faa5492.
2023-07-20 11:25:34.245 [flink-akka.actor.default-dispatcher-2] INFO  o.a.f.runtime.taskexecutor.slot.TaskSlotTableImpl - Activate slot 5ca4b93edadeb5bae52ab54e56846f7d.
2023-07-20 11:25:34.244 [Source: Custom Source -> Map -> Sink: Print to Std. Out (12/12)#0] INFO  org.apache.flink.runtime.taskmanager.Task - Loading JAR files for task Source: Custom Source -> Map -> Sink: Print to Std. Out (12/12)#0 (4747991b52a7b5fa339fb5bb4783dac3) [DEPLOYING].
2023-07-20 11:25:34.245 [flink-akka.actor.default-dispatcher-2] INFO  o.a.f.runtime.taskexecutor.slot.TaskSlotTableImpl - Activate slot 8c3d7ffe59468eeab82e35718253494a.
2023-07-20 11:25:34.246 [flink-akka.actor.default-dispatcher-2] INFO  o.a.f.runtime.taskexecutor.slot.TaskSlotTableImpl - Activate slot b4b57e742c1e361ea949da20053d7cab.
2023-07-20 11:25:34.246 [flink-akka.actor.default-dispatcher-2] INFO  o.a.f.runtime.taskexecutor.slot.TaskSlotTableImpl - Activate slot 3ff7a87005665645c9bc2042d47e314a.
2023-07-20 11:25:34.246 [Source: Custom Source -> Map -> Sink: Print to Std. Out (12/12)#0] INFO  org.apache.flink.runtime.taskmanager.Task - Registering task at network: Source: Custom Source -> Map -> Sink: Print to Std. Out (12/12)#0 (4747991b52a7b5fa339fb5bb4783dac3) [DEPLOYING].
2023-07-20 11:25:34.246 [flink-akka.actor.default-dispatcher-2] INFO  o.a.f.runtime.taskexecutor.slot.TaskSlotTableImpl - Activate slot 6b34d81f9715059094e5733c926048c9.
2023-07-20 11:25:34.246 [flink-akka.actor.default-dispatcher-2] INFO  o.a.f.runtime.taskexecutor.slot.TaskSlotTableImpl - Activate slot f3bfc3cfad8248254a6fa8d99820cc9e.
2023-07-20 11:25:34.246 [Source: Custom Source -> Map -> Sink: Print to Std. Out (12/12)#0] INFO  o.apache.flink.streaming.runtime.tasks.StreamTask - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2023-07-20 11:25:34.246 [Source: Custom Source -> Map -> Sink: Print to Std. Out (12/12)#0] INFO  org.apache.flink.runtime.taskmanager.Task - Source: Custom Source -> Map -> Sink: Print to Std. Out (12/12)#0 (4747991b52a7b5fa339fb5bb4783dac3) switched from DEPLOYING to RUNNING.
2023-07-20 11:25:34.246 [flink-akka.actor.default-dispatcher-2] INFO  o.a.flink.runtime.executiongraph.ExecutionGraph - Source: Custom Source -> Map -> Sink: Print to Std. Out (12/12) (4747991b52a7b5fa339fb5bb4783dac3) switched from DEPLOYING to RUNNING.
2023-07-20 11:25:34.315 [Source: Custom Source -> Map -> Sink: Print to Std. Out (8/12)#0] INFO  o.a.f.s.connectors.kafka.FlinkKafkaConsumerBase - Consumer subtask 7 has no restore state.
2023-07-20 11:25:34.315 [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/12)#0] INFO  o.a.f.s.connectors.kafka.FlinkKafkaConsumerBase - Consumer subtask 3 has no restore state.
2023-07-20 11:25:34.315 [Source: Custom Source -> Map -> Sink: Print to Std. Out (7/12)#0] INFO  o.a.f.s.connectors.kafka.FlinkKafkaConsumerBase - Consumer subtask 6 has no restore state.
2023-07-20 11:25:34.315 [Source: Custom Source -> Map -> Sink: Print to Std. Out (12/12)#0] INFO  o.a.f.s.connectors.kafka.FlinkKafkaConsumerBase - Consumer subtask 11 has no restore state.
2023-07-20 11:25:34.315 [Source: Custom Source -> Map -> Sink: Print to Std. Out (11/12)#0] INFO  o.a.f.s.connectors.kafka.FlinkKafkaConsumerBase - Consumer subtask 10 has no restore state.
2023-07-20 11:25:34.315 [Source: Custom Source -> Map -> Sink: Print to Std. Out (10/12)#0] INFO  o.a.f.s.connectors.kafka.FlinkKafkaConsumerBase - Consumer subtask 9 has no restore state.
2023-07-20 11:25:34.315 [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/12)#0] INFO  o.a.f.s.connectors.kafka.FlinkKafkaConsumerBase - Consumer subtask 2 has no restore state.
2023-07-20 11:25:34.315 [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/12)#0] INFO  o.a.f.s.connectors.kafka.FlinkKafkaConsumerBase - Consumer subtask 1 has no restore state.
2023-07-20 11:25:34.315 [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/12)#0] INFO  o.a.f.s.connectors.kafka.FlinkKafkaConsumerBase - Consumer subtask 4 has no restore state.
2023-07-20 11:25:34.315 [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/12)#0] INFO  o.a.f.s.connectors.kafka.FlinkKafkaConsumerBase - Consumer subtask 5 has no restore state.
2023-07-20 11:25:34.315 [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/12)#0] INFO  o.a.f.s.connectors.kafka.FlinkKafkaConsumerBase - Consumer subtask 0 has no restore state.
2023-07-20 11:25:34.315 [Source: Custom Source -> Map -> Sink: Print to Std. Out (9/12)#0] INFO  o.a.f.s.connectors.kafka.FlinkKafkaConsumerBase - Consumer subtask 8 has no restore state.
2023-07-20 11:25:34.337 [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/12)#0] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-flink-8
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2023-07-20 11:25:34.338 [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/12)#0] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-flink-9
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2023-07-20 11:25:34.337 [Source: Custom Source -> Map -> Sink: Print to Std. Out (7/12)#0] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-flink-10
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2023-07-20 11:25:34.337 [Source: Custom Source -> Map -> Sink: Print to Std. Out (9/12)#0] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-flink-6
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2023-07-20 11:25:34.338 [Source: Custom Source -> Map -> Sink: Print to Std. Out (10/12)#0] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-flink-7
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2023-07-20 11:25:34.338 [Source: Custom Source -> Map -> Sink: Print to Std. Out (8/12)#0] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-flink-12
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2023-07-20 11:25:34.337 [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/12)#0] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-flink-11
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2023-07-20 11:25:34.338 [Source: Custom Source -> Map -> Sink: Print to Std. Out (11/12)#0] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-flink-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2023-07-20 11:25:34.338 [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/12)#0] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-flink-3
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2023-07-20 11:25:34.338 [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/12)#0] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-flink-4
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2023-07-20 11:25:34.337 [Source: Custom Source -> Map -> Sink: Print to Std. Out (12/12)#0] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-flink-5
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2023-07-20 11:25:34.338 [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/12)#0] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-flink-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2023-07-20 11:25:34.421 [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.7.1
2023-07-20 11:25:34.421 [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 61dbce85d0d41457
2023-07-20 11:25:34.421 [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1689823534420
2023-07-20 11:25:34.422 [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.7.1
2023-07-20 11:25:34.422 [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 61dbce85d0d41457
2023-07-20 11:25:34.422 [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1689823534421
2023-07-20 11:25:34.423 [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.7.1
2023-07-20 11:25:34.423 [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 61dbce85d0d41457
2023-07-20 11:25:34.423 [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1689823534420
2023-07-20 11:25:34.423 [Source: Custom Source -> Map -> Sink: Print to Std. Out (10/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.7.1
2023-07-20 11:25:34.423 [Source: Custom Source -> Map -> Sink: Print to Std. Out (10/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 61dbce85d0d41457
2023-07-20 11:25:34.423 [Source: Custom Source -> Map -> Sink: Print to Std. Out (10/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1689823534420
2023-07-20 11:25:34.423 [Source: Custom Source -> Map -> Sink: Print to Std. Out (9/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.7.1
2023-07-20 11:25:34.423 [Source: Custom Source -> Map -> Sink: Print to Std. Out (9/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 61dbce85d0d41457
2023-07-20 11:25:34.423 [Source: Custom Source -> Map -> Sink: Print to Std. Out (9/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1689823534421
2023-07-20 11:25:34.423 [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.7.1
2023-07-20 11:25:34.423 [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 61dbce85d0d41457
2023-07-20 11:25:34.423 [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1689823534421
2023-07-20 11:25:34.423 [Source: Custom Source -> Map -> Sink: Print to Std. Out (11/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.7.1
2023-07-20 11:25:34.423 [Source: Custom Source -> Map -> Sink: Print to Std. Out (11/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 61dbce85d0d41457
2023-07-20 11:25:34.423 [Source: Custom Source -> Map -> Sink: Print to Std. Out (11/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1689823534421
2023-07-20 11:25:34.423 [Source: Custom Source -> Map -> Sink: Print to Std. Out (8/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.7.1
2023-07-20 11:25:34.423 [Source: Custom Source -> Map -> Sink: Print to Std. Out (8/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 61dbce85d0d41457
2023-07-20 11:25:34.424 [Source: Custom Source -> Map -> Sink: Print to Std. Out (8/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1689823534420
2023-07-20 11:25:34.424 [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.7.1
2023-07-20 11:25:34.424 [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 61dbce85d0d41457
2023-07-20 11:25:34.424 [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1689823534420
2023-07-20 11:25:34.424 [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.7.1
2023-07-20 11:25:34.424 [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 61dbce85d0d41457
2023-07-20 11:25:34.424 [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1689823534421
2023-07-20 11:25:34.424 [Source: Custom Source -> Map -> Sink: Print to Std. Out (12/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.7.1
2023-07-20 11:25:34.424 [Source: Custom Source -> Map -> Sink: Print to Std. Out (12/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 61dbce85d0d41457
2023-07-20 11:25:34.424 [Source: Custom Source -> Map -> Sink: Print to Std. Out (12/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1689823534421
2023-07-20 11:25:34.424 [Source: Custom Source -> Map -> Sink: Print to Std. Out (7/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.7.1
2023-07-20 11:25:34.424 [Source: Custom Source -> Map -> Sink: Print to Std. Out (7/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 61dbce85d0d41457
2023-07-20 11:25:34.424 [Source: Custom Source -> Map -> Sink: Print to Std. Out (7/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1689823534421
2023-07-20 11:25:34.648 [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/12)#0] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-flink-2, groupId=flink] Cluster ID: qYheim3NRmyUgYYzRu7BeQ
2023-07-20 11:25:34.648 [Source: Custom Source -> Map -> Sink: Print to Std. Out (12/12)#0] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-flink-5, groupId=flink] Cluster ID: qYheim3NRmyUgYYzRu7BeQ
2023-07-20 11:25:34.648 [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/12)#0] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-flink-8, groupId=flink] Cluster ID: qYheim3NRmyUgYYzRu7BeQ
2023-07-20 11:25:34.648 [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/12)#0] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-flink-11, groupId=flink] Cluster ID: qYheim3NRmyUgYYzRu7BeQ
2023-07-20 11:25:34.648 [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/12)#0] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-flink-3, groupId=flink] Cluster ID: qYheim3NRmyUgYYzRu7BeQ
2023-07-20 11:25:34.648 [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/12)#0] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-flink-9, groupId=flink] Cluster ID: qYheim3NRmyUgYYzRu7BeQ
2023-07-20 11:25:34.648 [Source: Custom Source -> Map -> Sink: Print to Std. Out (7/12)#0] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-flink-10, groupId=flink] Cluster ID: qYheim3NRmyUgYYzRu7BeQ
2023-07-20 11:25:34.648 [Source: Custom Source -> Map -> Sink: Print to Std. Out (9/12)#0] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-flink-6, groupId=flink] Cluster ID: qYheim3NRmyUgYYzRu7BeQ
2023-07-20 11:25:34.648 [Source: Custom Source -> Map -> Sink: Print to Std. Out (10/12)#0] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-flink-7, groupId=flink] Cluster ID: qYheim3NRmyUgYYzRu7BeQ
2023-07-20 11:25:34.648 [Source: Custom Source -> Map -> Sink: Print to Std. Out (8/12)#0] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-flink-12, groupId=flink] Cluster ID: qYheim3NRmyUgYYzRu7BeQ
2023-07-20 11:25:34.648 [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/12)#0] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-flink-4, groupId=flink] Cluster ID: qYheim3NRmyUgYYzRu7BeQ
2023-07-20 11:25:34.648 [Source: Custom Source -> Map -> Sink: Print to Std. Out (11/12)#0] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-flink-1, groupId=flink] Cluster ID: qYheim3NRmyUgYYzRu7BeQ
2023-07-20 11:25:34.652 [Source: Custom Source -> Map -> Sink: Print to Std. Out (8/12)#0] INFO  o.a.f.s.connectors.kafka.FlinkKafkaConsumerBase - Consumer subtask 7 initially has no partitions to read from.
2023-07-20 11:25:34.652 [Source: Custom Source -> Map -> Sink: Print to Std. Out (10/12)#0] INFO  o.a.f.s.connectors.kafka.FlinkKafkaConsumerBase - Consumer subtask 9 initially has no partitions to read from.
2023-07-20 11:25:34.652 [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/12)#0] INFO  o.a.f.s.connectors.kafka.FlinkKafkaConsumerBase - Consumer subtask 5 initially has no partitions to read from.
2023-07-20 11:25:34.652 [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/12)#0] INFO  o.a.f.s.connectors.kafka.FlinkKafkaConsumerBase - Consumer subtask 4 initially has no partitions to read from.
2023-07-20 11:25:34.652 [Source: Custom Source -> Map -> Sink: Print to Std. Out (11/12)#0] INFO  o.a.f.s.connectors.kafka.FlinkKafkaConsumerBase - Consumer subtask 10 initially has no partitions to read from.
2023-07-20 11:25:34.652 [Source: Custom Source -> Map -> Sink: Print to Std. Out (7/12)#0] INFO  o.a.f.s.connectors.kafka.FlinkKafkaConsumerBase - Consumer subtask 6 will start reading the following 1 partitions from the committed group offsets in Kafka: [KafkaTopicPartition{topic='topic001', partition=0}]
2023-07-20 11:25:34.652 [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/12)#0] INFO  o.a.f.s.connectors.kafka.FlinkKafkaConsumerBase - Consumer subtask 2 initially has no partitions to read from.
2023-07-20 11:25:34.652 [Source: Custom Source -> Map -> Sink: Print to Std. Out (12/12)#0] INFO  o.a.f.s.connectors.kafka.FlinkKafkaConsumerBase - Consumer subtask 11 initially has no partitions to read from.
2023-07-20 11:25:34.652 [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/12)#0] INFO  o.a.f.s.connectors.kafka.FlinkKafkaConsumerBase - Consumer subtask 0 initially has no partitions to read from.
2023-07-20 11:25:34.652 [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/12)#0] INFO  o.a.f.s.connectors.kafka.FlinkKafkaConsumerBase - Consumer subtask 1 initially has no partitions to read from.
2023-07-20 11:25:34.652 [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/12)#0] INFO  o.a.f.s.connectors.kafka.FlinkKafkaConsumerBase - Consumer subtask 3 initially has no partitions to read from.
2023-07-20 11:25:34.652 [Source: Custom Source -> Map -> Sink: Print to Std. Out (9/12)#0] INFO  o.a.f.s.connectors.kafka.FlinkKafkaConsumerBase - Consumer subtask 8 initially has no partitions to read from.
2023-07-20 11:25:34.657 [Legacy Source Thread - Source: Custom Source -> Map -> Sink: Print to Std. Out (4/12)#0] INFO  o.a.f.s.connectors.kafka.FlinkKafkaConsumerBase - Consumer subtask 3 creating fetcher with offsets {}.
2023-07-20 11:25:34.657 [Legacy Source Thread - Source: Custom Source -> Map -> Sink: Print to Std. Out (1/12)#0] INFO  o.a.f.s.connectors.kafka.FlinkKafkaConsumerBase - Consumer subtask 0 creating fetcher with offsets {}.
2023-07-20 11:25:34.657 [Legacy Source Thread - Source: Custom Source -> Map -> Sink: Print to Std. Out (3/12)#0] INFO  o.a.f.s.connectors.kafka.FlinkKafkaConsumerBase - Consumer subtask 2 creating fetcher with offsets {}.
2023-07-20 11:25:34.657 [Legacy Source Thread - Source: Custom Source -> Map -> Sink: Print to Std. Out (9/12)#0] INFO  o.a.f.s.connectors.kafka.FlinkKafkaConsumerBase - Consumer subtask 8 creating fetcher with offsets {}.
2023-07-20 11:25:34.657 [Legacy Source Thread - Source: Custom Source -> Map -> Sink: Print to Std. Out (2/12)#0] INFO  o.a.f.s.connectors.kafka.FlinkKafkaConsumerBase - Consumer subtask 1 creating fetcher with offsets {}.
2023-07-20 11:25:34.657 [Legacy Source Thread - Source: Custom Source -> Map -> Sink: Print to Std. Out (11/12)#0] INFO  o.a.f.s.connectors.kafka.FlinkKafkaConsumerBase - Consumer subtask 10 creating fetcher with offsets {}.
2023-07-20 11:25:34.657 [Legacy Source Thread - Source: Custom Source -> Map -> Sink: Print to Std. Out (5/12)#0] INFO  o.a.f.s.connectors.kafka.FlinkKafkaConsumerBase - Consumer subtask 4 creating fetcher with offsets {}.
2023-07-20 11:25:34.657 [Legacy Source Thread - Source: Custom Source -> Map -> Sink: Print to Std. Out (10/12)#0] INFO  o.a.f.s.connectors.kafka.FlinkKafkaConsumerBase - Consumer subtask 9 creating fetcher with offsets {}.
2023-07-20 11:25:34.657 [Legacy Source Thread - Source: Custom Source -> Map -> Sink: Print to Std. Out (7/12)#0] INFO  o.a.f.s.connectors.kafka.FlinkKafkaConsumerBase - Consumer subtask 6 creating fetcher with offsets {KafkaTopicPartition{topic='topic001', partition=0}=-915623761773}.
2023-07-20 11:25:34.657 [Legacy Source Thread - Source: Custom Source -> Map -> Sink: Print to Std. Out (12/12)#0] INFO  o.a.f.s.connectors.kafka.FlinkKafkaConsumerBase - Consumer subtask 11 creating fetcher with offsets {}.
2023-07-20 11:25:34.657 [Legacy Source Thread - Source: Custom Source -> Map -> Sink: Print to Std. Out (8/12)#0] INFO  o.a.f.s.connectors.kafka.FlinkKafkaConsumerBase - Consumer subtask 7 creating fetcher with offsets {}.
2023-07-20 11:25:34.657 [Legacy Source Thread - Source: Custom Source -> Map -> Sink: Print to Std. Out (6/12)#0] INFO  o.a.f.s.connectors.kafka.FlinkKafkaConsumerBase - Consumer subtask 5 creating fetcher with offsets {}.
2023-07-20 11:25:34.662 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (9/12)#0] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-flink-15
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2023-07-20 11:25:34.662 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (7/12)#0] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-flink-18
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2023-07-20 11:25:34.662 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (1/12)#0] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-flink-19
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2023-07-20 11:25:34.662 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (11/12)#0] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-flink-20
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2023-07-20 11:25:34.662 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (10/12)#0] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-flink-23
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2023-07-20 11:25:34.662 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (6/12)#0] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-flink-16
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2023-07-20 11:25:34.662 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (3/12)#0] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-flink-17
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2023-07-20 11:25:34.662 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (2/12)#0] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-flink-13
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2023-07-20 11:25:34.662 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (4/12)#0] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-flink-14
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2023-07-20 11:25:34.662 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (5/12)#0] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-flink-21
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2023-07-20 11:25:34.662 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (12/12)#0] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-flink-22
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2023-07-20 11:25:34.662 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (8/12)#0] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-flink-24
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2023-07-20 11:25:34.677 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (7/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.7.1
2023-07-20 11:25:34.677 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (7/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 61dbce85d0d41457
2023-07-20 11:25:34.677 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (7/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1689823534677
2023-07-20 11:25:34.678 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (6/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.7.1
2023-07-20 11:25:34.678 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (6/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 61dbce85d0d41457
2023-07-20 11:25:34.678 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (6/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1689823534678
2023-07-20 11:25:34.678 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (2/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.7.1
2023-07-20 11:25:34.678 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (2/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 61dbce85d0d41457
2023-07-20 11:25:34.678 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (2/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1689823534677
2023-07-20 11:25:34.679 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (8/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.7.1
2023-07-20 11:25:34.679 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (8/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 61dbce85d0d41457
2023-07-20 11:25:34.679 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (8/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1689823534677
2023-07-20 11:25:34.679 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (5/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.7.1
2023-07-20 11:25:34.679 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (5/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 61dbce85d0d41457
2023-07-20 11:25:34.679 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (5/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1689823534677
2023-07-20 11:25:34.679 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (11/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.7.1
2023-07-20 11:25:34.679 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (11/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 61dbce85d0d41457
2023-07-20 11:25:34.679 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (11/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1689823534679
2023-07-20 11:25:34.679 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (9/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.7.1
2023-07-20 11:25:34.679 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (9/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 61dbce85d0d41457
2023-07-20 11:25:34.679 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (9/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1689823534679
2023-07-20 11:25:34.680 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (10/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.7.1
2023-07-20 11:25:34.680 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (10/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 61dbce85d0d41457
2023-07-20 11:25:34.680 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (10/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1689823534679
2023-07-20 11:25:34.680 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (12/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.7.1
2023-07-20 11:25:34.680 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (12/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 61dbce85d0d41457
2023-07-20 11:25:34.680 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (12/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1689823534679
2023-07-20 11:25:34.680 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (1/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.7.1
2023-07-20 11:25:34.680 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (1/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 61dbce85d0d41457
2023-07-20 11:25:34.680 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (1/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1689823534678
2023-07-20 11:25:34.680 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (3/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.7.1
2023-07-20 11:25:34.680 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (3/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 61dbce85d0d41457
2023-07-20 11:25:34.680 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (3/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1689823534678
2023-07-20 11:25:34.680 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (4/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.7.1
2023-07-20 11:25:34.680 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (4/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 61dbce85d0d41457
2023-07-20 11:25:34.680 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (4/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1689823534679
2023-07-20 11:25:34.685 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (7/12)#0] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-flink-18, groupId=flink] Subscribed to partition(s): topic001-0
2023-07-20 11:25:34.694 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (7/12)#0] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-flink-18, groupId=flink] Cluster ID: qYheim3NRmyUgYYzRu7BeQ
2023-07-20 11:25:34.695 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (7/12)#0] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-flink-18, groupId=flink] Discovered group coordinator localhost:9092 (id: 2147483647 rack: null)
2023-07-20 11:25:34.700 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (7/12)#0] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-flink-18, groupId=flink] Setting offset for partition topic001-0 to the committed offset FetchPosition{offset=2, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 0 rack: null)], epoch=0}}
2023-07-20 11:26:04.595 [PermanentBlobCache shutdown hook] INFO  org.apache.flink.runtime.blob.PermanentBlobCache - Shutting down BLOB cache
2023-07-20 11:26:04.595 [TransientBlobCache shutdown hook] INFO  org.apache.flink.runtime.blob.TransientBlobCache - Shutting down BLOB cache
2023-07-20 11:26:04.596 [TaskExecutorLocalStateStoresManager shutdown hook] INFO  o.a.f.r.state.TaskExecutorLocalStateStoresManager - Shutting down TaskExecutorLocalStateStoresManager.
2023-07-20 11:26:04.599 [FileCache shutdown hook] INFO  org.apache.flink.runtime.filecache.FileCache - removed file cache directory C:\Users\DELL\AppData\Local\Temp\flink-dist-cache-965353f3-b7a4-440e-ab65-93c6e12a389c
2023-07-20 11:26:04.600 [FileChannelManagerImpl-io shutdown hook] INFO  o.a.flink.runtime.io.disk.FileChannelManagerImpl - FileChannelManager removed spill file directory C:\Users\DELL\AppData\Local\Temp\flink-io-3e595dfa-97fb-4723-9d00-552e9a3b2bfc
2023-07-20 11:26:04.600 [FileChannelManagerImpl-netty-shuffle shutdown hook] INFO  o.a.flink.runtime.io.disk.FileChannelManagerImpl - FileChannelManager removed spill file directory C:\Users\DELL\AppData\Local\Temp\flink-netty-shuffle-5967d670-c686-44cb-88e7-c1ee40be4959
2023-07-20 11:26:04.600 [BlobServer shutdown hook] INFO  org.apache.flink.runtime.blob.BlobServer - Stopped BLOB server at 0.0.0.0:64896
2023-07-20 13:32:06.572 [main] INFO  o.a.f.r.taskexecutor.TaskExecutorResourceUtils - The configuration option taskmanager.cpu.cores required for local execution is not set, setting it to the maximal possible value.
2023-07-20 13:32:06.576 [main] INFO  o.a.f.r.taskexecutor.TaskExecutorResourceUtils - The configuration option taskmanager.memory.task.heap.size required for local execution is not set, setting it to the maximal possible value.
2023-07-20 13:32:06.576 [main] INFO  o.a.f.r.taskexecutor.TaskExecutorResourceUtils - The configuration option taskmanager.memory.task.off-heap.size required for local execution is not set, setting it to the maximal possible value.
2023-07-20 13:32:06.577 [main] INFO  o.a.f.r.taskexecutor.TaskExecutorResourceUtils - The configuration option taskmanager.memory.network.min required for local execution is not set, setting it to its default value 64 mb.
2023-07-20 13:32:06.577 [main] INFO  o.a.f.r.taskexecutor.TaskExecutorResourceUtils - The configuration option taskmanager.memory.network.max required for local execution is not set, setting it to its default value 64 mb.
2023-07-20 13:32:06.577 [main] INFO  o.a.f.r.taskexecutor.TaskExecutorResourceUtils - The configuration option taskmanager.memory.managed.size required for local execution is not set, setting it to its default value 128 mb.
2023-07-20 13:32:06.719 [main] INFO  org.apache.flink.runtime.minicluster.MiniCluster - Starting Flink Mini Cluster
2023-07-20 13:32:06.721 [main] INFO  org.apache.flink.runtime.minicluster.MiniCluster - Starting Metrics Registry
2023-07-20 13:32:06.757 [main] INFO  o.apache.flink.runtime.metrics.MetricRegistryImpl - No metrics reporter configured, no metrics will be exposed/reported.
2023-07-20 13:32:06.757 [main] INFO  org.apache.flink.runtime.minicluster.MiniCluster - Starting RPC Service(s)
2023-07-20 13:32:07.100 [main] INFO  o.a.flink.runtime.rpc.akka.AkkaRpcServiceUtils - Trying to start local actor system
2023-07-20 13:32:07.718 [flink-akka.actor.default-dispatcher-2] INFO  akka.event.slf4j.Slf4jLogger - Slf4jLogger started
2023-07-20 13:32:07.832 [main] INFO  o.a.flink.runtime.rpc.akka.AkkaRpcServiceUtils - Actor system started at akka://flink
2023-07-20 13:32:07.862 [main] INFO  o.a.flink.runtime.rpc.akka.AkkaRpcServiceUtils - Trying to start local actor system
2023-07-20 13:32:07.874 [flink-metrics-2] INFO  akka.event.slf4j.Slf4jLogger - Slf4jLogger started
2023-07-20 13:32:07.890 [main] INFO  o.a.flink.runtime.rpc.akka.AkkaRpcServiceUtils - Actor system started at akka://flink-metrics
2023-07-20 13:32:07.903 [main] INFO  org.apache.flink.runtime.rpc.akka.AkkaRpcService - Starting RPC endpoint for org.apache.flink.runtime.metrics.dump.MetricQueryService at akka://flink-metrics/user/rpc/MetricQueryService .
2023-07-20 13:32:08.019 [main] INFO  org.apache.flink.runtime.minicluster.MiniCluster - Starting high-availability services
2023-07-20 13:32:08.180 [main] INFO  org.apache.flink.runtime.blob.BlobServer - Created BLOB server storage directory C:\Users\DELL\AppData\Local\Temp\blobStore-96003701-0054-4e67-8ad5-2f5f43dacec2
2023-07-20 13:32:08.200 [main] INFO  org.apache.flink.runtime.blob.BlobServer - Started BLOB server at 0.0.0.0:51767 - max concurrent requests: 50 - max backlog: 1000
2023-07-20 13:32:08.207 [main] INFO  org.apache.flink.runtime.blob.PermanentBlobCache - Created BLOB cache storage directory C:\Users\DELL\AppData\Local\Temp\blobStore-c966a896-214a-4e88-9658-a469f0019a6b
2023-07-20 13:32:08.208 [main] INFO  org.apache.flink.runtime.blob.TransientBlobCache - Created BLOB cache storage directory C:\Users\DELL\AppData\Local\Temp\blobStore-63e09916-61cb-49ef-9930-317bcd1e2552
2023-07-20 13:32:08.209 [main] INFO  org.apache.flink.runtime.minicluster.MiniCluster - Starting 1 TaskManger(s)
2023-07-20 13:32:08.218 [main] INFO  o.a.flink.runtime.taskexecutor.TaskManagerRunner - Starting TaskManager with ResourceID: 98448656-7d3b-49bd-b2ca-4a899bb6f0e2
2023-07-20 13:32:08.249 [main] INFO  o.a.flink.runtime.taskexecutor.TaskManagerServices - Temporary file directory 'C:\Users\DELL\AppData\Local\Temp': total 237 GB, usable 96 GB (40.51% usable)
2023-07-20 13:32:08.255 [main] INFO  o.a.flink.runtime.io.disk.FileChannelManagerImpl - FileChannelManager uses directory C:\Users\DELL\AppData\Local\Temp\flink-io-d9eb96d6-eb30-4ace-906d-b42574bec575 for spill files.
2023-07-20 13:32:08.264 [main] INFO  o.a.flink.runtime.io.disk.FileChannelManagerImpl - FileChannelManager uses directory C:\Users\DELL\AppData\Local\Temp\flink-netty-shuffle-d5989633-d00a-4bee-bd62-98d5eb9a6d38 for spill files.
2023-07-20 13:32:08.292 [main] INFO  o.a.f.runtime.io.network.buffer.NetworkBufferPool - Allocated 64 MB for network buffer pool (number of memory segments: 2048, bytes per segment: 32768).
2023-07-20 13:32:08.309 [main] INFO  o.a.f.runtime.io.network.NettyShuffleEnvironment - Starting the network environment and its components.
2023-07-20 13:32:08.311 [main] INFO  o.apache.flink.runtime.taskexecutor.KvStateService - Starting the kvState service and its components.
2023-07-20 13:32:08.333 [main] INFO  org.apache.flink.runtime.rpc.akka.AkkaRpcService - Starting RPC endpoint for org.apache.flink.runtime.taskexecutor.TaskExecutor at akka://flink/user/rpc/taskmanager_0 .
2023-07-20 13:32:08.342 [flink-akka.actor.default-dispatcher-2] INFO  o.a.f.runtime.taskexecutor.DefaultJobLeaderService - Start job leader service.
2023-07-20 13:32:08.344 [flink-akka.actor.default-dispatcher-2] INFO  org.apache.flink.runtime.filecache.FileCache - User file cache uses directory C:\Users\DELL\AppData\Local\Temp\flink-dist-cache-f85646f6-04b2-452b-ab17-d3d1e4da71b4
2023-07-20 13:32:08.437 [main] INFO  o.a.f.runtime.dispatcher.DispatcherRestEndpoint - Starting rest endpoint.
2023-07-20 13:32:08.440 [main] INFO  o.a.f.runtime.dispatcher.DispatcherRestEndpoint - Failed to load web based job submission extension. Probable reason: flink-runtime-web is not in the classpath.
2023-07-20 13:32:09.125 [main] INFO  o.a.f.runtime.dispatcher.DispatcherRestEndpoint - Rest endpoint listening at localhost:51818
2023-07-20 13:32:09.126 [main] INFO  o.a.f.r.h.nonha.embedded.EmbeddedLeaderService - Proposing leadership to contender http://localhost:51818
2023-07-20 13:32:09.127 [mini-cluster-io-thread-1] INFO  o.a.f.runtime.dispatcher.DispatcherRestEndpoint - http://localhost:51818 was granted leadership with leaderSessionID=d9d522b2-ee03-47c8-807b-65baed632df1
2023-07-20 13:32:09.127 [mini-cluster-io-thread-1] INFO  o.a.f.r.h.nonha.embedded.EmbeddedLeaderService - Received confirmation of leadership for leader http://localhost:51818 , session=d9d522b2-ee03-47c8-807b-65baed632df1
2023-07-20 13:32:09.146 [main] INFO  org.apache.flink.runtime.rpc.akka.AkkaRpcService - Starting RPC endpoint for org.apache.flink.runtime.resourcemanager.StandaloneResourceManager at akka://flink/user/rpc/resourcemanager_1 .
2023-07-20 13:32:09.157 [main] INFO  o.a.f.r.h.nonha.embedded.EmbeddedLeaderService - Proposing leadership to contender LeaderContender: DefaultDispatcherRunner
2023-07-20 13:32:09.157 [flink-akka.actor.default-dispatcher-2] INFO  o.a.f.r.h.nonha.embedded.EmbeddedLeaderService - Proposing leadership to contender LeaderContender: StandaloneResourceManager
2023-07-20 13:32:09.159 [flink-akka.actor.default-dispatcher-2] INFO  o.a.f.r.resourcemanager.StandaloneResourceManager - ResourceManager akka://flink/user/rpc/resourcemanager_1 was granted leadership with fencing token aad1cf555e03d62b397c6cd0d81b4f0f
2023-07-20 13:32:09.160 [main] INFO  org.apache.flink.runtime.minicluster.MiniCluster - Flink Mini Cluster started successfully
2023-07-20 13:32:09.161 [flink-akka.actor.default-dispatcher-2] INFO  o.a.f.r.r.slotmanager.SlotManagerImpl - Starting the SlotManager.
2023-07-20 13:32:09.162 [mini-cluster-io-thread-2] INFO  o.a.f.r.d.runner.SessionDispatcherLeaderProcess - Start SessionDispatcherLeaderProcess.
2023-07-20 13:32:09.163 [mini-cluster-io-thread-5] INFO  o.a.f.r.d.runner.SessionDispatcherLeaderProcess - Recover all persisted job graphs.
2023-07-20 13:32:09.163 [mini-cluster-io-thread-5] INFO  o.a.f.r.d.runner.SessionDispatcherLeaderProcess - Successfully recovered 0 persisted job graphs.
2023-07-20 13:32:09.164 [mini-cluster-io-thread-6] INFO  o.a.f.r.h.nonha.embedded.EmbeddedLeaderService - Received confirmation of leadership for leader akka://flink/user/rpc/resourcemanager_1 , session=397c6cd0-d81b-4f0f-aad1-cf555e03d62b
2023-07-20 13:32:09.165 [flink-akka.actor.default-dispatcher-2] INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor - Connecting to ResourceManager akka://flink/user/rpc/resourcemanager_1(aad1cf555e03d62b397c6cd0d81b4f0f).
2023-07-20 13:32:09.172 [mini-cluster-io-thread-5] INFO  org.apache.flink.runtime.rpc.akka.AkkaRpcService - Starting RPC endpoint for org.apache.flink.runtime.dispatcher.StandaloneDispatcher at akka://flink/user/rpc/dispatcher_2 .
2023-07-20 13:32:09.181 [mini-cluster-io-thread-5] INFO  o.a.f.r.h.nonha.embedded.EmbeddedLeaderService - Received confirmation of leadership for leader akka://flink/user/rpc/dispatcher_2 , session=be1566f1-7c48-4608-bd0c-306bfafbc44e
2023-07-20 13:32:09.185 [flink-akka.actor.default-dispatcher-3] INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor - Resolved ResourceManager address, beginning registration
2023-07-20 13:32:09.190 [flink-akka.actor.default-dispatcher-6] INFO  o.a.f.r.resourcemanager.StandaloneResourceManager - Registering TaskManager with ResourceID 98448656-7d3b-49bd-b2ca-4a899bb6f0e2 (akka://flink/user/rpc/taskmanager_0) at ResourceManager
2023-07-20 13:32:09.192 [flink-akka.actor.default-dispatcher-3] INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor - Successful registration at resource manager akka://flink/user/rpc/resourcemanager_1 under registration id 6f18c003b622a05e217893225c9058ee.
2023-07-20 13:32:09.193 [flink-akka.actor.default-dispatcher-4] INFO  o.a.flink.runtime.dispatcher.StandaloneDispatcher - Received JobGraph submission 7d8105a9dc83a88a944faa41365a4f22 (kafka-flink-start).
2023-07-20 13:32:09.194 [flink-akka.actor.default-dispatcher-4] INFO  o.a.flink.runtime.dispatcher.StandaloneDispatcher - Submitting job 7d8105a9dc83a88a944faa41365a4f22 (kafka-flink-start).
2023-07-20 13:32:09.215 [mini-cluster-io-thread-12] INFO  o.a.f.r.h.nonha.embedded.EmbeddedLeaderService - Proposing leadership to contender LeaderContender: JobManagerRunnerImpl
2023-07-20 13:32:09.223 [mini-cluster-io-thread-12] INFO  org.apache.flink.runtime.rpc.akka.AkkaRpcService - Starting RPC endpoint for org.apache.flink.runtime.jobmaster.JobMaster at akka://flink/user/rpc/jobmanager_3 .
2023-07-20 13:32:09.229 [mini-cluster-io-thread-12] INFO  org.apache.flink.runtime.jobmaster.JobMaster - Initializing job kafka-flink-start (7d8105a9dc83a88a944faa41365a4f22).
2023-07-20 13:32:09.257 [mini-cluster-io-thread-12] INFO  org.apache.flink.runtime.jobmaster.JobMaster - Using restart back off time strategy NoRestartBackoffTimeStrategy for kafka-flink-start (7d8105a9dc83a88a944faa41365a4f22).
2023-07-20 13:32:09.290 [mini-cluster-io-thread-12] INFO  org.apache.flink.runtime.jobmaster.JobMaster - Running initialization on master for job kafka-flink-start (7d8105a9dc83a88a944faa41365a4f22).
2023-07-20 13:32:09.290 [mini-cluster-io-thread-12] INFO  org.apache.flink.runtime.jobmaster.JobMaster - Successfully ran initialization on master in 0 ms.
2023-07-20 13:32:09.300 [mini-cluster-io-thread-12] INFO  o.a.f.r.scheduler.adapter.DefaultExecutionTopology - Built 12 pipelined regions in 0 ms
2023-07-20 13:32:09.313 [mini-cluster-io-thread-12] INFO  org.apache.flink.runtime.jobmaster.JobMaster - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2023-07-20 13:32:09.326 [mini-cluster-io-thread-12] INFO  o.a.flink.runtime.checkpoint.CheckpointCoordinator - No checkpoint found during restore.
2023-07-20 13:32:09.327 [mini-cluster-io-thread-12] INFO  org.apache.flink.runtime.jobmaster.JobMaster - Using failover strategy org.apache.flink.runtime.executiongraph.failover.flip1.RestartPipelinedRegionFailoverStrategy@699de71 for kafka-flink-start (7d8105a9dc83a88a944faa41365a4f22).
2023-07-20 13:32:09.334 [mini-cluster-io-thread-12] INFO  o.a.flink.runtime.jobmaster.JobManagerRunnerImpl - JobManager runner for job kafka-flink-start (7d8105a9dc83a88a944faa41365a4f22) was granted leadership with session id f9e2a8cc-685f-4fcb-b15a-e427f067a933 at akka://flink/user/rpc/jobmanager_3.
2023-07-20 13:32:09.335 [flink-akka.actor.default-dispatcher-4] INFO  org.apache.flink.runtime.jobmaster.JobMaster - Starting execution of job kafka-flink-start (7d8105a9dc83a88a944faa41365a4f22) under job master id b15ae427f067a933f9e2a8cc685f4fcb.
2023-07-20 13:32:09.336 [flink-akka.actor.default-dispatcher-4] INFO  org.apache.flink.runtime.jobmaster.JobMaster - Starting scheduling with scheduling strategy [org.apache.flink.runtime.scheduler.strategy.PipelinedRegionSchedulingStrategy]
2023-07-20 13:32:09.337 [flink-akka.actor.default-dispatcher-4] INFO  o.a.flink.runtime.executiongraph.ExecutionGraph - Job kafka-flink-start (7d8105a9dc83a88a944faa41365a4f22) switched from state CREATED to RUNNING.
2023-07-20 13:32:09.340 [flink-akka.actor.default-dispatcher-4] INFO  o.a.flink.runtime.executiongraph.ExecutionGraph - Source: Custom Source -> Map -> Sink: Print to Std. Out (1/12) (439e158f53f0da7b90b5b208ab804aee) switched from CREATED to SCHEDULED.
2023-07-20 13:32:09.348 [flink-akka.actor.default-dispatcher-4] INFO  o.a.flink.runtime.jobmaster.slotpool.SlotPoolImpl - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{79495f6e4224f214667f2ee2460e508c}]
2023-07-20 13:32:09.353 [flink-akka.actor.default-dispatcher-4] INFO  o.a.flink.runtime.executiongraph.ExecutionGraph - Source: Custom Source -> Map -> Sink: Print to Std. Out (2/12) (93772b2f0da1c8ff36cdfe9eb6ef6060) switched from CREATED to SCHEDULED.
2023-07-20 13:32:09.353 [flink-akka.actor.default-dispatcher-4] INFO  o.a.flink.runtime.jobmaster.slotpool.SlotPoolImpl - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{16d492f1ed40191ee736b5cd113ed427}]
2023-07-20 13:32:09.354 [flink-akka.actor.default-dispatcher-4] INFO  o.a.flink.runtime.executiongraph.ExecutionGraph - Source: Custom Source -> Map -> Sink: Print to Std. Out (3/12) (4d95c331cf3f03b2fc423c4f9b4135ba) switched from CREATED to SCHEDULED.
2023-07-20 13:32:09.354 [flink-akka.actor.default-dispatcher-4] INFO  o.a.flink.runtime.jobmaster.slotpool.SlotPoolImpl - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{8f8bf3cf148eab8ee9feb2dce7dd47a2}]
2023-07-20 13:32:09.354 [flink-akka.actor.default-dispatcher-4] INFO  o.a.flink.runtime.executiongraph.ExecutionGraph - Source: Custom Source -> Map -> Sink: Print to Std. Out (4/12) (142ca053d79c836e770127960c42f756) switched from CREATED to SCHEDULED.
2023-07-20 13:32:09.354 [flink-akka.actor.default-dispatcher-4] INFO  o.a.flink.runtime.jobmaster.slotpool.SlotPoolImpl - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{fe65018d217cdcaee9afbbbe8d078a05}]
2023-07-20 13:32:09.355 [flink-akka.actor.default-dispatcher-4] INFO  o.a.flink.runtime.executiongraph.ExecutionGraph - Source: Custom Source -> Map -> Sink: Print to Std. Out (5/12) (c8a15616da2c761f6b90c7e95f702d4f) switched from CREATED to SCHEDULED.
2023-07-20 13:32:09.355 [flink-akka.actor.default-dispatcher-4] INFO  o.a.flink.runtime.jobmaster.slotpool.SlotPoolImpl - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{b2a1b97763b6843acaeba382ebe275ee}]
2023-07-20 13:32:09.356 [flink-akka.actor.default-dispatcher-4] INFO  o.a.flink.runtime.executiongraph.ExecutionGraph - Source: Custom Source -> Map -> Sink: Print to Std. Out (6/12) (35ad28c1f3f23875aeca7962b4dc2e54) switched from CREATED to SCHEDULED.
2023-07-20 13:32:09.356 [flink-akka.actor.default-dispatcher-4] INFO  o.a.flink.runtime.jobmaster.slotpool.SlotPoolImpl - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{24d10b1b3103b8e20dda431db71e400f}]
2023-07-20 13:32:09.356 [flink-akka.actor.default-dispatcher-4] INFO  o.a.flink.runtime.executiongraph.ExecutionGraph - Source: Custom Source -> Map -> Sink: Print to Std. Out (7/12) (eb5d69acb13eb6d5cf1b6ca598bf6bbf) switched from CREATED to SCHEDULED.
2023-07-20 13:32:09.356 [flink-akka.actor.default-dispatcher-4] INFO  o.a.flink.runtime.jobmaster.slotpool.SlotPoolImpl - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{2ab95ccbd92e3acbf286d1e6583825ad}]
2023-07-20 13:32:09.356 [flink-akka.actor.default-dispatcher-4] INFO  o.a.flink.runtime.executiongraph.ExecutionGraph - Source: Custom Source -> Map -> Sink: Print to Std. Out (8/12) (7506d3bc6d1d69903872c0fc8c84eae6) switched from CREATED to SCHEDULED.
2023-07-20 13:32:09.357 [flink-akka.actor.default-dispatcher-4] INFO  o.a.flink.runtime.jobmaster.slotpool.SlotPoolImpl - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{f75f20237839ae0f6d5fce194ad36b23}]
2023-07-20 13:32:09.357 [flink-akka.actor.default-dispatcher-4] INFO  o.a.flink.runtime.executiongraph.ExecutionGraph - Source: Custom Source -> Map -> Sink: Print to Std. Out (9/12) (8073ac279e1860562cf49cc107257faf) switched from CREATED to SCHEDULED.
2023-07-20 13:32:09.357 [flink-akka.actor.default-dispatcher-4] INFO  o.a.flink.runtime.jobmaster.slotpool.SlotPoolImpl - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{28997679f078a538379b755671c3aa5d}]
2023-07-20 13:32:09.357 [flink-akka.actor.default-dispatcher-4] INFO  o.a.flink.runtime.executiongraph.ExecutionGraph - Source: Custom Source -> Map -> Sink: Print to Std. Out (10/12) (53ccab84936d10ec6c1be7fd33639c69) switched from CREATED to SCHEDULED.
2023-07-20 13:32:09.357 [flink-akka.actor.default-dispatcher-4] INFO  o.a.flink.runtime.jobmaster.slotpool.SlotPoolImpl - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{1fe6e5703d487bc93d82cd214ca2715d}]
2023-07-20 13:32:09.358 [flink-akka.actor.default-dispatcher-4] INFO  o.a.flink.runtime.executiongraph.ExecutionGraph - Source: Custom Source -> Map -> Sink: Print to Std. Out (11/12) (f938f2fed132dd1d206a8d540853cada) switched from CREATED to SCHEDULED.
2023-07-20 13:32:09.358 [flink-akka.actor.default-dispatcher-4] INFO  o.a.flink.runtime.jobmaster.slotpool.SlotPoolImpl - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{28741b67de7e00b52ae53b64360a30ba}]
2023-07-20 13:32:09.358 [flink-akka.actor.default-dispatcher-4] INFO  o.a.flink.runtime.executiongraph.ExecutionGraph - Source: Custom Source -> Map -> Sink: Print to Std. Out (12/12) (443191e6ec8f83ed33626521aacb2294) switched from CREATED to SCHEDULED.
2023-07-20 13:32:09.358 [flink-akka.actor.default-dispatcher-4] INFO  o.a.flink.runtime.jobmaster.slotpool.SlotPoolImpl - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{7886c40953ccf0e6dc36aee8fbd07a1c}]
2023-07-20 13:32:09.359 [jobmanager-future-thread-1] INFO  o.a.f.r.h.nonha.embedded.EmbeddedLeaderService - Received confirmation of leadership for leader akka://flink/user/rpc/jobmanager_3 , session=f9e2a8cc-685f-4fcb-b15a-e427f067a933
2023-07-20 13:32:09.359 [flink-akka.actor.default-dispatcher-4] INFO  org.apache.flink.runtime.jobmaster.JobMaster - Connecting to ResourceManager akka://flink/user/rpc/resourcemanager_1(aad1cf555e03d62b397c6cd0d81b4f0f)
2023-07-20 13:32:09.360 [flink-akka.actor.default-dispatcher-2] INFO  org.apache.flink.runtime.jobmaster.JobMaster - Resolved ResourceManager address, beginning registration
2023-07-20 13:32:09.361 [flink-akka.actor.default-dispatcher-3] INFO  o.a.f.r.resourcemanager.StandaloneResourceManager - Registering job manager b15ae427f067a933f9e2a8cc685f4fcb@akka://flink/user/rpc/jobmanager_3 for job 7d8105a9dc83a88a944faa41365a4f22.
2023-07-20 13:32:09.364 [flink-akka.actor.default-dispatcher-6] INFO  o.a.f.r.resourcemanager.StandaloneResourceManager - Registered job manager b15ae427f067a933f9e2a8cc685f4fcb@akka://flink/user/rpc/jobmanager_3 for job 7d8105a9dc83a88a944faa41365a4f22.
2023-07-20 13:32:09.365 [flink-akka.actor.default-dispatcher-6] INFO  org.apache.flink.runtime.jobmaster.JobMaster - JobManager successfully registered at ResourceManager, leader id: aad1cf555e03d62b397c6cd0d81b4f0f.
2023-07-20 13:32:09.366 [flink-akka.actor.default-dispatcher-6] INFO  o.a.flink.runtime.jobmaster.slotpool.SlotPoolImpl - Requesting new slot [SlotRequestId{79495f6e4224f214667f2ee2460e508c}] and profile ResourceProfile{UNKNOWN} with allocation id f0be6cbf7eb441b7091a57e133d98ec1 from resource manager.
2023-07-20 13:32:09.367 [flink-akka.actor.default-dispatcher-3] INFO  o.a.f.r.resourcemanager.StandaloneResourceManager - Request slot with profile ResourceProfile{UNKNOWN} for job 7d8105a9dc83a88a944faa41365a4f22 with allocation id f0be6cbf7eb441b7091a57e133d98ec1.
2023-07-20 13:32:09.367 [flink-akka.actor.default-dispatcher-6] INFO  o.a.flink.runtime.jobmaster.slotpool.SlotPoolImpl - Requesting new slot [SlotRequestId{16d492f1ed40191ee736b5cd113ed427}] and profile ResourceProfile{UNKNOWN} with allocation id 2b591626384e147b65286cfba3239550 from resource manager.
2023-07-20 13:32:09.367 [flink-akka.actor.default-dispatcher-6] INFO  o.a.flink.runtime.jobmaster.slotpool.SlotPoolImpl - Requesting new slot [SlotRequestId{8f8bf3cf148eab8ee9feb2dce7dd47a2}] and profile ResourceProfile{UNKNOWN} with allocation id 97dd793948b93b7b935bf05fa95f3dfb from resource manager.
2023-07-20 13:32:09.367 [flink-akka.actor.default-dispatcher-6] INFO  o.a.flink.runtime.jobmaster.slotpool.SlotPoolImpl - Requesting new slot [SlotRequestId{fe65018d217cdcaee9afbbbe8d078a05}] and profile ResourceProfile{UNKNOWN} with allocation id f3184b2410536fb074a078df8c3aa301 from resource manager.
2023-07-20 13:32:09.368 [flink-akka.actor.default-dispatcher-6] INFO  o.a.flink.runtime.jobmaster.slotpool.SlotPoolImpl - Requesting new slot [SlotRequestId{b2a1b97763b6843acaeba382ebe275ee}] and profile ResourceProfile{UNKNOWN} with allocation id 360c27e91afb63f4839994de1fc513b0 from resource manager.
2023-07-20 13:32:09.368 [flink-akka.actor.default-dispatcher-6] INFO  o.a.flink.runtime.jobmaster.slotpool.SlotPoolImpl - Requesting new slot [SlotRequestId{24d10b1b3103b8e20dda431db71e400f}] and profile ResourceProfile{UNKNOWN} with allocation id 7033c3632df93bb221330ceca2eacc3e from resource manager.
2023-07-20 13:32:09.368 [flink-akka.actor.default-dispatcher-6] INFO  o.a.flink.runtime.jobmaster.slotpool.SlotPoolImpl - Requesting new slot [SlotRequestId{2ab95ccbd92e3acbf286d1e6583825ad}] and profile ResourceProfile{UNKNOWN} with allocation id 1ec7a6868b6b38dce3202cb77153d6d9 from resource manager.
2023-07-20 13:32:09.368 [flink-akka.actor.default-dispatcher-6] INFO  o.a.flink.runtime.jobmaster.slotpool.SlotPoolImpl - Requesting new slot [SlotRequestId{f75f20237839ae0f6d5fce194ad36b23}] and profile ResourceProfile{UNKNOWN} with allocation id fd4bfced12fad522898c3620842769fc from resource manager.
2023-07-20 13:32:09.369 [flink-akka.actor.default-dispatcher-6] INFO  o.a.flink.runtime.jobmaster.slotpool.SlotPoolImpl - Requesting new slot [SlotRequestId{28997679f078a538379b755671c3aa5d}] and profile ResourceProfile{UNKNOWN} with allocation id 2cef368e232dba6050bc62abc1765803 from resource manager.
2023-07-20 13:32:09.370 [flink-akka.actor.default-dispatcher-6] INFO  o.a.flink.runtime.jobmaster.slotpool.SlotPoolImpl - Requesting new slot [SlotRequestId{1fe6e5703d487bc93d82cd214ca2715d}] and profile ResourceProfile{UNKNOWN} with allocation id d98a81cf3be94e573486171dbb246401 from resource manager.
2023-07-20 13:32:09.370 [flink-akka.actor.default-dispatcher-6] INFO  o.a.flink.runtime.jobmaster.slotpool.SlotPoolImpl - Requesting new slot [SlotRequestId{28741b67de7e00b52ae53b64360a30ba}] and profile ResourceProfile{UNKNOWN} with allocation id 30a161be48f6c59f64822d6013518fd1 from resource manager.
2023-07-20 13:32:09.371 [flink-akka.actor.default-dispatcher-6] INFO  o.a.flink.runtime.jobmaster.slotpool.SlotPoolImpl - Requesting new slot [SlotRequestId{7886c40953ccf0e6dc36aee8fbd07a1c}] and profile ResourceProfile{UNKNOWN} with allocation id 10cde49a45c0f1dcb31078a9f2c1b76a from resource manager.
2023-07-20 13:32:09.371 [flink-akka.actor.default-dispatcher-2] INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor - Receive slot request f0be6cbf7eb441b7091a57e133d98ec1 for job 7d8105a9dc83a88a944faa41365a4f22 from resource manager with leader id aad1cf555e03d62b397c6cd0d81b4f0f.
2023-07-20 13:32:09.372 [flink-akka.actor.default-dispatcher-3] INFO  o.a.f.r.resourcemanager.StandaloneResourceManager - Request slot with profile ResourceProfile{UNKNOWN} for job 7d8105a9dc83a88a944faa41365a4f22 with allocation id 2b591626384e147b65286cfba3239550.
2023-07-20 13:32:09.372 [flink-akka.actor.default-dispatcher-3] INFO  o.a.f.r.resourcemanager.StandaloneResourceManager - Request slot with profile ResourceProfile{UNKNOWN} for job 7d8105a9dc83a88a944faa41365a4f22 with allocation id 97dd793948b93b7b935bf05fa95f3dfb.
2023-07-20 13:32:09.373 [flink-akka.actor.default-dispatcher-3] INFO  o.a.f.r.resourcemanager.StandaloneResourceManager - Request slot with profile ResourceProfile{UNKNOWN} for job 7d8105a9dc83a88a944faa41365a4f22 with allocation id f3184b2410536fb074a078df8c3aa301.
2023-07-20 13:32:09.373 [flink-akka.actor.default-dispatcher-3] INFO  o.a.f.r.resourcemanager.StandaloneResourceManager - Request slot with profile ResourceProfile{UNKNOWN} for job 7d8105a9dc83a88a944faa41365a4f22 with allocation id 360c27e91afb63f4839994de1fc513b0.
2023-07-20 13:32:09.373 [flink-akka.actor.default-dispatcher-3] INFO  o.a.f.r.resourcemanager.StandaloneResourceManager - Request slot with profile ResourceProfile{UNKNOWN} for job 7d8105a9dc83a88a944faa41365a4f22 with allocation id 7033c3632df93bb221330ceca2eacc3e.
2023-07-20 13:32:09.374 [flink-akka.actor.default-dispatcher-3] INFO  o.a.f.r.resourcemanager.StandaloneResourceManager - Request slot with profile ResourceProfile{UNKNOWN} for job 7d8105a9dc83a88a944faa41365a4f22 with allocation id 1ec7a6868b6b38dce3202cb77153d6d9.
2023-07-20 13:32:09.374 [flink-akka.actor.default-dispatcher-3] INFO  o.a.f.r.resourcemanager.StandaloneResourceManager - Request slot with profile ResourceProfile{UNKNOWN} for job 7d8105a9dc83a88a944faa41365a4f22 with allocation id fd4bfced12fad522898c3620842769fc.
2023-07-20 13:32:09.374 [flink-akka.actor.default-dispatcher-3] INFO  o.a.f.r.resourcemanager.StandaloneResourceManager - Request slot with profile ResourceProfile{UNKNOWN} for job 7d8105a9dc83a88a944faa41365a4f22 with allocation id 2cef368e232dba6050bc62abc1765803.
2023-07-20 13:32:09.374 [flink-akka.actor.default-dispatcher-3] INFO  o.a.f.r.resourcemanager.StandaloneResourceManager - Request slot with profile ResourceProfile{UNKNOWN} for job 7d8105a9dc83a88a944faa41365a4f22 with allocation id d98a81cf3be94e573486171dbb246401.
2023-07-20 13:32:09.375 [flink-akka.actor.default-dispatcher-3] INFO  o.a.f.r.resourcemanager.StandaloneResourceManager - Request slot with profile ResourceProfile{UNKNOWN} for job 7d8105a9dc83a88a944faa41365a4f22 with allocation id 30a161be48f6c59f64822d6013518fd1.
2023-07-20 13:32:09.375 [flink-akka.actor.default-dispatcher-3] INFO  o.a.f.r.resourcemanager.StandaloneResourceManager - Request slot with profile ResourceProfile{UNKNOWN} for job 7d8105a9dc83a88a944faa41365a4f22 with allocation id 10cde49a45c0f1dcb31078a9f2c1b76a.
2023-07-20 13:32:09.376 [flink-akka.actor.default-dispatcher-2] INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor - Allocated slot for f0be6cbf7eb441b7091a57e133d98ec1.
2023-07-20 13:32:09.377 [flink-akka.actor.default-dispatcher-2] INFO  o.a.f.runtime.taskexecutor.DefaultJobLeaderService - Add job 7d8105a9dc83a88a944faa41365a4f22 for job leader monitoring.
2023-07-20 13:32:09.378 [mini-cluster-io-thread-18] INFO  o.a.f.runtime.taskexecutor.DefaultJobLeaderService - Try to register at job manager akka://flink/user/rpc/jobmanager_3 with leader id f9e2a8cc-685f-4fcb-b15a-e427f067a933.
2023-07-20 13:32:09.378 [flink-akka.actor.default-dispatcher-2] INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor - Receive slot request 2b591626384e147b65286cfba3239550 for job 7d8105a9dc83a88a944faa41365a4f22 from resource manager with leader id aad1cf555e03d62b397c6cd0d81b4f0f.
2023-07-20 13:32:09.379 [flink-akka.actor.default-dispatcher-2] INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor - Allocated slot for 2b591626384e147b65286cfba3239550.
2023-07-20 13:32:09.379 [flink-akka.actor.default-dispatcher-2] INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor - Receive slot request 97dd793948b93b7b935bf05fa95f3dfb for job 7d8105a9dc83a88a944faa41365a4f22 from resource manager with leader id aad1cf555e03d62b397c6cd0d81b4f0f.
2023-07-20 13:32:09.379 [flink-akka.actor.default-dispatcher-3] INFO  o.a.f.runtime.taskexecutor.DefaultJobLeaderService - Resolved JobManager address, beginning registration
2023-07-20 13:32:09.379 [flink-akka.actor.default-dispatcher-2] INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor - Allocated slot for 97dd793948b93b7b935bf05fa95f3dfb.
2023-07-20 13:32:09.379 [flink-akka.actor.default-dispatcher-2] INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor - Receive slot request f3184b2410536fb074a078df8c3aa301 for job 7d8105a9dc83a88a944faa41365a4f22 from resource manager with leader id aad1cf555e03d62b397c6cd0d81b4f0f.
2023-07-20 13:32:09.380 [flink-akka.actor.default-dispatcher-2] INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor - Allocated slot for f3184b2410536fb074a078df8c3aa301.
2023-07-20 13:32:09.380 [flink-akka.actor.default-dispatcher-2] INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor - Receive slot request 360c27e91afb63f4839994de1fc513b0 for job 7d8105a9dc83a88a944faa41365a4f22 from resource manager with leader id aad1cf555e03d62b397c6cd0d81b4f0f.
2023-07-20 13:32:09.380 [flink-akka.actor.default-dispatcher-2] INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor - Allocated slot for 360c27e91afb63f4839994de1fc513b0.
2023-07-20 13:32:09.380 [flink-akka.actor.default-dispatcher-2] INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor - Receive slot request 7033c3632df93bb221330ceca2eacc3e for job 7d8105a9dc83a88a944faa41365a4f22 from resource manager with leader id aad1cf555e03d62b397c6cd0d81b4f0f.
2023-07-20 13:32:09.380 [flink-akka.actor.default-dispatcher-2] INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor - Allocated slot for 7033c3632df93bb221330ceca2eacc3e.
2023-07-20 13:32:09.380 [flink-akka.actor.default-dispatcher-2] INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor - Receive slot request 1ec7a6868b6b38dce3202cb77153d6d9 for job 7d8105a9dc83a88a944faa41365a4f22 from resource manager with leader id aad1cf555e03d62b397c6cd0d81b4f0f.
2023-07-20 13:32:09.380 [flink-akka.actor.default-dispatcher-2] INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor - Allocated slot for 1ec7a6868b6b38dce3202cb77153d6d9.
2023-07-20 13:32:09.381 [flink-akka.actor.default-dispatcher-2] INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor - Receive slot request fd4bfced12fad522898c3620842769fc for job 7d8105a9dc83a88a944faa41365a4f22 from resource manager with leader id aad1cf555e03d62b397c6cd0d81b4f0f.
2023-07-20 13:32:09.381 [flink-akka.actor.default-dispatcher-2] INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor - Allocated slot for fd4bfced12fad522898c3620842769fc.
2023-07-20 13:32:09.381 [flink-akka.actor.default-dispatcher-2] INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor - Receive slot request 2cef368e232dba6050bc62abc1765803 for job 7d8105a9dc83a88a944faa41365a4f22 from resource manager with leader id aad1cf555e03d62b397c6cd0d81b4f0f.
2023-07-20 13:32:09.381 [flink-akka.actor.default-dispatcher-2] INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor - Allocated slot for 2cef368e232dba6050bc62abc1765803.
2023-07-20 13:32:09.381 [flink-akka.actor.default-dispatcher-2] INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor - Receive slot request d98a81cf3be94e573486171dbb246401 for job 7d8105a9dc83a88a944faa41365a4f22 from resource manager with leader id aad1cf555e03d62b397c6cd0d81b4f0f.
2023-07-20 13:32:09.381 [flink-akka.actor.default-dispatcher-2] INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor - Allocated slot for d98a81cf3be94e573486171dbb246401.
2023-07-20 13:32:09.381 [flink-akka.actor.default-dispatcher-2] INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor - Receive slot request 30a161be48f6c59f64822d6013518fd1 for job 7d8105a9dc83a88a944faa41365a4f22 from resource manager with leader id aad1cf555e03d62b397c6cd0d81b4f0f.
2023-07-20 13:32:09.381 [flink-akka.actor.default-dispatcher-2] INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor - Allocated slot for 30a161be48f6c59f64822d6013518fd1.
2023-07-20 13:32:09.382 [flink-akka.actor.default-dispatcher-2] INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor - Receive slot request 10cde49a45c0f1dcb31078a9f2c1b76a for job 7d8105a9dc83a88a944faa41365a4f22 from resource manager with leader id aad1cf555e03d62b397c6cd0d81b4f0f.
2023-07-20 13:32:09.382 [flink-akka.actor.default-dispatcher-2] INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor - Allocated slot for 10cde49a45c0f1dcb31078a9f2c1b76a.
2023-07-20 13:32:09.383 [flink-akka.actor.default-dispatcher-6] INFO  o.a.f.runtime.taskexecutor.DefaultJobLeaderService - Successful registration at job manager akka://flink/user/rpc/jobmanager_3 for job 7d8105a9dc83a88a944faa41365a4f22.
2023-07-20 13:32:09.383 [flink-akka.actor.default-dispatcher-6] INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor - Establish JobManager connection for job 7d8105a9dc83a88a944faa41365a4f22.
2023-07-20 13:32:09.386 [flink-akka.actor.default-dispatcher-6] INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor - Offer reserved slots to the leader of job 7d8105a9dc83a88a944faa41365a4f22.
2023-07-20 13:32:09.392 [flink-akka.actor.default-dispatcher-4] INFO  o.a.flink.runtime.executiongraph.ExecutionGraph - Source: Custom Source -> Map -> Sink: Print to Std. Out (1/12) (439e158f53f0da7b90b5b208ab804aee) switched from SCHEDULED to DEPLOYING.
2023-07-20 13:32:09.392 [flink-akka.actor.default-dispatcher-4] INFO  o.a.flink.runtime.executiongraph.ExecutionGraph - Deploying Source: Custom Source -> Map -> Sink: Print to Std. Out (1/12) (attempt #0) with attempt id 439e158f53f0da7b90b5b208ab804aee to 98448656-7d3b-49bd-b2ca-4a899bb6f0e2 @ activate.navicat.com (dataPort=-1) with allocation id 7033c3632df93bb221330ceca2eacc3e
2023-07-20 13:32:09.396 [flink-akka.actor.default-dispatcher-4] INFO  o.a.flink.runtime.executiongraph.ExecutionGraph - Source: Custom Source -> Map -> Sink: Print to Std. Out (2/12) (93772b2f0da1c8ff36cdfe9eb6ef6060) switched from SCHEDULED to DEPLOYING.
2023-07-20 13:32:09.396 [flink-akka.actor.default-dispatcher-4] INFO  o.a.flink.runtime.executiongraph.ExecutionGraph - Deploying Source: Custom Source -> Map -> Sink: Print to Std. Out (2/12) (attempt #0) with attempt id 93772b2f0da1c8ff36cdfe9eb6ef6060 to 98448656-7d3b-49bd-b2ca-4a899bb6f0e2 @ activate.navicat.com (dataPort=-1) with allocation id f0be6cbf7eb441b7091a57e133d98ec1
2023-07-20 13:32:09.396 [flink-akka.actor.default-dispatcher-6] INFO  o.a.f.runtime.taskexecutor.slot.TaskSlotTableImpl - Activate slot 7033c3632df93bb221330ceca2eacc3e.
2023-07-20 13:32:09.396 [flink-akka.actor.default-dispatcher-4] INFO  o.a.flink.runtime.executiongraph.ExecutionGraph - Source: Custom Source -> Map -> Sink: Print to Std. Out (3/12) (4d95c331cf3f03b2fc423c4f9b4135ba) switched from SCHEDULED to DEPLOYING.
2023-07-20 13:32:09.396 [flink-akka.actor.default-dispatcher-4] INFO  o.a.flink.runtime.executiongraph.ExecutionGraph - Deploying Source: Custom Source -> Map -> Sink: Print to Std. Out (3/12) (attempt #0) with attempt id 4d95c331cf3f03b2fc423c4f9b4135ba to 98448656-7d3b-49bd-b2ca-4a899bb6f0e2 @ activate.navicat.com (dataPort=-1) with allocation id 30a161be48f6c59f64822d6013518fd1
2023-07-20 13:32:09.396 [flink-akka.actor.default-dispatcher-4] INFO  o.a.flink.runtime.executiongraph.ExecutionGraph - Source: Custom Source -> Map -> Sink: Print to Std. Out (4/12) (142ca053d79c836e770127960c42f756) switched from SCHEDULED to DEPLOYING.
2023-07-20 13:32:09.397 [flink-akka.actor.default-dispatcher-4] INFO  o.a.flink.runtime.executiongraph.ExecutionGraph - Deploying Source: Custom Source -> Map -> Sink: Print to Std. Out (4/12) (attempt #0) with attempt id 142ca053d79c836e770127960c42f756 to 98448656-7d3b-49bd-b2ca-4a899bb6f0e2 @ activate.navicat.com (dataPort=-1) with allocation id d98a81cf3be94e573486171dbb246401
2023-07-20 13:32:09.397 [flink-akka.actor.default-dispatcher-4] INFO  o.a.flink.runtime.executiongraph.ExecutionGraph - Source: Custom Source -> Map -> Sink: Print to Std. Out (5/12) (c8a15616da2c761f6b90c7e95f702d4f) switched from SCHEDULED to DEPLOYING.
2023-07-20 13:32:09.397 [flink-akka.actor.default-dispatcher-4] INFO  o.a.flink.runtime.executiongraph.ExecutionGraph - Deploying Source: Custom Source -> Map -> Sink: Print to Std. Out (5/12) (attempt #0) with attempt id c8a15616da2c761f6b90c7e95f702d4f to 98448656-7d3b-49bd-b2ca-4a899bb6f0e2 @ activate.navicat.com (dataPort=-1) with allocation id 97dd793948b93b7b935bf05fa95f3dfb
2023-07-20 13:32:09.397 [flink-akka.actor.default-dispatcher-4] INFO  o.a.flink.runtime.executiongraph.ExecutionGraph - Source: Custom Source -> Map -> Sink: Print to Std. Out (6/12) (35ad28c1f3f23875aeca7962b4dc2e54) switched from SCHEDULED to DEPLOYING.
2023-07-20 13:32:09.397 [flink-akka.actor.default-dispatcher-4] INFO  o.a.flink.runtime.executiongraph.ExecutionGraph - Deploying Source: Custom Source -> Map -> Sink: Print to Std. Out (6/12) (attempt #0) with attempt id 35ad28c1f3f23875aeca7962b4dc2e54 to 98448656-7d3b-49bd-b2ca-4a899bb6f0e2 @ activate.navicat.com (dataPort=-1) with allocation id 360c27e91afb63f4839994de1fc513b0
2023-07-20 13:32:09.397 [flink-akka.actor.default-dispatcher-4] INFO  o.a.flink.runtime.executiongraph.ExecutionGraph - Source: Custom Source -> Map -> Sink: Print to Std. Out (7/12) (eb5d69acb13eb6d5cf1b6ca598bf6bbf) switched from SCHEDULED to DEPLOYING.
2023-07-20 13:32:09.398 [flink-akka.actor.default-dispatcher-4] INFO  o.a.flink.runtime.executiongraph.ExecutionGraph - Deploying Source: Custom Source -> Map -> Sink: Print to Std. Out (7/12) (attempt #0) with attempt id eb5d69acb13eb6d5cf1b6ca598bf6bbf to 98448656-7d3b-49bd-b2ca-4a899bb6f0e2 @ activate.navicat.com (dataPort=-1) with allocation id fd4bfced12fad522898c3620842769fc
2023-07-20 13:32:09.398 [flink-akka.actor.default-dispatcher-4] INFO  o.a.flink.runtime.executiongraph.ExecutionGraph - Source: Custom Source -> Map -> Sink: Print to Std. Out (8/12) (7506d3bc6d1d69903872c0fc8c84eae6) switched from SCHEDULED to DEPLOYING.
2023-07-20 13:32:09.398 [flink-akka.actor.default-dispatcher-4] INFO  o.a.flink.runtime.executiongraph.ExecutionGraph - Deploying Source: Custom Source -> Map -> Sink: Print to Std. Out (8/12) (attempt #0) with attempt id 7506d3bc6d1d69903872c0fc8c84eae6 to 98448656-7d3b-49bd-b2ca-4a899bb6f0e2 @ activate.navicat.com (dataPort=-1) with allocation id 10cde49a45c0f1dcb31078a9f2c1b76a
2023-07-20 13:32:09.398 [flink-akka.actor.default-dispatcher-4] INFO  o.a.flink.runtime.executiongraph.ExecutionGraph - Source: Custom Source -> Map -> Sink: Print to Std. Out (9/12) (8073ac279e1860562cf49cc107257faf) switched from SCHEDULED to DEPLOYING.
2023-07-20 13:32:09.398 [flink-akka.actor.default-dispatcher-4] INFO  o.a.flink.runtime.executiongraph.ExecutionGraph - Deploying Source: Custom Source -> Map -> Sink: Print to Std. Out (9/12) (attempt #0) with attempt id 8073ac279e1860562cf49cc107257faf to 98448656-7d3b-49bd-b2ca-4a899bb6f0e2 @ activate.navicat.com (dataPort=-1) with allocation id 2b591626384e147b65286cfba3239550
2023-07-20 13:32:09.398 [flink-akka.actor.default-dispatcher-4] INFO  o.a.flink.runtime.executiongraph.ExecutionGraph - Source: Custom Source -> Map -> Sink: Print to Std. Out (10/12) (53ccab84936d10ec6c1be7fd33639c69) switched from SCHEDULED to DEPLOYING.
2023-07-20 13:32:09.398 [flink-akka.actor.default-dispatcher-4] INFO  o.a.flink.runtime.executiongraph.ExecutionGraph - Deploying Source: Custom Source -> Map -> Sink: Print to Std. Out (10/12) (attempt #0) with attempt id 53ccab84936d10ec6c1be7fd33639c69 to 98448656-7d3b-49bd-b2ca-4a899bb6f0e2 @ activate.navicat.com (dataPort=-1) with allocation id f3184b2410536fb074a078df8c3aa301
2023-07-20 13:32:09.398 [flink-akka.actor.default-dispatcher-4] INFO  o.a.flink.runtime.executiongraph.ExecutionGraph - Source: Custom Source -> Map -> Sink: Print to Std. Out (11/12) (f938f2fed132dd1d206a8d540853cada) switched from SCHEDULED to DEPLOYING.
2023-07-20 13:32:09.398 [flink-akka.actor.default-dispatcher-4] INFO  o.a.flink.runtime.executiongraph.ExecutionGraph - Deploying Source: Custom Source -> Map -> Sink: Print to Std. Out (11/12) (attempt #0) with attempt id f938f2fed132dd1d206a8d540853cada to 98448656-7d3b-49bd-b2ca-4a899bb6f0e2 @ activate.navicat.com (dataPort=-1) with allocation id 1ec7a6868b6b38dce3202cb77153d6d9
2023-07-20 13:32:09.399 [flink-akka.actor.default-dispatcher-4] INFO  o.a.flink.runtime.executiongraph.ExecutionGraph - Source: Custom Source -> Map -> Sink: Print to Std. Out (12/12) (443191e6ec8f83ed33626521aacb2294) switched from SCHEDULED to DEPLOYING.
2023-07-20 13:32:09.399 [flink-akka.actor.default-dispatcher-4] INFO  o.a.flink.runtime.executiongraph.ExecutionGraph - Deploying Source: Custom Source -> Map -> Sink: Print to Std. Out (12/12) (attempt #0) with attempt id 443191e6ec8f83ed33626521aacb2294 to 98448656-7d3b-49bd-b2ca-4a899bb6f0e2 @ activate.navicat.com (dataPort=-1) with allocation id 2cef368e232dba6050bc62abc1765803
2023-07-20 13:32:09.417 [flink-akka.actor.default-dispatcher-6] INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor - Received task Source: Custom Source -> Map -> Sink: Print to Std. Out (1/12)#0 (439e158f53f0da7b90b5b208ab804aee), deploy into slot with allocation id 7033c3632df93bb221330ceca2eacc3e.
2023-07-20 13:32:09.419 [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/12)#0] INFO  org.apache.flink.runtime.taskmanager.Task - Source: Custom Source -> Map -> Sink: Print to Std. Out (1/12)#0 (439e158f53f0da7b90b5b208ab804aee) switched from CREATED to DEPLOYING.
2023-07-20 13:32:09.421 [flink-akka.actor.default-dispatcher-6] INFO  o.a.f.runtime.taskexecutor.slot.TaskSlotTableImpl - Activate slot f0be6cbf7eb441b7091a57e133d98ec1.
2023-07-20 13:32:09.423 [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/12)#0] INFO  org.apache.flink.runtime.taskmanager.Task - Loading JAR files for task Source: Custom Source -> Map -> Sink: Print to Std. Out (1/12)#0 (439e158f53f0da7b90b5b208ab804aee) [DEPLOYING].
2023-07-20 13:32:09.424 [flink-akka.actor.default-dispatcher-6] INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor - Received task Source: Custom Source -> Map -> Sink: Print to Std. Out (2/12)#0 (93772b2f0da1c8ff36cdfe9eb6ef6060), deploy into slot with allocation id f0be6cbf7eb441b7091a57e133d98ec1.
2023-07-20 13:32:09.424 [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/12)#0] INFO  org.apache.flink.runtime.taskmanager.Task - Source: Custom Source -> Map -> Sink: Print to Std. Out (2/12)#0 (93772b2f0da1c8ff36cdfe9eb6ef6060) switched from CREATED to DEPLOYING.
2023-07-20 13:32:09.424 [flink-akka.actor.default-dispatcher-6] INFO  o.a.f.runtime.taskexecutor.slot.TaskSlotTableImpl - Activate slot 30a161be48f6c59f64822d6013518fd1.
2023-07-20 13:32:09.424 [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/12)#0] INFO  org.apache.flink.runtime.taskmanager.Task - Loading JAR files for task Source: Custom Source -> Map -> Sink: Print to Std. Out (2/12)#0 (93772b2f0da1c8ff36cdfe9eb6ef6060) [DEPLOYING].
2023-07-20 13:32:09.424 [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/12)#0] INFO  org.apache.flink.runtime.taskmanager.Task - Registering task at network: Source: Custom Source -> Map -> Sink: Print to Std. Out (1/12)#0 (439e158f53f0da7b90b5b208ab804aee) [DEPLOYING].
2023-07-20 13:32:09.425 [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/12)#0] INFO  org.apache.flink.runtime.taskmanager.Task - Registering task at network: Source: Custom Source -> Map -> Sink: Print to Std. Out (2/12)#0 (93772b2f0da1c8ff36cdfe9eb6ef6060) [DEPLOYING].
2023-07-20 13:32:09.426 [flink-akka.actor.default-dispatcher-6] INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor - Received task Source: Custom Source -> Map -> Sink: Print to Std. Out (3/12)#0 (4d95c331cf3f03b2fc423c4f9b4135ba), deploy into slot with allocation id 30a161be48f6c59f64822d6013518fd1.
2023-07-20 13:32:09.426 [flink-akka.actor.default-dispatcher-6] INFO  o.a.f.runtime.taskexecutor.slot.TaskSlotTableImpl - Activate slot d98a81cf3be94e573486171dbb246401.
2023-07-20 13:32:09.426 [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/12)#0] INFO  org.apache.flink.runtime.taskmanager.Task - Source: Custom Source -> Map -> Sink: Print to Std. Out (3/12)#0 (4d95c331cf3f03b2fc423c4f9b4135ba) switched from CREATED to DEPLOYING.
2023-07-20 13:32:09.426 [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/12)#0] INFO  org.apache.flink.runtime.taskmanager.Task - Loading JAR files for task Source: Custom Source -> Map -> Sink: Print to Std. Out (3/12)#0 (4d95c331cf3f03b2fc423c4f9b4135ba) [DEPLOYING].
2023-07-20 13:32:09.427 [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/12)#0] INFO  org.apache.flink.runtime.taskmanager.Task - Registering task at network: Source: Custom Source -> Map -> Sink: Print to Std. Out (3/12)#0 (4d95c331cf3f03b2fc423c4f9b4135ba) [DEPLOYING].
2023-07-20 13:32:09.427 [flink-akka.actor.default-dispatcher-6] INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor - Received task Source: Custom Source -> Map -> Sink: Print to Std. Out (4/12)#0 (142ca053d79c836e770127960c42f756), deploy into slot with allocation id d98a81cf3be94e573486171dbb246401.
2023-07-20 13:32:09.428 [flink-akka.actor.default-dispatcher-6] INFO  o.a.f.runtime.taskexecutor.slot.TaskSlotTableImpl - Activate slot 97dd793948b93b7b935bf05fa95f3dfb.
2023-07-20 13:32:09.428 [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/12)#0] INFO  org.apache.flink.runtime.taskmanager.Task - Source: Custom Source -> Map -> Sink: Print to Std. Out (4/12)#0 (142ca053d79c836e770127960c42f756) switched from CREATED to DEPLOYING.
2023-07-20 13:32:09.428 [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/12)#0] INFO  org.apache.flink.runtime.taskmanager.Task - Loading JAR files for task Source: Custom Source -> Map -> Sink: Print to Std. Out (4/12)#0 (142ca053d79c836e770127960c42f756) [DEPLOYING].
2023-07-20 13:32:09.428 [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/12)#0] INFO  org.apache.flink.runtime.taskmanager.Task - Registering task at network: Source: Custom Source -> Map -> Sink: Print to Std. Out (4/12)#0 (142ca053d79c836e770127960c42f756) [DEPLOYING].
2023-07-20 13:32:09.429 [flink-akka.actor.default-dispatcher-6] INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor - Received task Source: Custom Source -> Map -> Sink: Print to Std. Out (5/12)#0 (c8a15616da2c761f6b90c7e95f702d4f), deploy into slot with allocation id 97dd793948b93b7b935bf05fa95f3dfb.
2023-07-20 13:32:09.429 [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/12)#0] INFO  org.apache.flink.runtime.taskmanager.Task - Source: Custom Source -> Map -> Sink: Print to Std. Out (5/12)#0 (c8a15616da2c761f6b90c7e95f702d4f) switched from CREATED to DEPLOYING.
2023-07-20 13:32:09.429 [flink-akka.actor.default-dispatcher-6] INFO  o.a.f.runtime.taskexecutor.slot.TaskSlotTableImpl - Activate slot 360c27e91afb63f4839994de1fc513b0.
2023-07-20 13:32:09.429 [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/12)#0] INFO  org.apache.flink.runtime.taskmanager.Task - Loading JAR files for task Source: Custom Source -> Map -> Sink: Print to Std. Out (5/12)#0 (c8a15616da2c761f6b90c7e95f702d4f) [DEPLOYING].
2023-07-20 13:32:09.430 [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/12)#0] INFO  org.apache.flink.runtime.taskmanager.Task - Registering task at network: Source: Custom Source -> Map -> Sink: Print to Std. Out (5/12)#0 (c8a15616da2c761f6b90c7e95f702d4f) [DEPLOYING].
2023-07-20 13:32:09.431 [flink-akka.actor.default-dispatcher-6] INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor - Received task Source: Custom Source -> Map -> Sink: Print to Std. Out (6/12)#0 (35ad28c1f3f23875aeca7962b4dc2e54), deploy into slot with allocation id 360c27e91afb63f4839994de1fc513b0.
2023-07-20 13:32:09.431 [flink-akka.actor.default-dispatcher-6] INFO  o.a.f.runtime.taskexecutor.slot.TaskSlotTableImpl - Activate slot fd4bfced12fad522898c3620842769fc.
2023-07-20 13:32:09.431 [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/12)#0] INFO  org.apache.flink.runtime.taskmanager.Task - Source: Custom Source -> Map -> Sink: Print to Std. Out (6/12)#0 (35ad28c1f3f23875aeca7962b4dc2e54) switched from CREATED to DEPLOYING.
2023-07-20 13:32:09.431 [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/12)#0] INFO  org.apache.flink.runtime.taskmanager.Task - Loading JAR files for task Source: Custom Source -> Map -> Sink: Print to Std. Out (6/12)#0 (35ad28c1f3f23875aeca7962b4dc2e54) [DEPLOYING].
2023-07-20 13:32:09.432 [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/12)#0] INFO  org.apache.flink.runtime.taskmanager.Task - Registering task at network: Source: Custom Source -> Map -> Sink: Print to Std. Out (6/12)#0 (35ad28c1f3f23875aeca7962b4dc2e54) [DEPLOYING].
2023-07-20 13:32:09.434 [flink-akka.actor.default-dispatcher-6] INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor - Received task Source: Custom Source -> Map -> Sink: Print to Std. Out (7/12)#0 (eb5d69acb13eb6d5cf1b6ca598bf6bbf), deploy into slot with allocation id fd4bfced12fad522898c3620842769fc.
2023-07-20 13:32:09.435 [Source: Custom Source -> Map -> Sink: Print to Std. Out (7/12)#0] INFO  org.apache.flink.runtime.taskmanager.Task - Source: Custom Source -> Map -> Sink: Print to Std. Out (7/12)#0 (eb5d69acb13eb6d5cf1b6ca598bf6bbf) switched from CREATED to DEPLOYING.
2023-07-20 13:32:09.435 [flink-akka.actor.default-dispatcher-6] INFO  o.a.f.runtime.taskexecutor.slot.TaskSlotTableImpl - Activate slot 10cde49a45c0f1dcb31078a9f2c1b76a.
2023-07-20 13:32:09.435 [Source: Custom Source -> Map -> Sink: Print to Std. Out (7/12)#0] INFO  org.apache.flink.runtime.taskmanager.Task - Loading JAR files for task Source: Custom Source -> Map -> Sink: Print to Std. Out (7/12)#0 (eb5d69acb13eb6d5cf1b6ca598bf6bbf) [DEPLOYING].
2023-07-20 13:32:09.436 [Source: Custom Source -> Map -> Sink: Print to Std. Out (7/12)#0] INFO  org.apache.flink.runtime.taskmanager.Task - Registering task at network: Source: Custom Source -> Map -> Sink: Print to Std. Out (7/12)#0 (eb5d69acb13eb6d5cf1b6ca598bf6bbf) [DEPLOYING].
2023-07-20 13:32:09.438 [flink-akka.actor.default-dispatcher-6] INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor - Received task Source: Custom Source -> Map -> Sink: Print to Std. Out (8/12)#0 (7506d3bc6d1d69903872c0fc8c84eae6), deploy into slot with allocation id 10cde49a45c0f1dcb31078a9f2c1b76a.
2023-07-20 13:32:09.438 [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/12)#0] INFO  o.apache.flink.streaming.runtime.tasks.StreamTask - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2023-07-20 13:32:09.438 [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/12)#0] INFO  o.apache.flink.streaming.runtime.tasks.StreamTask - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2023-07-20 13:32:09.438 [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/12)#0] INFO  o.apache.flink.streaming.runtime.tasks.StreamTask - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2023-07-20 13:32:09.438 [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/12)#0] INFO  o.apache.flink.streaming.runtime.tasks.StreamTask - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2023-07-20 13:32:09.438 [Source: Custom Source -> Map -> Sink: Print to Std. Out (7/12)#0] INFO  o.apache.flink.streaming.runtime.tasks.StreamTask - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2023-07-20 13:32:09.438 [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/12)#0] INFO  o.apache.flink.streaming.runtime.tasks.StreamTask - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2023-07-20 13:32:09.438 [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/12)#0] INFO  o.apache.flink.streaming.runtime.tasks.StreamTask - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2023-07-20 13:32:09.439 [Source: Custom Source -> Map -> Sink: Print to Std. Out (8/12)#0] INFO  org.apache.flink.runtime.taskmanager.Task - Source: Custom Source -> Map -> Sink: Print to Std. Out (8/12)#0 (7506d3bc6d1d69903872c0fc8c84eae6) switched from CREATED to DEPLOYING.
2023-07-20 13:32:09.439 [flink-akka.actor.default-dispatcher-6] INFO  o.a.f.runtime.taskexecutor.slot.TaskSlotTableImpl - Activate slot 2b591626384e147b65286cfba3239550.
2023-07-20 13:32:09.439 [Source: Custom Source -> Map -> Sink: Print to Std. Out (8/12)#0] INFO  org.apache.flink.runtime.taskmanager.Task - Loading JAR files for task Source: Custom Source -> Map -> Sink: Print to Std. Out (8/12)#0 (7506d3bc6d1d69903872c0fc8c84eae6) [DEPLOYING].
2023-07-20 13:32:09.439 [Source: Custom Source -> Map -> Sink: Print to Std. Out (8/12)#0] INFO  org.apache.flink.runtime.taskmanager.Task - Registering task at network: Source: Custom Source -> Map -> Sink: Print to Std. Out (8/12)#0 (7506d3bc6d1d69903872c0fc8c84eae6) [DEPLOYING].
2023-07-20 13:32:09.439 [Source: Custom Source -> Map -> Sink: Print to Std. Out (8/12)#0] INFO  o.apache.flink.streaming.runtime.tasks.StreamTask - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2023-07-20 13:32:09.441 [flink-akka.actor.default-dispatcher-6] INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor - Received task Source: Custom Source -> Map -> Sink: Print to Std. Out (9/12)#0 (8073ac279e1860562cf49cc107257faf), deploy into slot with allocation id 2b591626384e147b65286cfba3239550.
2023-07-20 13:32:09.441 [Source: Custom Source -> Map -> Sink: Print to Std. Out (9/12)#0] INFO  org.apache.flink.runtime.taskmanager.Task - Source: Custom Source -> Map -> Sink: Print to Std. Out (9/12)#0 (8073ac279e1860562cf49cc107257faf) switched from CREATED to DEPLOYING.
2023-07-20 13:32:09.441 [flink-akka.actor.default-dispatcher-6] INFO  o.a.f.runtime.taskexecutor.slot.TaskSlotTableImpl - Activate slot f3184b2410536fb074a078df8c3aa301.
2023-07-20 13:32:09.441 [Source: Custom Source -> Map -> Sink: Print to Std. Out (9/12)#0] INFO  org.apache.flink.runtime.taskmanager.Task - Loading JAR files for task Source: Custom Source -> Map -> Sink: Print to Std. Out (9/12)#0 (8073ac279e1860562cf49cc107257faf) [DEPLOYING].
2023-07-20 13:32:09.442 [Source: Custom Source -> Map -> Sink: Print to Std. Out (9/12)#0] INFO  org.apache.flink.runtime.taskmanager.Task - Registering task at network: Source: Custom Source -> Map -> Sink: Print to Std. Out (9/12)#0 (8073ac279e1860562cf49cc107257faf) [DEPLOYING].
2023-07-20 13:32:09.442 [Source: Custom Source -> Map -> Sink: Print to Std. Out (9/12)#0] INFO  o.apache.flink.streaming.runtime.tasks.StreamTask - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2023-07-20 13:32:09.443 [flink-akka.actor.default-dispatcher-6] INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor - Received task Source: Custom Source -> Map -> Sink: Print to Std. Out (10/12)#0 (53ccab84936d10ec6c1be7fd33639c69), deploy into slot with allocation id f3184b2410536fb074a078df8c3aa301.
2023-07-20 13:32:09.443 [Source: Custom Source -> Map -> Sink: Print to Std. Out (10/12)#0] INFO  org.apache.flink.runtime.taskmanager.Task - Source: Custom Source -> Map -> Sink: Print to Std. Out (10/12)#0 (53ccab84936d10ec6c1be7fd33639c69) switched from CREATED to DEPLOYING.
2023-07-20 13:32:09.443 [flink-akka.actor.default-dispatcher-6] INFO  o.a.f.runtime.taskexecutor.slot.TaskSlotTableImpl - Activate slot 1ec7a6868b6b38dce3202cb77153d6d9.
2023-07-20 13:32:09.444 [Source: Custom Source -> Map -> Sink: Print to Std. Out (10/12)#0] INFO  org.apache.flink.runtime.taskmanager.Task - Loading JAR files for task Source: Custom Source -> Map -> Sink: Print to Std. Out (10/12)#0 (53ccab84936d10ec6c1be7fd33639c69) [DEPLOYING].
2023-07-20 13:32:09.444 [Source: Custom Source -> Map -> Sink: Print to Std. Out (10/12)#0] INFO  org.apache.flink.runtime.taskmanager.Task - Registering task at network: Source: Custom Source -> Map -> Sink: Print to Std. Out (10/12)#0 (53ccab84936d10ec6c1be7fd33639c69) [DEPLOYING].
2023-07-20 13:32:09.445 [Source: Custom Source -> Map -> Sink: Print to Std. Out (10/12)#0] INFO  o.apache.flink.streaming.runtime.tasks.StreamTask - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2023-07-20 13:32:09.445 [flink-akka.actor.default-dispatcher-6] INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor - Received task Source: Custom Source -> Map -> Sink: Print to Std. Out (11/12)#0 (f938f2fed132dd1d206a8d540853cada), deploy into slot with allocation id 1ec7a6868b6b38dce3202cb77153d6d9.
2023-07-20 13:32:09.446 [Source: Custom Source -> Map -> Sink: Print to Std. Out (11/12)#0] INFO  org.apache.flink.runtime.taskmanager.Task - Source: Custom Source -> Map -> Sink: Print to Std. Out (11/12)#0 (f938f2fed132dd1d206a8d540853cada) switched from CREATED to DEPLOYING.
2023-07-20 13:32:09.446 [flink-akka.actor.default-dispatcher-6] INFO  o.a.f.runtime.taskexecutor.slot.TaskSlotTableImpl - Activate slot 2cef368e232dba6050bc62abc1765803.
2023-07-20 13:32:09.446 [Source: Custom Source -> Map -> Sink: Print to Std. Out (11/12)#0] INFO  org.apache.flink.runtime.taskmanager.Task - Loading JAR files for task Source: Custom Source -> Map -> Sink: Print to Std. Out (11/12)#0 (f938f2fed132dd1d206a8d540853cada) [DEPLOYING].
2023-07-20 13:32:09.446 [Source: Custom Source -> Map -> Sink: Print to Std. Out (9/12)#0] INFO  org.apache.flink.runtime.taskmanager.Task - Source: Custom Source -> Map -> Sink: Print to Std. Out (9/12)#0 (8073ac279e1860562cf49cc107257faf) switched from DEPLOYING to RUNNING.
2023-07-20 13:32:09.446 [Source: Custom Source -> Map -> Sink: Print to Std. Out (10/12)#0] INFO  org.apache.flink.runtime.taskmanager.Task - Source: Custom Source -> Map -> Sink: Print to Std. Out (10/12)#0 (53ccab84936d10ec6c1be7fd33639c69) switched from DEPLOYING to RUNNING.
2023-07-20 13:32:09.446 [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/12)#0] INFO  org.apache.flink.runtime.taskmanager.Task - Source: Custom Source -> Map -> Sink: Print to Std. Out (3/12)#0 (4d95c331cf3f03b2fc423c4f9b4135ba) switched from DEPLOYING to RUNNING.
2023-07-20 13:32:09.446 [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/12)#0] INFO  org.apache.flink.runtime.taskmanager.Task - Source: Custom Source -> Map -> Sink: Print to Std. Out (4/12)#0 (142ca053d79c836e770127960c42f756) switched from DEPLOYING to RUNNING.
2023-07-20 13:32:09.446 [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/12)#0] INFO  org.apache.flink.runtime.taskmanager.Task - Source: Custom Source -> Map -> Sink: Print to Std. Out (5/12)#0 (c8a15616da2c761f6b90c7e95f702d4f) switched from DEPLOYING to RUNNING.
2023-07-20 13:32:09.446 [Source: Custom Source -> Map -> Sink: Print to Std. Out (8/12)#0] INFO  org.apache.flink.runtime.taskmanager.Task - Source: Custom Source -> Map -> Sink: Print to Std. Out (8/12)#0 (7506d3bc6d1d69903872c0fc8c84eae6) switched from DEPLOYING to RUNNING.
2023-07-20 13:32:09.446 [Source: Custom Source -> Map -> Sink: Print to Std. Out (7/12)#0] INFO  org.apache.flink.runtime.taskmanager.Task - Source: Custom Source -> Map -> Sink: Print to Std. Out (7/12)#0 (eb5d69acb13eb6d5cf1b6ca598bf6bbf) switched from DEPLOYING to RUNNING.
2023-07-20 13:32:09.446 [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/12)#0] INFO  org.apache.flink.runtime.taskmanager.Task - Source: Custom Source -> Map -> Sink: Print to Std. Out (1/12)#0 (439e158f53f0da7b90b5b208ab804aee) switched from DEPLOYING to RUNNING.
2023-07-20 13:32:09.446 [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/12)#0] INFO  org.apache.flink.runtime.taskmanager.Task - Source: Custom Source -> Map -> Sink: Print to Std. Out (6/12)#0 (35ad28c1f3f23875aeca7962b4dc2e54) switched from DEPLOYING to RUNNING.
2023-07-20 13:32:09.446 [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/12)#0] INFO  org.apache.flink.runtime.taskmanager.Task - Source: Custom Source -> Map -> Sink: Print to Std. Out (2/12)#0 (93772b2f0da1c8ff36cdfe9eb6ef6060) switched from DEPLOYING to RUNNING.
2023-07-20 13:32:09.447 [Source: Custom Source -> Map -> Sink: Print to Std. Out (11/12)#0] INFO  org.apache.flink.runtime.taskmanager.Task - Registering task at network: Source: Custom Source -> Map -> Sink: Print to Std. Out (11/12)#0 (f938f2fed132dd1d206a8d540853cada) [DEPLOYING].
2023-07-20 13:32:09.447 [Source: Custom Source -> Map -> Sink: Print to Std. Out (11/12)#0] INFO  o.apache.flink.streaming.runtime.tasks.StreamTask - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2023-07-20 13:32:09.447 [flink-akka.actor.default-dispatcher-4] INFO  o.a.flink.runtime.executiongraph.ExecutionGraph - Source: Custom Source -> Map -> Sink: Print to Std. Out (4/12) (142ca053d79c836e770127960c42f756) switched from DEPLOYING to RUNNING.
2023-07-20 13:32:09.447 [Source: Custom Source -> Map -> Sink: Print to Std. Out (11/12)#0] INFO  org.apache.flink.runtime.taskmanager.Task - Source: Custom Source -> Map -> Sink: Print to Std. Out (11/12)#0 (f938f2fed132dd1d206a8d540853cada) switched from DEPLOYING to RUNNING.
2023-07-20 13:32:09.448 [flink-akka.actor.default-dispatcher-6] INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor - Received task Source: Custom Source -> Map -> Sink: Print to Std. Out (12/12)#0 (443191e6ec8f83ed33626521aacb2294), deploy into slot with allocation id 2cef368e232dba6050bc62abc1765803.
2023-07-20 13:32:09.448 [flink-akka.actor.default-dispatcher-4] INFO  o.a.flink.runtime.executiongraph.ExecutionGraph - Source: Custom Source -> Map -> Sink: Print to Std. Out (5/12) (c8a15616da2c761f6b90c7e95f702d4f) switched from DEPLOYING to RUNNING.
2023-07-20 13:32:09.448 [flink-akka.actor.default-dispatcher-4] INFO  o.a.flink.runtime.executiongraph.ExecutionGraph - Source: Custom Source -> Map -> Sink: Print to Std. Out (9/12) (8073ac279e1860562cf49cc107257faf) switched from DEPLOYING to RUNNING.
2023-07-20 13:32:09.448 [flink-akka.actor.default-dispatcher-4] INFO  o.a.flink.runtime.executiongraph.ExecutionGraph - Source: Custom Source -> Map -> Sink: Print to Std. Out (10/12) (53ccab84936d10ec6c1be7fd33639c69) switched from DEPLOYING to RUNNING.
2023-07-20 13:32:09.448 [flink-akka.actor.default-dispatcher-6] INFO  o.a.f.runtime.taskexecutor.slot.TaskSlotTableImpl - Activate slot 7033c3632df93bb221330ceca2eacc3e.
2023-07-20 13:32:09.448 [flink-akka.actor.default-dispatcher-6] INFO  o.a.f.runtime.taskexecutor.slot.TaskSlotTableImpl - Activate slot f0be6cbf7eb441b7091a57e133d98ec1.
2023-07-20 13:32:09.449 [flink-akka.actor.default-dispatcher-6] INFO  o.a.f.runtime.taskexecutor.slot.TaskSlotTableImpl - Activate slot 30a161be48f6c59f64822d6013518fd1.
2023-07-20 13:32:09.449 [flink-akka.actor.default-dispatcher-4] INFO  o.a.flink.runtime.executiongraph.ExecutionGraph - Source: Custom Source -> Map -> Sink: Print to Std. Out (3/12) (4d95c331cf3f03b2fc423c4f9b4135ba) switched from DEPLOYING to RUNNING.
2023-07-20 13:32:09.449 [flink-akka.actor.default-dispatcher-6] INFO  o.a.f.runtime.taskexecutor.slot.TaskSlotTableImpl - Activate slot d98a81cf3be94e573486171dbb246401.
2023-07-20 13:32:09.449 [flink-akka.actor.default-dispatcher-6] INFO  o.a.f.runtime.taskexecutor.slot.TaskSlotTableImpl - Activate slot 97dd793948b93b7b935bf05fa95f3dfb.
2023-07-20 13:32:09.449 [flink-akka.actor.default-dispatcher-6] INFO  o.a.f.runtime.taskexecutor.slot.TaskSlotTableImpl - Activate slot 360c27e91afb63f4839994de1fc513b0.
2023-07-20 13:32:09.449 [flink-akka.actor.default-dispatcher-4] INFO  o.a.flink.runtime.executiongraph.ExecutionGraph - Source: Custom Source -> Map -> Sink: Print to Std. Out (8/12) (7506d3bc6d1d69903872c0fc8c84eae6) switched from DEPLOYING to RUNNING.
2023-07-20 13:32:09.449 [flink-akka.actor.default-dispatcher-6] INFO  o.a.f.runtime.taskexecutor.slot.TaskSlotTableImpl - Activate slot fd4bfced12fad522898c3620842769fc.
2023-07-20 13:32:09.449 [flink-akka.actor.default-dispatcher-6] INFO  o.a.f.runtime.taskexecutor.slot.TaskSlotTableImpl - Activate slot 10cde49a45c0f1dcb31078a9f2c1b76a.
2023-07-20 13:32:09.449 [flink-akka.actor.default-dispatcher-6] INFO  o.a.f.runtime.taskexecutor.slot.TaskSlotTableImpl - Activate slot 2b591626384e147b65286cfba3239550.
2023-07-20 13:32:09.449 [flink-akka.actor.default-dispatcher-4] INFO  o.a.flink.runtime.executiongraph.ExecutionGraph - Source: Custom Source -> Map -> Sink: Print to Std. Out (7/12) (eb5d69acb13eb6d5cf1b6ca598bf6bbf) switched from DEPLOYING to RUNNING.
2023-07-20 13:32:09.449 [flink-akka.actor.default-dispatcher-6] INFO  o.a.f.runtime.taskexecutor.slot.TaskSlotTableImpl - Activate slot f3184b2410536fb074a078df8c3aa301.
2023-07-20 13:32:09.449 [flink-akka.actor.default-dispatcher-6] INFO  o.a.f.runtime.taskexecutor.slot.TaskSlotTableImpl - Activate slot 1ec7a6868b6b38dce3202cb77153d6d9.
2023-07-20 13:32:09.449 [Source: Custom Source -> Map -> Sink: Print to Std. Out (12/12)#0] INFO  org.apache.flink.runtime.taskmanager.Task - Source: Custom Source -> Map -> Sink: Print to Std. Out (12/12)#0 (443191e6ec8f83ed33626521aacb2294) switched from CREATED to DEPLOYING.
2023-07-20 13:32:09.449 [flink-akka.actor.default-dispatcher-6] INFO  o.a.f.runtime.taskexecutor.slot.TaskSlotTableImpl - Activate slot 2cef368e232dba6050bc62abc1765803.
2023-07-20 13:32:09.449 [flink-akka.actor.default-dispatcher-4] INFO  o.a.flink.runtime.executiongraph.ExecutionGraph - Source: Custom Source -> Map -> Sink: Print to Std. Out (1/12) (439e158f53f0da7b90b5b208ab804aee) switched from DEPLOYING to RUNNING.
2023-07-20 13:32:09.449 [flink-akka.actor.default-dispatcher-4] INFO  o.a.flink.runtime.executiongraph.ExecutionGraph - Source: Custom Source -> Map -> Sink: Print to Std. Out (6/12) (35ad28c1f3f23875aeca7962b4dc2e54) switched from DEPLOYING to RUNNING.
2023-07-20 13:32:09.449 [Source: Custom Source -> Map -> Sink: Print to Std. Out (12/12)#0] INFO  org.apache.flink.runtime.taskmanager.Task - Loading JAR files for task Source: Custom Source -> Map -> Sink: Print to Std. Out (12/12)#0 (443191e6ec8f83ed33626521aacb2294) [DEPLOYING].
2023-07-20 13:32:09.449 [flink-akka.actor.default-dispatcher-4] INFO  o.a.flink.runtime.executiongraph.ExecutionGraph - Source: Custom Source -> Map -> Sink: Print to Std. Out (2/12) (93772b2f0da1c8ff36cdfe9eb6ef6060) switched from DEPLOYING to RUNNING.
2023-07-20 13:32:09.450 [flink-akka.actor.default-dispatcher-4] INFO  o.a.flink.runtime.executiongraph.ExecutionGraph - Source: Custom Source -> Map -> Sink: Print to Std. Out (11/12) (f938f2fed132dd1d206a8d540853cada) switched from DEPLOYING to RUNNING.
2023-07-20 13:32:09.451 [Source: Custom Source -> Map -> Sink: Print to Std. Out (12/12)#0] INFO  org.apache.flink.runtime.taskmanager.Task - Registering task at network: Source: Custom Source -> Map -> Sink: Print to Std. Out (12/12)#0 (443191e6ec8f83ed33626521aacb2294) [DEPLOYING].
2023-07-20 13:32:09.452 [Source: Custom Source -> Map -> Sink: Print to Std. Out (12/12)#0] INFO  o.apache.flink.streaming.runtime.tasks.StreamTask - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2023-07-20 13:32:09.452 [Source: Custom Source -> Map -> Sink: Print to Std. Out (12/12)#0] INFO  org.apache.flink.runtime.taskmanager.Task - Source: Custom Source -> Map -> Sink: Print to Std. Out (12/12)#0 (443191e6ec8f83ed33626521aacb2294) switched from DEPLOYING to RUNNING.
2023-07-20 13:32:09.453 [flink-akka.actor.default-dispatcher-6] INFO  o.a.flink.runtime.executiongraph.ExecutionGraph - Source: Custom Source -> Map -> Sink: Print to Std. Out (12/12) (443191e6ec8f83ed33626521aacb2294) switched from DEPLOYING to RUNNING.
2023-07-20 13:32:09.508 [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/12)#0] INFO  o.a.f.s.connectors.kafka.FlinkKafkaConsumerBase - Consumer subtask 3 has no restore state.
2023-07-20 13:32:09.508 [Source: Custom Source -> Map -> Sink: Print to Std. Out (8/12)#0] INFO  o.a.f.s.connectors.kafka.FlinkKafkaConsumerBase - Consumer subtask 7 has no restore state.
2023-07-20 13:32:09.508 [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/12)#0] INFO  o.a.f.s.connectors.kafka.FlinkKafkaConsumerBase - Consumer subtask 0 has no restore state.
2023-07-20 13:32:09.508 [Source: Custom Source -> Map -> Sink: Print to Std. Out (11/12)#0] INFO  o.a.f.s.connectors.kafka.FlinkKafkaConsumerBase - Consumer subtask 10 has no restore state.
2023-07-20 13:32:09.508 [Source: Custom Source -> Map -> Sink: Print to Std. Out (10/12)#0] INFO  o.a.f.s.connectors.kafka.FlinkKafkaConsumerBase - Consumer subtask 9 has no restore state.
2023-07-20 13:32:09.508 [Source: Custom Source -> Map -> Sink: Print to Std. Out (7/12)#0] INFO  o.a.f.s.connectors.kafka.FlinkKafkaConsumerBase - Consumer subtask 6 has no restore state.
2023-07-20 13:32:09.508 [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/12)#0] INFO  o.a.f.s.connectors.kafka.FlinkKafkaConsumerBase - Consumer subtask 2 has no restore state.
2023-07-20 13:32:09.508 [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/12)#0] INFO  o.a.f.s.connectors.kafka.FlinkKafkaConsumerBase - Consumer subtask 4 has no restore state.
2023-07-20 13:32:09.508 [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/12)#0] INFO  o.a.f.s.connectors.kafka.FlinkKafkaConsumerBase - Consumer subtask 5 has no restore state.
2023-07-20 13:32:09.508 [Source: Custom Source -> Map -> Sink: Print to Std. Out (9/12)#0] INFO  o.a.f.s.connectors.kafka.FlinkKafkaConsumerBase - Consumer subtask 8 has no restore state.
2023-07-20 13:32:09.508 [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/12)#0] INFO  o.a.f.s.connectors.kafka.FlinkKafkaConsumerBase - Consumer subtask 1 has no restore state.
2023-07-20 13:32:09.508 [Source: Custom Source -> Map -> Sink: Print to Std. Out (12/12)#0] INFO  o.a.f.s.connectors.kafka.FlinkKafkaConsumerBase - Consumer subtask 11 has no restore state.
2023-07-20 13:32:09.556 [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/12)#0] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-flink-3
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2023-07-20 13:32:09.556 [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/12)#0] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-flink-5
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2023-07-20 13:32:09.557 [Source: Custom Source -> Map -> Sink: Print to Std. Out (12/12)#0] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-flink-8
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2023-07-20 13:32:09.556 [Source: Custom Source -> Map -> Sink: Print to Std. Out (10/12)#0] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-flink-4
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2023-07-20 13:32:09.556 [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/12)#0] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-flink-6
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2023-07-20 13:32:09.556 [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/12)#0] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-flink-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2023-07-20 13:32:09.556 [Source: Custom Source -> Map -> Sink: Print to Std. Out (11/12)#0] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-flink-10
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2023-07-20 13:32:09.556 [Source: Custom Source -> Map -> Sink: Print to Std. Out (9/12)#0] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-flink-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2023-07-20 13:32:09.556 [Source: Custom Source -> Map -> Sink: Print to Std. Out (8/12)#0] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-flink-11
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2023-07-20 13:32:09.556 [Source: Custom Source -> Map -> Sink: Print to Std. Out (7/12)#0] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-flink-9
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2023-07-20 13:32:09.557 [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/12)#0] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-flink-7
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2023-07-20 13:32:09.556 [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/12)#0] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-flink-12
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2023-07-20 13:32:09.659 [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.7.1
2023-07-20 13:32:09.659 [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 61dbce85d0d41457
2023-07-20 13:32:09.659 [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1689831129658
2023-07-20 13:32:09.660 [Source: Custom Source -> Map -> Sink: Print to Std. Out (9/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.7.1
2023-07-20 13:32:09.660 [Source: Custom Source -> Map -> Sink: Print to Std. Out (9/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 61dbce85d0d41457
2023-07-20 13:32:09.660 [Source: Custom Source -> Map -> Sink: Print to Std. Out (9/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1689831129658
2023-07-20 13:32:09.660 [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.7.1
2023-07-20 13:32:09.660 [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 61dbce85d0d41457
2023-07-20 13:32:09.660 [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1689831129658
2023-07-20 13:32:09.660 [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.7.1
2023-07-20 13:32:09.660 [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 61dbce85d0d41457
2023-07-20 13:32:09.660 [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1689831129658
2023-07-20 13:32:09.660 [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.7.1
2023-07-20 13:32:09.660 [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 61dbce85d0d41457
2023-07-20 13:32:09.660 [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1689831129658
2023-07-20 13:32:09.661 [Source: Custom Source -> Map -> Sink: Print to Std. Out (10/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.7.1
2023-07-20 13:32:09.661 [Source: Custom Source -> Map -> Sink: Print to Std. Out (10/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 61dbce85d0d41457
2023-07-20 13:32:09.661 [Source: Custom Source -> Map -> Sink: Print to Std. Out (10/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1689831129658
2023-07-20 13:32:09.661 [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.7.1
2023-07-20 13:32:09.661 [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 61dbce85d0d41457
2023-07-20 13:32:09.661 [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1689831129658
2023-07-20 13:32:09.661 [Source: Custom Source -> Map -> Sink: Print to Std. Out (8/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.7.1
2023-07-20 13:32:09.661 [Source: Custom Source -> Map -> Sink: Print to Std. Out (8/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 61dbce85d0d41457
2023-07-20 13:32:09.661 [Source: Custom Source -> Map -> Sink: Print to Std. Out (8/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1689831129658
2023-07-20 13:32:09.661 [Source: Custom Source -> Map -> Sink: Print to Std. Out (11/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.7.1
2023-07-20 13:32:09.661 [Source: Custom Source -> Map -> Sink: Print to Std. Out (11/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 61dbce85d0d41457
2023-07-20 13:32:09.661 [Source: Custom Source -> Map -> Sink: Print to Std. Out (11/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1689831129658
2023-07-20 13:32:09.661 [Source: Custom Source -> Map -> Sink: Print to Std. Out (7/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.7.1
2023-07-20 13:32:09.661 [Source: Custom Source -> Map -> Sink: Print to Std. Out (7/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 61dbce85d0d41457
2023-07-20 13:32:09.661 [Source: Custom Source -> Map -> Sink: Print to Std. Out (7/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1689831129658
2023-07-20 13:32:09.661 [Source: Custom Source -> Map -> Sink: Print to Std. Out (12/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.7.1
2023-07-20 13:32:09.661 [Source: Custom Source -> Map -> Sink: Print to Std. Out (12/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 61dbce85d0d41457
2023-07-20 13:32:09.661 [Source: Custom Source -> Map -> Sink: Print to Std. Out (12/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1689831129658
2023-07-20 13:32:09.662 [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.7.1
2023-07-20 13:32:09.662 [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 61dbce85d0d41457
2023-07-20 13:32:09.662 [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1689831129658
2023-07-20 13:32:10.060 [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/12)#0] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-flink-7, groupId=flink] Cluster ID: qYheim3NRmyUgYYzRu7BeQ
2023-07-20 13:32:10.060 [Source: Custom Source -> Map -> Sink: Print to Std. Out (8/12)#0] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-flink-11, groupId=flink] Cluster ID: qYheim3NRmyUgYYzRu7BeQ
2023-07-20 13:32:10.060 [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/12)#0] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-flink-6, groupId=flink] Cluster ID: qYheim3NRmyUgYYzRu7BeQ
2023-07-20 13:32:10.060 [Source: Custom Source -> Map -> Sink: Print to Std. Out (7/12)#0] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-flink-9, groupId=flink] Cluster ID: qYheim3NRmyUgYYzRu7BeQ
2023-07-20 13:32:10.060 [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/12)#0] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-flink-5, groupId=flink] Cluster ID: qYheim3NRmyUgYYzRu7BeQ
2023-07-20 13:32:10.060 [Source: Custom Source -> Map -> Sink: Print to Std. Out (12/12)#0] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-flink-8, groupId=flink] Cluster ID: qYheim3NRmyUgYYzRu7BeQ
2023-07-20 13:32:10.060 [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/12)#0] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-flink-3, groupId=flink] Cluster ID: qYheim3NRmyUgYYzRu7BeQ
2023-07-20 13:32:10.060 [Source: Custom Source -> Map -> Sink: Print to Std. Out (11/12)#0] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-flink-10, groupId=flink] Cluster ID: qYheim3NRmyUgYYzRu7BeQ
2023-07-20 13:32:10.060 [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/12)#0] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-flink-12, groupId=flink] Cluster ID: qYheim3NRmyUgYYzRu7BeQ
2023-07-20 13:32:10.060 [Source: Custom Source -> Map -> Sink: Print to Std. Out (10/12)#0] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-flink-4, groupId=flink] Cluster ID: qYheim3NRmyUgYYzRu7BeQ
2023-07-20 13:32:10.060 [Source: Custom Source -> Map -> Sink: Print to Std. Out (9/12)#0] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-flink-1, groupId=flink] Cluster ID: qYheim3NRmyUgYYzRu7BeQ
2023-07-20 13:32:10.060 [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/12)#0] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-flink-2, groupId=flink] Cluster ID: qYheim3NRmyUgYYzRu7BeQ
2023-07-20 13:32:10.063 [Source: Custom Source -> Map -> Sink: Print to Std. Out (9/12)#0] INFO  o.a.f.s.connectors.kafka.FlinkKafkaConsumerBase - Consumer subtask 8 initially has no partitions to read from.
2023-07-20 13:32:10.063 [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/12)#0] INFO  o.a.f.s.connectors.kafka.FlinkKafkaConsumerBase - Consumer subtask 0 initially has no partitions to read from.
2023-07-20 13:32:10.063 [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/12)#0] INFO  o.a.f.s.connectors.kafka.FlinkKafkaConsumerBase - Consumer subtask 2 initially has no partitions to read from.
2023-07-20 13:32:10.063 [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/12)#0] INFO  o.a.f.s.connectors.kafka.FlinkKafkaConsumerBase - Consumer subtask 5 initially has no partitions to read from.
2023-07-20 13:32:10.063 [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/12)#0] INFO  o.a.f.s.connectors.kafka.FlinkKafkaConsumerBase - Consumer subtask 1 initially has no partitions to read from.
2023-07-20 13:32:10.063 [Source: Custom Source -> Map -> Sink: Print to Std. Out (12/12)#0] INFO  o.a.f.s.connectors.kafka.FlinkKafkaConsumerBase - Consumer subtask 11 initially has no partitions to read from.
2023-07-20 13:32:10.063 [Source: Custom Source -> Map -> Sink: Print to Std. Out (7/12)#0] INFO  o.a.f.s.connectors.kafka.FlinkKafkaConsumerBase - Consumer subtask 6 will start reading the following 1 partitions from the committed group offsets in Kafka: [KafkaTopicPartition{topic='topic001', partition=0}]
2023-07-20 13:32:10.063 [Source: Custom Source -> Map -> Sink: Print to Std. Out (8/12)#0] INFO  o.a.f.s.connectors.kafka.FlinkKafkaConsumerBase - Consumer subtask 7 initially has no partitions to read from.
2023-07-20 13:32:10.063 [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/12)#0] INFO  o.a.f.s.connectors.kafka.FlinkKafkaConsumerBase - Consumer subtask 3 initially has no partitions to read from.
2023-07-20 13:32:10.063 [Source: Custom Source -> Map -> Sink: Print to Std. Out (11/12)#0] INFO  o.a.f.s.connectors.kafka.FlinkKafkaConsumerBase - Consumer subtask 10 initially has no partitions to read from.
2023-07-20 13:32:10.063 [Source: Custom Source -> Map -> Sink: Print to Std. Out (10/12)#0] INFO  o.a.f.s.connectors.kafka.FlinkKafkaConsumerBase - Consumer subtask 9 initially has no partitions to read from.
2023-07-20 13:32:10.063 [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/12)#0] INFO  o.a.f.s.connectors.kafka.FlinkKafkaConsumerBase - Consumer subtask 4 initially has no partitions to read from.
2023-07-20 13:32:10.068 [Legacy Source Thread - Source: Custom Source -> Map -> Sink: Print to Std. Out (12/12)#0] INFO  o.a.f.s.connectors.kafka.FlinkKafkaConsumerBase - Consumer subtask 11 creating fetcher with offsets {}.
2023-07-20 13:32:10.068 [Legacy Source Thread - Source: Custom Source -> Map -> Sink: Print to Std. Out (5/12)#0] INFO  o.a.f.s.connectors.kafka.FlinkKafkaConsumerBase - Consumer subtask 4 creating fetcher with offsets {}.
2023-07-20 13:32:10.068 [Legacy Source Thread - Source: Custom Source -> Map -> Sink: Print to Std. Out (2/12)#0] INFO  o.a.f.s.connectors.kafka.FlinkKafkaConsumerBase - Consumer subtask 1 creating fetcher with offsets {}.
2023-07-20 13:32:10.068 [Legacy Source Thread - Source: Custom Source -> Map -> Sink: Print to Std. Out (8/12)#0] INFO  o.a.f.s.connectors.kafka.FlinkKafkaConsumerBase - Consumer subtask 7 creating fetcher with offsets {}.
2023-07-20 13:32:10.069 [Legacy Source Thread - Source: Custom Source -> Map -> Sink: Print to Std. Out (7/12)#0] INFO  o.a.f.s.connectors.kafka.FlinkKafkaConsumerBase - Consumer subtask 6 creating fetcher with offsets {KafkaTopicPartition{topic='topic001', partition=0}=-915623761773}.
2023-07-20 13:32:10.069 [Legacy Source Thread - Source: Custom Source -> Map -> Sink: Print to Std. Out (11/12)#0] INFO  o.a.f.s.connectors.kafka.FlinkKafkaConsumerBase - Consumer subtask 10 creating fetcher with offsets {}.
2023-07-20 13:32:10.068 [Legacy Source Thread - Source: Custom Source -> Map -> Sink: Print to Std. Out (3/12)#0] INFO  o.a.f.s.connectors.kafka.FlinkKafkaConsumerBase - Consumer subtask 2 creating fetcher with offsets {}.
2023-07-20 13:32:10.068 [Legacy Source Thread - Source: Custom Source -> Map -> Sink: Print to Std. Out (6/12)#0] INFO  o.a.f.s.connectors.kafka.FlinkKafkaConsumerBase - Consumer subtask 5 creating fetcher with offsets {}.
2023-07-20 13:32:10.068 [Legacy Source Thread - Source: Custom Source -> Map -> Sink: Print to Std. Out (9/12)#0] INFO  o.a.f.s.connectors.kafka.FlinkKafkaConsumerBase - Consumer subtask 8 creating fetcher with offsets {}.
2023-07-20 13:32:10.068 [Legacy Source Thread - Source: Custom Source -> Map -> Sink: Print to Std. Out (1/12)#0] INFO  o.a.f.s.connectors.kafka.FlinkKafkaConsumerBase - Consumer subtask 0 creating fetcher with offsets {}.
2023-07-20 13:32:10.069 [Legacy Source Thread - Source: Custom Source -> Map -> Sink: Print to Std. Out (4/12)#0] INFO  o.a.f.s.connectors.kafka.FlinkKafkaConsumerBase - Consumer subtask 3 creating fetcher with offsets {}.
2023-07-20 13:32:10.068 [Legacy Source Thread - Source: Custom Source -> Map -> Sink: Print to Std. Out (10/12)#0] INFO  o.a.f.s.connectors.kafka.FlinkKafkaConsumerBase - Consumer subtask 9 creating fetcher with offsets {}.
2023-07-20 13:32:10.073 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (5/12)#0] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-flink-13
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2023-07-20 13:32:10.073 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (10/12)#0] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-flink-16
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2023-07-20 13:32:10.073 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (9/12)#0] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-flink-18
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2023-07-20 13:32:10.073 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (3/12)#0] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-flink-15
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2023-07-20 13:32:10.073 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (8/12)#0] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-flink-14
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2023-07-20 13:32:10.073 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (2/12)#0] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-flink-17
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2023-07-20 13:32:10.073 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (6/12)#0] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-flink-22
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2023-07-20 13:32:10.073 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (4/12)#0] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-flink-20
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2023-07-20 13:32:10.073 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (11/12)#0] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-flink-19
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2023-07-20 13:32:10.073 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (12/12)#0] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-flink-21
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2023-07-20 13:32:10.073 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (1/12)#0] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-flink-23
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2023-07-20 13:32:10.073 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (7/12)#0] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-flink-24
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2023-07-20 13:32:10.084 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (7/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.7.1
2023-07-20 13:32:10.084 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (7/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 61dbce85d0d41457
2023-07-20 13:32:10.084 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (7/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1689831130084
2023-07-20 13:32:10.085 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (9/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.7.1
2023-07-20 13:32:10.085 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (9/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 61dbce85d0d41457
2023-07-20 13:32:10.085 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (9/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1689831130085
2023-07-20 13:32:10.086 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (5/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.7.1
2023-07-20 13:32:10.086 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (5/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 61dbce85d0d41457
2023-07-20 13:32:10.086 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (5/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1689831130086
2023-07-20 13:32:10.087 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (1/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.7.1
2023-07-20 13:32:10.087 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (1/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 61dbce85d0d41457
2023-07-20 13:32:10.087 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (1/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1689831130087
2023-07-20 13:32:10.088 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (12/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.7.1
2023-07-20 13:32:10.088 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (12/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 61dbce85d0d41457
2023-07-20 13:32:10.088 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (12/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1689831130088
2023-07-20 13:32:10.089 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (2/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.7.1
2023-07-20 13:32:10.089 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (2/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 61dbce85d0d41457
2023-07-20 13:32:10.089 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (2/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1689831130088
2023-07-20 13:32:10.090 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (8/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.7.1
2023-07-20 13:32:10.090 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (8/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 61dbce85d0d41457
2023-07-20 13:32:10.090 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (8/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1689831130087
2023-07-20 13:32:10.090 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (11/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.7.1
2023-07-20 13:32:10.090 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (11/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 61dbce85d0d41457
2023-07-20 13:32:10.090 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (11/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1689831130089
2023-07-20 13:32:10.090 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (3/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.7.1
2023-07-20 13:32:10.090 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (3/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 61dbce85d0d41457
2023-07-20 13:32:10.090 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (3/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1689831130089
2023-07-20 13:32:10.090 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (10/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.7.1
2023-07-20 13:32:10.090 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (10/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 61dbce85d0d41457
2023-07-20 13:32:10.090 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (10/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1689831130089
2023-07-20 13:32:10.090 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (6/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.7.1
2023-07-20 13:32:10.090 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (6/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 61dbce85d0d41457
2023-07-20 13:32:10.090 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (6/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1689831130088
2023-07-20 13:32:10.091 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (4/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.7.1
2023-07-20 13:32:10.091 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (4/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 61dbce85d0d41457
2023-07-20 13:32:10.091 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (4/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1689831130090
2023-07-20 13:32:10.097 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (7/12)#0] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-flink-24, groupId=flink] Subscribed to partition(s): topic001-0
2023-07-20 13:32:10.105 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (7/12)#0] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-flink-24, groupId=flink] Cluster ID: qYheim3NRmyUgYYzRu7BeQ
2023-07-20 13:32:10.105 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (7/12)#0] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-flink-24, groupId=flink] Discovered group coordinator localhost:9092 (id: 2147483647 rack: null)
2023-07-20 13:32:10.110 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (7/12)#0] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-flink-24, groupId=flink] Setting offset for partition topic001-0 to the committed offset FetchPosition{offset=4, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 0 rack: null)], epoch=0}}
2023-07-20 13:32:47.508 [PermanentBlobCache shutdown hook] INFO  org.apache.flink.runtime.blob.PermanentBlobCache - Shutting down BLOB cache
2023-07-20 13:32:47.508 [TaskExecutorLocalStateStoresManager shutdown hook] INFO  o.a.f.r.state.TaskExecutorLocalStateStoresManager - Shutting down TaskExecutorLocalStateStoresManager.
2023-07-20 13:32:47.508 [TransientBlobCache shutdown hook] INFO  org.apache.flink.runtime.blob.TransientBlobCache - Shutting down BLOB cache
2023-07-20 13:32:47.512 [FileChannelManagerImpl-netty-shuffle shutdown hook] INFO  o.a.flink.runtime.io.disk.FileChannelManagerImpl - FileChannelManager removed spill file directory C:\Users\DELL\AppData\Local\Temp\flink-netty-shuffle-d5989633-d00a-4bee-bd62-98d5eb9a6d38
2023-07-20 13:32:47.512 [FileCache shutdown hook] INFO  org.apache.flink.runtime.filecache.FileCache - removed file cache directory C:\Users\DELL\AppData\Local\Temp\flink-dist-cache-f85646f6-04b2-452b-ab17-d3d1e4da71b4
2023-07-20 13:32:47.512 [BlobServer shutdown hook] INFO  org.apache.flink.runtime.blob.BlobServer - Stopped BLOB server at 0.0.0.0:51767
2023-07-20 13:32:47.513 [FileChannelManagerImpl-io shutdown hook] INFO  o.a.flink.runtime.io.disk.FileChannelManagerImpl - FileChannelManager removed spill file directory C:\Users\DELL\AppData\Local\Temp\flink-io-d9eb96d6-eb30-4ace-906d-b42574bec575
2023-07-20 15:09:08.275 [main] INFO  o.a.f.r.taskexecutor.TaskExecutorResourceUtils - The configuration option taskmanager.cpu.cores required for local execution is not set, setting it to the maximal possible value.
2023-07-20 15:09:08.325 [main] INFO  o.a.f.r.taskexecutor.TaskExecutorResourceUtils - The configuration option taskmanager.memory.task.heap.size required for local execution is not set, setting it to the maximal possible value.
2023-07-20 15:09:08.325 [main] INFO  o.a.f.r.taskexecutor.TaskExecutorResourceUtils - The configuration option taskmanager.memory.task.off-heap.size required for local execution is not set, setting it to the maximal possible value.
2023-07-20 15:09:08.327 [main] INFO  o.a.f.r.taskexecutor.TaskExecutorResourceUtils - The configuration option taskmanager.memory.network.min required for local execution is not set, setting it to its default value 64 mb.
2023-07-20 15:09:08.327 [main] INFO  o.a.f.r.taskexecutor.TaskExecutorResourceUtils - The configuration option taskmanager.memory.network.max required for local execution is not set, setting it to its default value 64 mb.
2023-07-20 15:09:08.327 [main] INFO  o.a.f.r.taskexecutor.TaskExecutorResourceUtils - The configuration option taskmanager.memory.managed.size required for local execution is not set, setting it to its default value 128 mb.
2023-07-20 15:09:08.575 [main] INFO  org.apache.flink.runtime.minicluster.MiniCluster - Starting Flink Mini Cluster
2023-07-20 15:09:08.590 [main] INFO  org.apache.flink.runtime.minicluster.MiniCluster - Starting Metrics Registry
2023-07-20 15:09:08.837 [main] INFO  o.apache.flink.runtime.metrics.MetricRegistryImpl - No metrics reporter configured, no metrics will be exposed/reported.
2023-07-20 15:09:08.837 [main] INFO  org.apache.flink.runtime.minicluster.MiniCluster - Starting RPC Service(s)
2023-07-20 15:09:09.557 [main] INFO  o.a.flink.runtime.rpc.akka.AkkaRpcServiceUtils - Trying to start local actor system
2023-07-20 15:09:10.361 [flink-akka.actor.default-dispatcher-3] INFO  akka.event.slf4j.Slf4jLogger - Slf4jLogger started
2023-07-20 15:09:10.553 [main] INFO  o.a.flink.runtime.rpc.akka.AkkaRpcServiceUtils - Actor system started at akka://flink
2023-07-20 15:09:10.594 [main] INFO  o.a.flink.runtime.rpc.akka.AkkaRpcServiceUtils - Trying to start local actor system
2023-07-20 15:09:10.604 [flink-metrics-2] INFO  akka.event.slf4j.Slf4jLogger - Slf4jLogger started
2023-07-20 15:09:10.617 [main] INFO  o.a.flink.runtime.rpc.akka.AkkaRpcServiceUtils - Actor system started at akka://flink-metrics
2023-07-20 15:09:10.698 [main] INFO  org.apache.flink.runtime.rpc.akka.AkkaRpcService - Starting RPC endpoint for org.apache.flink.runtime.metrics.dump.MetricQueryService at akka://flink-metrics/user/rpc/MetricQueryService .
2023-07-20 15:09:10.767 [main] INFO  org.apache.flink.runtime.minicluster.MiniCluster - Starting high-availability services
2023-07-20 15:09:10.952 [main] INFO  org.apache.flink.runtime.blob.BlobServer - Created BLOB server storage directory C:\Users\DELL\AppData\Local\Temp\blobStore-f9b311a7-44b7-4e5b-a1d5-0091d555e516
2023-07-20 15:09:10.974 [main] INFO  org.apache.flink.runtime.blob.BlobServer - Started BLOB server at 0.0.0.0:56778 - max concurrent requests: 50 - max backlog: 1000
2023-07-20 15:09:10.986 [main] INFO  org.apache.flink.runtime.blob.PermanentBlobCache - Created BLOB cache storage directory C:\Users\DELL\AppData\Local\Temp\blobStore-ec63e275-58c7-4ab0-b090-aa393f62f792
2023-07-20 15:09:10.988 [main] INFO  org.apache.flink.runtime.blob.TransientBlobCache - Created BLOB cache storage directory C:\Users\DELL\AppData\Local\Temp\blobStore-8eb0fdd9-44cb-4fe2-9d80-596698edbba9
2023-07-20 15:09:10.988 [main] INFO  org.apache.flink.runtime.minicluster.MiniCluster - Starting 1 TaskManger(s)
2023-07-20 15:09:11.001 [main] INFO  o.a.flink.runtime.taskexecutor.TaskManagerRunner - Starting TaskManager with ResourceID: c98b9cb4-8f6f-4d69-aa34-3d9453424d27
2023-07-20 15:09:11.056 [main] INFO  o.a.flink.runtime.taskexecutor.TaskManagerServices - Temporary file directory 'C:\Users\DELL\AppData\Local\Temp': total 237 GB, usable 96 GB (40.51% usable)
2023-07-20 15:09:11.060 [main] INFO  o.a.flink.runtime.io.disk.FileChannelManagerImpl - FileChannelManager uses directory C:\Users\DELL\AppData\Local\Temp\flink-io-5a260558-4faf-43eb-a225-926f434f4e71 for spill files.
2023-07-20 15:09:11.068 [main] INFO  o.a.flink.runtime.io.disk.FileChannelManagerImpl - FileChannelManager uses directory C:\Users\DELL\AppData\Local\Temp\flink-netty-shuffle-8528dd11-7560-4b13-841f-c628e5b1945d for spill files.
2023-07-20 15:09:11.119 [main] INFO  o.a.f.runtime.io.network.buffer.NetworkBufferPool - Allocated 64 MB for network buffer pool (number of memory segments: 2048, bytes per segment: 32768).
2023-07-20 15:09:11.140 [main] INFO  o.a.f.runtime.io.network.NettyShuffleEnvironment - Starting the network environment and its components.
2023-07-20 15:09:11.151 [main] INFO  o.apache.flink.runtime.taskexecutor.KvStateService - Starting the kvState service and its components.
2023-07-20 15:09:11.173 [main] INFO  org.apache.flink.runtime.rpc.akka.AkkaRpcService - Starting RPC endpoint for org.apache.flink.runtime.taskexecutor.TaskExecutor at akka://flink/user/rpc/taskmanager_0 .
2023-07-20 15:09:11.185 [flink-akka.actor.default-dispatcher-3] INFO  o.a.f.runtime.taskexecutor.DefaultJobLeaderService - Start job leader service.
2023-07-20 15:09:11.187 [flink-akka.actor.default-dispatcher-3] INFO  org.apache.flink.runtime.filecache.FileCache - User file cache uses directory C:\Users\DELL\AppData\Local\Temp\flink-dist-cache-2ccfe79c-d5e7-4935-bc1a-bc2f5e11fcd0
2023-07-20 15:09:11.251 [main] INFO  o.a.f.runtime.dispatcher.DispatcherRestEndpoint - Starting rest endpoint.
2023-07-20 15:09:11.254 [main] INFO  o.a.f.runtime.dispatcher.DispatcherRestEndpoint - Failed to load web based job submission extension. Probable reason: flink-runtime-web is not in the classpath.
2023-07-20 15:09:12.029 [main] INFO  o.a.f.runtime.dispatcher.DispatcherRestEndpoint - Rest endpoint listening at localhost:56829
2023-07-20 15:09:12.030 [main] INFO  o.a.f.r.h.nonha.embedded.EmbeddedLeaderService - Proposing leadership to contender http://localhost:56829
2023-07-20 15:09:12.031 [mini-cluster-io-thread-1] INFO  o.a.f.runtime.dispatcher.DispatcherRestEndpoint - http://localhost:56829 was granted leadership with leaderSessionID=7136f8bb-5693-463c-830d-48644616dba2
2023-07-20 15:09:12.032 [mini-cluster-io-thread-1] INFO  o.a.f.r.h.nonha.embedded.EmbeddedLeaderService - Received confirmation of leadership for leader http://localhost:56829 , session=7136f8bb-5693-463c-830d-48644616dba2
2023-07-20 15:09:12.056 [main] INFO  org.apache.flink.runtime.rpc.akka.AkkaRpcService - Starting RPC endpoint for org.apache.flink.runtime.resourcemanager.StandaloneResourceManager at akka://flink/user/rpc/resourcemanager_1 .
2023-07-20 15:09:12.068 [main] INFO  o.a.f.r.h.nonha.embedded.EmbeddedLeaderService - Proposing leadership to contender LeaderContender: DefaultDispatcherRunner
2023-07-20 15:09:12.068 [flink-akka.actor.default-dispatcher-3] INFO  o.a.f.r.h.nonha.embedded.EmbeddedLeaderService - Proposing leadership to contender LeaderContender: StandaloneResourceManager
2023-07-20 15:09:12.069 [flink-akka.actor.default-dispatcher-3] INFO  o.a.f.r.resourcemanager.StandaloneResourceManager - ResourceManager akka://flink/user/rpc/resourcemanager_1 was granted leadership with fencing token b4ec00fccd83cf0ae0e59a3f06114225
2023-07-20 15:09:12.071 [main] INFO  org.apache.flink.runtime.minicluster.MiniCluster - Flink Mini Cluster started successfully
2023-07-20 15:09:12.072 [mini-cluster-io-thread-2] INFO  o.a.f.r.d.runner.SessionDispatcherLeaderProcess - Start SessionDispatcherLeaderProcess.
2023-07-20 15:09:12.072 [flink-akka.actor.default-dispatcher-3] INFO  o.a.f.r.r.slotmanager.SlotManagerImpl - Starting the SlotManager.
2023-07-20 15:09:12.073 [mini-cluster-io-thread-5] INFO  o.a.f.r.d.runner.SessionDispatcherLeaderProcess - Recover all persisted job graphs.
2023-07-20 15:09:12.073 [mini-cluster-io-thread-5] INFO  o.a.f.r.d.runner.SessionDispatcherLeaderProcess - Successfully recovered 0 persisted job graphs.
2023-07-20 15:09:12.075 [mini-cluster-io-thread-6] INFO  o.a.f.r.h.nonha.embedded.EmbeddedLeaderService - Received confirmation of leadership for leader akka://flink/user/rpc/resourcemanager_1 , session=e0e59a3f-0611-4225-b4ec-00fccd83cf0a
2023-07-20 15:09:12.081 [flink-akka.actor.default-dispatcher-3] INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor - Connecting to ResourceManager akka://flink/user/rpc/resourcemanager_1(b4ec00fccd83cf0ae0e59a3f06114225).
2023-07-20 15:09:12.085 [mini-cluster-io-thread-5] INFO  org.apache.flink.runtime.rpc.akka.AkkaRpcService - Starting RPC endpoint for org.apache.flink.runtime.dispatcher.StandaloneDispatcher at akka://flink/user/rpc/dispatcher_2 .
2023-07-20 15:09:12.109 [mini-cluster-io-thread-5] INFO  o.a.f.r.h.nonha.embedded.EmbeddedLeaderService - Received confirmation of leadership for leader akka://flink/user/rpc/dispatcher_2 , session=7eecf613-2761-4b4c-91f7-0e5fbc5e6f4f
2023-07-20 15:09:12.133 [flink-akka.actor.default-dispatcher-6] INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor - Resolved ResourceManager address, beginning registration
2023-07-20 15:09:12.166 [flink-akka.actor.default-dispatcher-2] INFO  o.a.f.r.resourcemanager.StandaloneResourceManager - Registering TaskManager with ResourceID c98b9cb4-8f6f-4d69-aa34-3d9453424d27 (akka://flink/user/rpc/taskmanager_0) at ResourceManager
2023-07-20 15:09:12.168 [flink-akka.actor.default-dispatcher-6] INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor - Successful registration at resource manager akka://flink/user/rpc/resourcemanager_1 under registration id 3b003d36a9ce247c827cd816dec205be.
2023-07-20 15:09:12.169 [flink-akka.actor.default-dispatcher-2] INFO  o.a.flink.runtime.dispatcher.StandaloneDispatcher - Received JobGraph submission 0d987a8aa41f83e9302c68a1cf021e48 (kafka-flink-start).
2023-07-20 15:09:12.170 [flink-akka.actor.default-dispatcher-2] INFO  o.a.flink.runtime.dispatcher.StandaloneDispatcher - Submitting job 0d987a8aa41f83e9302c68a1cf021e48 (kafka-flink-start).
2023-07-20 15:09:12.184 [mini-cluster-io-thread-12] INFO  o.a.f.r.h.nonha.embedded.EmbeddedLeaderService - Proposing leadership to contender LeaderContender: JobManagerRunnerImpl
2023-07-20 15:09:12.189 [mini-cluster-io-thread-12] INFO  org.apache.flink.runtime.rpc.akka.AkkaRpcService - Starting RPC endpoint for org.apache.flink.runtime.jobmaster.JobMaster at akka://flink/user/rpc/jobmanager_3 .
2023-07-20 15:09:12.195 [mini-cluster-io-thread-12] INFO  org.apache.flink.runtime.jobmaster.JobMaster - Initializing job kafka-flink-start (0d987a8aa41f83e9302c68a1cf021e48).
2023-07-20 15:09:12.213 [mini-cluster-io-thread-12] INFO  org.apache.flink.runtime.jobmaster.JobMaster - Using restart back off time strategy NoRestartBackoffTimeStrategy for kafka-flink-start (0d987a8aa41f83e9302c68a1cf021e48).
2023-07-20 15:09:12.264 [mini-cluster-io-thread-12] INFO  org.apache.flink.runtime.jobmaster.JobMaster - Running initialization on master for job kafka-flink-start (0d987a8aa41f83e9302c68a1cf021e48).
2023-07-20 15:09:12.264 [mini-cluster-io-thread-12] INFO  org.apache.flink.runtime.jobmaster.JobMaster - Successfully ran initialization on master in 0 ms.
2023-07-20 15:09:12.274 [mini-cluster-io-thread-12] INFO  o.a.f.r.scheduler.adapter.DefaultExecutionTopology - Built 12 pipelined regions in 0 ms
2023-07-20 15:09:12.316 [mini-cluster-io-thread-12] INFO  org.apache.flink.runtime.jobmaster.JobMaster - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2023-07-20 15:09:12.330 [mini-cluster-io-thread-12] INFO  o.a.flink.runtime.checkpoint.CheckpointCoordinator - No checkpoint found during restore.
2023-07-20 15:09:12.331 [mini-cluster-io-thread-12] INFO  org.apache.flink.runtime.jobmaster.JobMaster - Using failover strategy org.apache.flink.runtime.executiongraph.failover.flip1.RestartPipelinedRegionFailoverStrategy@394ba890 for kafka-flink-start (0d987a8aa41f83e9302c68a1cf021e48).
2023-07-20 15:09:12.338 [mini-cluster-io-thread-12] INFO  o.a.flink.runtime.jobmaster.JobManagerRunnerImpl - JobManager runner for job kafka-flink-start (0d987a8aa41f83e9302c68a1cf021e48) was granted leadership with session id 3b54d7bb-a118-449f-8ab8-1f51bb2574bd at akka://flink/user/rpc/jobmanager_3.
2023-07-20 15:09:12.341 [flink-akka.actor.default-dispatcher-6] INFO  org.apache.flink.runtime.jobmaster.JobMaster - Starting execution of job kafka-flink-start (0d987a8aa41f83e9302c68a1cf021e48) under job master id 8ab81f51bb2574bd3b54d7bba118449f.
2023-07-20 15:09:12.343 [flink-akka.actor.default-dispatcher-6] INFO  org.apache.flink.runtime.jobmaster.JobMaster - Starting scheduling with scheduling strategy [org.apache.flink.runtime.scheduler.strategy.PipelinedRegionSchedulingStrategy]
2023-07-20 15:09:12.344 [flink-akka.actor.default-dispatcher-6] INFO  o.a.flink.runtime.executiongraph.ExecutionGraph - Job kafka-flink-start (0d987a8aa41f83e9302c68a1cf021e48) switched from state CREATED to RUNNING.
2023-07-20 15:09:12.350 [flink-akka.actor.default-dispatcher-6] INFO  o.a.flink.runtime.executiongraph.ExecutionGraph - Source: Custom Source -> Map -> Sink: Print to Std. Out (1/12) (26a0e88843a2e302f733846a1bc38770) switched from CREATED to SCHEDULED.
2023-07-20 15:09:12.356 [flink-akka.actor.default-dispatcher-6] INFO  o.a.flink.runtime.jobmaster.slotpool.SlotPoolImpl - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{e49b9c73d25962c7d5d1cf5cf90ab184}]
2023-07-20 15:09:12.364 [flink-akka.actor.default-dispatcher-6] INFO  o.a.flink.runtime.executiongraph.ExecutionGraph - Source: Custom Source -> Map -> Sink: Print to Std. Out (2/12) (3ac85efa3053001b6efe102876248b41) switched from CREATED to SCHEDULED.
2023-07-20 15:09:12.364 [flink-akka.actor.default-dispatcher-6] INFO  o.a.flink.runtime.jobmaster.slotpool.SlotPoolImpl - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{168dee674fc40a902b7ac1e944b39c30}]
2023-07-20 15:09:12.364 [flink-akka.actor.default-dispatcher-6] INFO  o.a.flink.runtime.executiongraph.ExecutionGraph - Source: Custom Source -> Map -> Sink: Print to Std. Out (3/12) (ee1f3acadf87491452e580a477c1162e) switched from CREATED to SCHEDULED.
2023-07-20 15:09:12.365 [flink-akka.actor.default-dispatcher-6] INFO  o.a.flink.runtime.jobmaster.slotpool.SlotPoolImpl - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{f15ddd72328aaf456c6c74a52ca15c2f}]
2023-07-20 15:09:12.365 [flink-akka.actor.default-dispatcher-6] INFO  o.a.flink.runtime.executiongraph.ExecutionGraph - Source: Custom Source -> Map -> Sink: Print to Std. Out (4/12) (a613a743e9e68f31e89be68e6c650d32) switched from CREATED to SCHEDULED.
2023-07-20 15:09:12.365 [flink-akka.actor.default-dispatcher-6] INFO  o.a.flink.runtime.jobmaster.slotpool.SlotPoolImpl - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{2e4cce181a746b7a0612409978c3a6b7}]
2023-07-20 15:09:12.366 [flink-akka.actor.default-dispatcher-6] INFO  o.a.flink.runtime.executiongraph.ExecutionGraph - Source: Custom Source -> Map -> Sink: Print to Std. Out (5/12) (9742eda81823099ae2ea798f963c29a1) switched from CREATED to SCHEDULED.
2023-07-20 15:09:12.366 [flink-akka.actor.default-dispatcher-6] INFO  o.a.flink.runtime.jobmaster.slotpool.SlotPoolImpl - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{4409c62070891bb9a99b4bb04fad4612}]
2023-07-20 15:09:12.366 [flink-akka.actor.default-dispatcher-6] INFO  o.a.flink.runtime.executiongraph.ExecutionGraph - Source: Custom Source -> Map -> Sink: Print to Std. Out (6/12) (5da6f0bd61008494b4ac696adfb35d7d) switched from CREATED to SCHEDULED.
2023-07-20 15:09:12.366 [flink-akka.actor.default-dispatcher-6] INFO  o.a.flink.runtime.jobmaster.slotpool.SlotPoolImpl - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{b662d1165be428fe99a9c13accf2281d}]
2023-07-20 15:09:12.366 [flink-akka.actor.default-dispatcher-6] INFO  o.a.flink.runtime.executiongraph.ExecutionGraph - Source: Custom Source -> Map -> Sink: Print to Std. Out (7/12) (8f215c8a5c31cff2d5431d5f9a1ba908) switched from CREATED to SCHEDULED.
2023-07-20 15:09:12.367 [flink-akka.actor.default-dispatcher-6] INFO  o.a.flink.runtime.jobmaster.slotpool.SlotPoolImpl - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{900e74c90126233a2c809a6e66c8bcca}]
2023-07-20 15:09:12.367 [flink-akka.actor.default-dispatcher-6] INFO  o.a.flink.runtime.executiongraph.ExecutionGraph - Source: Custom Source -> Map -> Sink: Print to Std. Out (8/12) (6f238e60f6fa20cad10485d0152c359a) switched from CREATED to SCHEDULED.
2023-07-20 15:09:12.367 [flink-akka.actor.default-dispatcher-6] INFO  o.a.flink.runtime.jobmaster.slotpool.SlotPoolImpl - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{8b7f35cb138f2bd17df1f6e26a08a49e}]
2023-07-20 15:09:12.367 [flink-akka.actor.default-dispatcher-6] INFO  o.a.flink.runtime.executiongraph.ExecutionGraph - Source: Custom Source -> Map -> Sink: Print to Std. Out (9/12) (e89e791ecd165a6a950a64261f0ac9b4) switched from CREATED to SCHEDULED.
2023-07-20 15:09:12.367 [flink-akka.actor.default-dispatcher-6] INFO  o.a.flink.runtime.jobmaster.slotpool.SlotPoolImpl - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{5bf32bf4d60c301bb2900511dce0af33}]
2023-07-20 15:09:12.368 [flink-akka.actor.default-dispatcher-6] INFO  o.a.flink.runtime.executiongraph.ExecutionGraph - Source: Custom Source -> Map -> Sink: Print to Std. Out (10/12) (045609b1983d728cbad3acf3e75eea54) switched from CREATED to SCHEDULED.
2023-07-20 15:09:12.368 [flink-akka.actor.default-dispatcher-6] INFO  o.a.flink.runtime.jobmaster.slotpool.SlotPoolImpl - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{bc31a6e069c0f3e61be27ade09de29b8}]
2023-07-20 15:09:12.368 [flink-akka.actor.default-dispatcher-6] INFO  o.a.flink.runtime.executiongraph.ExecutionGraph - Source: Custom Source -> Map -> Sink: Print to Std. Out (11/12) (5967cfdaa1c664c90b97685bf3653d8a) switched from CREATED to SCHEDULED.
2023-07-20 15:09:12.368 [flink-akka.actor.default-dispatcher-6] INFO  o.a.flink.runtime.jobmaster.slotpool.SlotPoolImpl - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{64a8e26baed8ebf203a29e09ce1f7d6c}]
2023-07-20 15:09:12.368 [flink-akka.actor.default-dispatcher-6] INFO  o.a.flink.runtime.executiongraph.ExecutionGraph - Source: Custom Source -> Map -> Sink: Print to Std. Out (12/12) (9c8cef33a7f5694b073ab4b1423e024b) switched from CREATED to SCHEDULED.
2023-07-20 15:09:12.368 [flink-akka.actor.default-dispatcher-6] INFO  o.a.flink.runtime.jobmaster.slotpool.SlotPoolImpl - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{ceddcb3d0ba8e874e23fdcbf86cc1e26}]
2023-07-20 15:09:12.369 [jobmanager-future-thread-1] INFO  o.a.f.r.h.nonha.embedded.EmbeddedLeaderService - Received confirmation of leadership for leader akka://flink/user/rpc/jobmanager_3 , session=3b54d7bb-a118-449f-8ab8-1f51bb2574bd
2023-07-20 15:09:12.369 [flink-akka.actor.default-dispatcher-6] INFO  org.apache.flink.runtime.jobmaster.JobMaster - Connecting to ResourceManager akka://flink/user/rpc/resourcemanager_1(b4ec00fccd83cf0ae0e59a3f06114225)
2023-07-20 15:09:12.370 [flink-akka.actor.default-dispatcher-4] INFO  org.apache.flink.runtime.jobmaster.JobMaster - Resolved ResourceManager address, beginning registration
2023-07-20 15:09:12.372 [flink-akka.actor.default-dispatcher-4] INFO  o.a.f.r.resourcemanager.StandaloneResourceManager - Registering job manager 8ab81f51bb2574bd3b54d7bba118449f@akka://flink/user/rpc/jobmanager_3 for job 0d987a8aa41f83e9302c68a1cf021e48.
2023-07-20 15:09:12.376 [flink-akka.actor.default-dispatcher-4] INFO  o.a.f.r.resourcemanager.StandaloneResourceManager - Registered job manager 8ab81f51bb2574bd3b54d7bba118449f@akka://flink/user/rpc/jobmanager_3 for job 0d987a8aa41f83e9302c68a1cf021e48.
2023-07-20 15:09:12.378 [flink-akka.actor.default-dispatcher-6] INFO  org.apache.flink.runtime.jobmaster.JobMaster - JobManager successfully registered at ResourceManager, leader id: b4ec00fccd83cf0ae0e59a3f06114225.
2023-07-20 15:09:12.379 [flink-akka.actor.default-dispatcher-6] INFO  o.a.flink.runtime.jobmaster.slotpool.SlotPoolImpl - Requesting new slot [SlotRequestId{e49b9c73d25962c7d5d1cf5cf90ab184}] and profile ResourceProfile{UNKNOWN} with allocation id b85fd339256b8f944b2ef60a232bc8d0 from resource manager.
2023-07-20 15:09:12.379 [flink-akka.actor.default-dispatcher-4] INFO  o.a.f.r.resourcemanager.StandaloneResourceManager - Request slot with profile ResourceProfile{UNKNOWN} for job 0d987a8aa41f83e9302c68a1cf021e48 with allocation id b85fd339256b8f944b2ef60a232bc8d0.
2023-07-20 15:09:12.379 [flink-akka.actor.default-dispatcher-6] INFO  o.a.flink.runtime.jobmaster.slotpool.SlotPoolImpl - Requesting new slot [SlotRequestId{168dee674fc40a902b7ac1e944b39c30}] and profile ResourceProfile{UNKNOWN} with allocation id 7a84ed97655711dee0875a2bc20c2351 from resource manager.
2023-07-20 15:09:12.380 [flink-akka.actor.default-dispatcher-6] INFO  o.a.flink.runtime.jobmaster.slotpool.SlotPoolImpl - Requesting new slot [SlotRequestId{f15ddd72328aaf456c6c74a52ca15c2f}] and profile ResourceProfile{UNKNOWN} with allocation id abb2d60af522a7efe7c5b25971f711e7 from resource manager.
2023-07-20 15:09:12.380 [flink-akka.actor.default-dispatcher-6] INFO  o.a.flink.runtime.jobmaster.slotpool.SlotPoolImpl - Requesting new slot [SlotRequestId{2e4cce181a746b7a0612409978c3a6b7}] and profile ResourceProfile{UNKNOWN} with allocation id ad84932c86454a8407f32d7980838dd3 from resource manager.
2023-07-20 15:09:12.380 [flink-akka.actor.default-dispatcher-6] INFO  o.a.flink.runtime.jobmaster.slotpool.SlotPoolImpl - Requesting new slot [SlotRequestId{4409c62070891bb9a99b4bb04fad4612}] and profile ResourceProfile{UNKNOWN} with allocation id 71e10da2aa6733156fa52c0139bb43fd from resource manager.
2023-07-20 15:09:12.380 [flink-akka.actor.default-dispatcher-6] INFO  o.a.flink.runtime.jobmaster.slotpool.SlotPoolImpl - Requesting new slot [SlotRequestId{b662d1165be428fe99a9c13accf2281d}] and profile ResourceProfile{UNKNOWN} with allocation id f476bca22bb8e802fef42a07adc89e4c from resource manager.
2023-07-20 15:09:12.380 [flink-akka.actor.default-dispatcher-6] INFO  o.a.flink.runtime.jobmaster.slotpool.SlotPoolImpl - Requesting new slot [SlotRequestId{900e74c90126233a2c809a6e66c8bcca}] and profile ResourceProfile{UNKNOWN} with allocation id 33a716b47d32580cabf4a7ba0d6b8e38 from resource manager.
2023-07-20 15:09:12.380 [flink-akka.actor.default-dispatcher-6] INFO  o.a.flink.runtime.jobmaster.slotpool.SlotPoolImpl - Requesting new slot [SlotRequestId{8b7f35cb138f2bd17df1f6e26a08a49e}] and profile ResourceProfile{UNKNOWN} with allocation id 94b1cabb3de3b9067a2bb3f0c257ec9c from resource manager.
2023-07-20 15:09:12.381 [flink-akka.actor.default-dispatcher-6] INFO  o.a.flink.runtime.jobmaster.slotpool.SlotPoolImpl - Requesting new slot [SlotRequestId{5bf32bf4d60c301bb2900511dce0af33}] and profile ResourceProfile{UNKNOWN} with allocation id 3d6c0534e6e91dcb38eefd21177982d0 from resource manager.
2023-07-20 15:09:12.381 [flink-akka.actor.default-dispatcher-6] INFO  o.a.flink.runtime.jobmaster.slotpool.SlotPoolImpl - Requesting new slot [SlotRequestId{bc31a6e069c0f3e61be27ade09de29b8}] and profile ResourceProfile{UNKNOWN} with allocation id 8fd045c0ef2cf772b13a8c72804710f7 from resource manager.
2023-07-20 15:09:12.381 [flink-akka.actor.default-dispatcher-2] INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor - Receive slot request b85fd339256b8f944b2ef60a232bc8d0 for job 0d987a8aa41f83e9302c68a1cf021e48 from resource manager with leader id b4ec00fccd83cf0ae0e59a3f06114225.
2023-07-20 15:09:12.381 [flink-akka.actor.default-dispatcher-6] INFO  o.a.flink.runtime.jobmaster.slotpool.SlotPoolImpl - Requesting new slot [SlotRequestId{64a8e26baed8ebf203a29e09ce1f7d6c}] and profile ResourceProfile{UNKNOWN} with allocation id cd7788e0ba34f5c0e7848f34470ee594 from resource manager.
2023-07-20 15:09:12.381 [flink-akka.actor.default-dispatcher-6] INFO  o.a.flink.runtime.jobmaster.slotpool.SlotPoolImpl - Requesting new slot [SlotRequestId{ceddcb3d0ba8e874e23fdcbf86cc1e26}] and profile ResourceProfile{UNKNOWN} with allocation id 32d4c9fffaf7fadd2bb9d27065bcda63 from resource manager.
2023-07-20 15:09:12.382 [flink-akka.actor.default-dispatcher-4] INFO  o.a.f.r.resourcemanager.StandaloneResourceManager - Request slot with profile ResourceProfile{UNKNOWN} for job 0d987a8aa41f83e9302c68a1cf021e48 with allocation id 7a84ed97655711dee0875a2bc20c2351.
2023-07-20 15:09:12.382 [flink-akka.actor.default-dispatcher-4] INFO  o.a.f.r.resourcemanager.StandaloneResourceManager - Request slot with profile ResourceProfile{UNKNOWN} for job 0d987a8aa41f83e9302c68a1cf021e48 with allocation id abb2d60af522a7efe7c5b25971f711e7.
2023-07-20 15:09:12.382 [flink-akka.actor.default-dispatcher-4] INFO  o.a.f.r.resourcemanager.StandaloneResourceManager - Request slot with profile ResourceProfile{UNKNOWN} for job 0d987a8aa41f83e9302c68a1cf021e48 with allocation id ad84932c86454a8407f32d7980838dd3.
2023-07-20 15:09:12.382 [flink-akka.actor.default-dispatcher-4] INFO  o.a.f.r.resourcemanager.StandaloneResourceManager - Request slot with profile ResourceProfile{UNKNOWN} for job 0d987a8aa41f83e9302c68a1cf021e48 with allocation id 71e10da2aa6733156fa52c0139bb43fd.
2023-07-20 15:09:12.383 [flink-akka.actor.default-dispatcher-4] INFO  o.a.f.r.resourcemanager.StandaloneResourceManager - Request slot with profile ResourceProfile{UNKNOWN} for job 0d987a8aa41f83e9302c68a1cf021e48 with allocation id f476bca22bb8e802fef42a07adc89e4c.
2023-07-20 15:09:12.383 [flink-akka.actor.default-dispatcher-4] INFO  o.a.f.r.resourcemanager.StandaloneResourceManager - Request slot with profile ResourceProfile{UNKNOWN} for job 0d987a8aa41f83e9302c68a1cf021e48 with allocation id 33a716b47d32580cabf4a7ba0d6b8e38.
2023-07-20 15:09:12.383 [flink-akka.actor.default-dispatcher-4] INFO  o.a.f.r.resourcemanager.StandaloneResourceManager - Request slot with profile ResourceProfile{UNKNOWN} for job 0d987a8aa41f83e9302c68a1cf021e48 with allocation id 94b1cabb3de3b9067a2bb3f0c257ec9c.
2023-07-20 15:09:12.383 [flink-akka.actor.default-dispatcher-4] INFO  o.a.f.r.resourcemanager.StandaloneResourceManager - Request slot with profile ResourceProfile{UNKNOWN} for job 0d987a8aa41f83e9302c68a1cf021e48 with allocation id 3d6c0534e6e91dcb38eefd21177982d0.
2023-07-20 15:09:12.383 [flink-akka.actor.default-dispatcher-4] INFO  o.a.f.r.resourcemanager.StandaloneResourceManager - Request slot with profile ResourceProfile{UNKNOWN} for job 0d987a8aa41f83e9302c68a1cf021e48 with allocation id 8fd045c0ef2cf772b13a8c72804710f7.
2023-07-20 15:09:12.384 [flink-akka.actor.default-dispatcher-4] INFO  o.a.f.r.resourcemanager.StandaloneResourceManager - Request slot with profile ResourceProfile{UNKNOWN} for job 0d987a8aa41f83e9302c68a1cf021e48 with allocation id cd7788e0ba34f5c0e7848f34470ee594.
2023-07-20 15:09:12.384 [flink-akka.actor.default-dispatcher-4] INFO  o.a.f.r.resourcemanager.StandaloneResourceManager - Request slot with profile ResourceProfile{UNKNOWN} for job 0d987a8aa41f83e9302c68a1cf021e48 with allocation id 32d4c9fffaf7fadd2bb9d27065bcda63.
2023-07-20 15:09:12.384 [flink-akka.actor.default-dispatcher-2] INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor - Allocated slot for b85fd339256b8f944b2ef60a232bc8d0.
2023-07-20 15:09:12.385 [flink-akka.actor.default-dispatcher-2] INFO  o.a.f.runtime.taskexecutor.DefaultJobLeaderService - Add job 0d987a8aa41f83e9302c68a1cf021e48 for job leader monitoring.
2023-07-20 15:09:12.388 [mini-cluster-io-thread-18] INFO  o.a.f.runtime.taskexecutor.DefaultJobLeaderService - Try to register at job manager akka://flink/user/rpc/jobmanager_3 with leader id 3b54d7bb-a118-449f-8ab8-1f51bb2574bd.
2023-07-20 15:09:12.388 [flink-akka.actor.default-dispatcher-2] INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor - Receive slot request 7a84ed97655711dee0875a2bc20c2351 for job 0d987a8aa41f83e9302c68a1cf021e48 from resource manager with leader id b4ec00fccd83cf0ae0e59a3f06114225.
2023-07-20 15:09:12.389 [flink-akka.actor.default-dispatcher-2] INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor - Allocated slot for 7a84ed97655711dee0875a2bc20c2351.
2023-07-20 15:09:12.389 [flink-akka.actor.default-dispatcher-2] INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor - Receive slot request abb2d60af522a7efe7c5b25971f711e7 for job 0d987a8aa41f83e9302c68a1cf021e48 from resource manager with leader id b4ec00fccd83cf0ae0e59a3f06114225.
2023-07-20 15:09:12.389 [flink-akka.actor.default-dispatcher-4] INFO  o.a.f.runtime.taskexecutor.DefaultJobLeaderService - Resolved JobManager address, beginning registration
2023-07-20 15:09:12.389 [flink-akka.actor.default-dispatcher-2] INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor - Allocated slot for abb2d60af522a7efe7c5b25971f711e7.
2023-07-20 15:09:12.390 [flink-akka.actor.default-dispatcher-2] INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor - Receive slot request ad84932c86454a8407f32d7980838dd3 for job 0d987a8aa41f83e9302c68a1cf021e48 from resource manager with leader id b4ec00fccd83cf0ae0e59a3f06114225.
2023-07-20 15:09:12.390 [flink-akka.actor.default-dispatcher-2] INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor - Allocated slot for ad84932c86454a8407f32d7980838dd3.
2023-07-20 15:09:12.390 [flink-akka.actor.default-dispatcher-2] INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor - Receive slot request 71e10da2aa6733156fa52c0139bb43fd for job 0d987a8aa41f83e9302c68a1cf021e48 from resource manager with leader id b4ec00fccd83cf0ae0e59a3f06114225.
2023-07-20 15:09:12.390 [flink-akka.actor.default-dispatcher-2] INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor - Allocated slot for 71e10da2aa6733156fa52c0139bb43fd.
2023-07-20 15:09:12.390 [flink-akka.actor.default-dispatcher-2] INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor - Receive slot request f476bca22bb8e802fef42a07adc89e4c for job 0d987a8aa41f83e9302c68a1cf021e48 from resource manager with leader id b4ec00fccd83cf0ae0e59a3f06114225.
2023-07-20 15:09:12.391 [flink-akka.actor.default-dispatcher-2] INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor - Allocated slot for f476bca22bb8e802fef42a07adc89e4c.
2023-07-20 15:09:12.391 [flink-akka.actor.default-dispatcher-2] INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor - Receive slot request 33a716b47d32580cabf4a7ba0d6b8e38 for job 0d987a8aa41f83e9302c68a1cf021e48 from resource manager with leader id b4ec00fccd83cf0ae0e59a3f06114225.
2023-07-20 15:09:12.391 [flink-akka.actor.default-dispatcher-2] INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor - Allocated slot for 33a716b47d32580cabf4a7ba0d6b8e38.
2023-07-20 15:09:12.391 [flink-akka.actor.default-dispatcher-2] INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor - Receive slot request 94b1cabb3de3b9067a2bb3f0c257ec9c for job 0d987a8aa41f83e9302c68a1cf021e48 from resource manager with leader id b4ec00fccd83cf0ae0e59a3f06114225.
2023-07-20 15:09:12.391 [flink-akka.actor.default-dispatcher-2] INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor - Allocated slot for 94b1cabb3de3b9067a2bb3f0c257ec9c.
2023-07-20 15:09:12.391 [flink-akka.actor.default-dispatcher-2] INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor - Receive slot request 3d6c0534e6e91dcb38eefd21177982d0 for job 0d987a8aa41f83e9302c68a1cf021e48 from resource manager with leader id b4ec00fccd83cf0ae0e59a3f06114225.
2023-07-20 15:09:12.392 [flink-akka.actor.default-dispatcher-2] INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor - Allocated slot for 3d6c0534e6e91dcb38eefd21177982d0.
2023-07-20 15:09:12.392 [flink-akka.actor.default-dispatcher-2] INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor - Receive slot request 8fd045c0ef2cf772b13a8c72804710f7 for job 0d987a8aa41f83e9302c68a1cf021e48 from resource manager with leader id b4ec00fccd83cf0ae0e59a3f06114225.
2023-07-20 15:09:12.392 [flink-akka.actor.default-dispatcher-2] INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor - Allocated slot for 8fd045c0ef2cf772b13a8c72804710f7.
2023-07-20 15:09:12.392 [flink-akka.actor.default-dispatcher-2] INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor - Receive slot request cd7788e0ba34f5c0e7848f34470ee594 for job 0d987a8aa41f83e9302c68a1cf021e48 from resource manager with leader id b4ec00fccd83cf0ae0e59a3f06114225.
2023-07-20 15:09:12.392 [flink-akka.actor.default-dispatcher-2] INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor - Allocated slot for cd7788e0ba34f5c0e7848f34470ee594.
2023-07-20 15:09:12.393 [flink-akka.actor.default-dispatcher-2] INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor - Receive slot request 32d4c9fffaf7fadd2bb9d27065bcda63 for job 0d987a8aa41f83e9302c68a1cf021e48 from resource manager with leader id b4ec00fccd83cf0ae0e59a3f06114225.
2023-07-20 15:09:12.393 [flink-akka.actor.default-dispatcher-2] INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor - Allocated slot for 32d4c9fffaf7fadd2bb9d27065bcda63.
2023-07-20 15:09:12.393 [flink-akka.actor.default-dispatcher-3] INFO  o.a.f.runtime.taskexecutor.DefaultJobLeaderService - Successful registration at job manager akka://flink/user/rpc/jobmanager_3 for job 0d987a8aa41f83e9302c68a1cf021e48.
2023-07-20 15:09:12.394 [flink-akka.actor.default-dispatcher-3] INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor - Establish JobManager connection for job 0d987a8aa41f83e9302c68a1cf021e48.
2023-07-20 15:09:12.396 [flink-akka.actor.default-dispatcher-3] INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor - Offer reserved slots to the leader of job 0d987a8aa41f83e9302c68a1cf021e48.
2023-07-20 15:09:12.399 [flink-akka.actor.default-dispatcher-4] INFO  o.a.flink.runtime.executiongraph.ExecutionGraph - Source: Custom Source -> Map -> Sink: Print to Std. Out (1/12) (26a0e88843a2e302f733846a1bc38770) switched from SCHEDULED to DEPLOYING.
2023-07-20 15:09:12.399 [flink-akka.actor.default-dispatcher-4] INFO  o.a.flink.runtime.executiongraph.ExecutionGraph - Deploying Source: Custom Source -> Map -> Sink: Print to Std. Out (1/12) (attempt #0) with attempt id 26a0e88843a2e302f733846a1bc38770 to c98b9cb4-8f6f-4d69-aa34-3d9453424d27 @ activate.navicat.com (dataPort=-1) with allocation id 33a716b47d32580cabf4a7ba0d6b8e38
2023-07-20 15:09:12.405 [flink-akka.actor.default-dispatcher-4] INFO  o.a.flink.runtime.executiongraph.ExecutionGraph - Source: Custom Source -> Map -> Sink: Print to Std. Out (2/12) (3ac85efa3053001b6efe102876248b41) switched from SCHEDULED to DEPLOYING.
2023-07-20 15:09:12.405 [flink-akka.actor.default-dispatcher-4] INFO  o.a.flink.runtime.executiongraph.ExecutionGraph - Deploying Source: Custom Source -> Map -> Sink: Print to Std. Out (2/12) (attempt #0) with attempt id 3ac85efa3053001b6efe102876248b41 to c98b9cb4-8f6f-4d69-aa34-3d9453424d27 @ activate.navicat.com (dataPort=-1) with allocation id ad84932c86454a8407f32d7980838dd3
2023-07-20 15:09:12.405 [flink-akka.actor.default-dispatcher-3] INFO  o.a.f.runtime.taskexecutor.slot.TaskSlotTableImpl - Activate slot 33a716b47d32580cabf4a7ba0d6b8e38.
2023-07-20 15:09:12.405 [flink-akka.actor.default-dispatcher-4] INFO  o.a.flink.runtime.executiongraph.ExecutionGraph - Source: Custom Source -> Map -> Sink: Print to Std. Out (3/12) (ee1f3acadf87491452e580a477c1162e) switched from SCHEDULED to DEPLOYING.
2023-07-20 15:09:12.405 [flink-akka.actor.default-dispatcher-4] INFO  o.a.flink.runtime.executiongraph.ExecutionGraph - Deploying Source: Custom Source -> Map -> Sink: Print to Std. Out (3/12) (attempt #0) with attempt id ee1f3acadf87491452e580a477c1162e to c98b9cb4-8f6f-4d69-aa34-3d9453424d27 @ activate.navicat.com (dataPort=-1) with allocation id 71e10da2aa6733156fa52c0139bb43fd
2023-07-20 15:09:12.405 [flink-akka.actor.default-dispatcher-4] INFO  o.a.flink.runtime.executiongraph.ExecutionGraph - Source: Custom Source -> Map -> Sink: Print to Std. Out (4/12) (a613a743e9e68f31e89be68e6c650d32) switched from SCHEDULED to DEPLOYING.
2023-07-20 15:09:12.405 [flink-akka.actor.default-dispatcher-4] INFO  o.a.flink.runtime.executiongraph.ExecutionGraph - Deploying Source: Custom Source -> Map -> Sink: Print to Std. Out (4/12) (attempt #0) with attempt id a613a743e9e68f31e89be68e6c650d32 to c98b9cb4-8f6f-4d69-aa34-3d9453424d27 @ activate.navicat.com (dataPort=-1) with allocation id b85fd339256b8f944b2ef60a232bc8d0
2023-07-20 15:09:12.405 [flink-akka.actor.default-dispatcher-4] INFO  o.a.flink.runtime.executiongraph.ExecutionGraph - Source: Custom Source -> Map -> Sink: Print to Std. Out (5/12) (9742eda81823099ae2ea798f963c29a1) switched from SCHEDULED to DEPLOYING.
2023-07-20 15:09:12.406 [flink-akka.actor.default-dispatcher-4] INFO  o.a.flink.runtime.executiongraph.ExecutionGraph - Deploying Source: Custom Source -> Map -> Sink: Print to Std. Out (5/12) (attempt #0) with attempt id 9742eda81823099ae2ea798f963c29a1 to c98b9cb4-8f6f-4d69-aa34-3d9453424d27 @ activate.navicat.com (dataPort=-1) with allocation id 8fd045c0ef2cf772b13a8c72804710f7
2023-07-20 15:09:12.406 [flink-akka.actor.default-dispatcher-4] INFO  o.a.flink.runtime.executiongraph.ExecutionGraph - Source: Custom Source -> Map -> Sink: Print to Std. Out (6/12) (5da6f0bd61008494b4ac696adfb35d7d) switched from SCHEDULED to DEPLOYING.
2023-07-20 15:09:12.406 [flink-akka.actor.default-dispatcher-4] INFO  o.a.flink.runtime.executiongraph.ExecutionGraph - Deploying Source: Custom Source -> Map -> Sink: Print to Std. Out (6/12) (attempt #0) with attempt id 5da6f0bd61008494b4ac696adfb35d7d to c98b9cb4-8f6f-4d69-aa34-3d9453424d27 @ activate.navicat.com (dataPort=-1) with allocation id 32d4c9fffaf7fadd2bb9d27065bcda63
2023-07-20 15:09:12.406 [flink-akka.actor.default-dispatcher-4] INFO  o.a.flink.runtime.executiongraph.ExecutionGraph - Source: Custom Source -> Map -> Sink: Print to Std. Out (7/12) (8f215c8a5c31cff2d5431d5f9a1ba908) switched from SCHEDULED to DEPLOYING.
2023-07-20 15:09:12.406 [flink-akka.actor.default-dispatcher-4] INFO  o.a.flink.runtime.executiongraph.ExecutionGraph - Deploying Source: Custom Source -> Map -> Sink: Print to Std. Out (7/12) (attempt #0) with attempt id 8f215c8a5c31cff2d5431d5f9a1ba908 to c98b9cb4-8f6f-4d69-aa34-3d9453424d27 @ activate.navicat.com (dataPort=-1) with allocation id abb2d60af522a7efe7c5b25971f711e7
2023-07-20 15:09:12.406 [flink-akka.actor.default-dispatcher-4] INFO  o.a.flink.runtime.executiongraph.ExecutionGraph - Source: Custom Source -> Map -> Sink: Print to Std. Out (8/12) (6f238e60f6fa20cad10485d0152c359a) switched from SCHEDULED to DEPLOYING.
2023-07-20 15:09:12.410 [flink-akka.actor.default-dispatcher-4] INFO  o.a.flink.runtime.executiongraph.ExecutionGraph - Deploying Source: Custom Source -> Map -> Sink: Print to Std. Out (8/12) (attempt #0) with attempt id 6f238e60f6fa20cad10485d0152c359a to c98b9cb4-8f6f-4d69-aa34-3d9453424d27 @ activate.navicat.com (dataPort=-1) with allocation id f476bca22bb8e802fef42a07adc89e4c
2023-07-20 15:09:12.411 [flink-akka.actor.default-dispatcher-4] INFO  o.a.flink.runtime.executiongraph.ExecutionGraph - Source: Custom Source -> Map -> Sink: Print to Std. Out (9/12) (e89e791ecd165a6a950a64261f0ac9b4) switched from SCHEDULED to DEPLOYING.
2023-07-20 15:09:12.411 [flink-akka.actor.default-dispatcher-4] INFO  o.a.flink.runtime.executiongraph.ExecutionGraph - Deploying Source: Custom Source -> Map -> Sink: Print to Std. Out (9/12) (attempt #0) with attempt id e89e791ecd165a6a950a64261f0ac9b4 to c98b9cb4-8f6f-4d69-aa34-3d9453424d27 @ activate.navicat.com (dataPort=-1) with allocation id cd7788e0ba34f5c0e7848f34470ee594
2023-07-20 15:09:12.411 [flink-akka.actor.default-dispatcher-4] INFO  o.a.flink.runtime.executiongraph.ExecutionGraph - Source: Custom Source -> Map -> Sink: Print to Std. Out (10/12) (045609b1983d728cbad3acf3e75eea54) switched from SCHEDULED to DEPLOYING.
2023-07-20 15:09:12.411 [flink-akka.actor.default-dispatcher-4] INFO  o.a.flink.runtime.executiongraph.ExecutionGraph - Deploying Source: Custom Source -> Map -> Sink: Print to Std. Out (10/12) (attempt #0) with attempt id 045609b1983d728cbad3acf3e75eea54 to c98b9cb4-8f6f-4d69-aa34-3d9453424d27 @ activate.navicat.com (dataPort=-1) with allocation id 7a84ed97655711dee0875a2bc20c2351
2023-07-20 15:09:12.411 [flink-akka.actor.default-dispatcher-4] INFO  o.a.flink.runtime.executiongraph.ExecutionGraph - Source: Custom Source -> Map -> Sink: Print to Std. Out (11/12) (5967cfdaa1c664c90b97685bf3653d8a) switched from SCHEDULED to DEPLOYING.
2023-07-20 15:09:12.411 [flink-akka.actor.default-dispatcher-4] INFO  o.a.flink.runtime.executiongraph.ExecutionGraph - Deploying Source: Custom Source -> Map -> Sink: Print to Std. Out (11/12) (attempt #0) with attempt id 5967cfdaa1c664c90b97685bf3653d8a to c98b9cb4-8f6f-4d69-aa34-3d9453424d27 @ activate.navicat.com (dataPort=-1) with allocation id 3d6c0534e6e91dcb38eefd21177982d0
2023-07-20 15:09:12.411 [flink-akka.actor.default-dispatcher-4] INFO  o.a.flink.runtime.executiongraph.ExecutionGraph - Source: Custom Source -> Map -> Sink: Print to Std. Out (12/12) (9c8cef33a7f5694b073ab4b1423e024b) switched from SCHEDULED to DEPLOYING.
2023-07-20 15:09:12.412 [flink-akka.actor.default-dispatcher-4] INFO  o.a.flink.runtime.executiongraph.ExecutionGraph - Deploying Source: Custom Source -> Map -> Sink: Print to Std. Out (12/12) (attempt #0) with attempt id 9c8cef33a7f5694b073ab4b1423e024b to c98b9cb4-8f6f-4d69-aa34-3d9453424d27 @ activate.navicat.com (dataPort=-1) with allocation id 94b1cabb3de3b9067a2bb3f0c257ec9c
2023-07-20 15:09:12.426 [flink-akka.actor.default-dispatcher-3] INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor - Received task Source: Custom Source -> Map -> Sink: Print to Std. Out (1/12)#0 (26a0e88843a2e302f733846a1bc38770), deploy into slot with allocation id 33a716b47d32580cabf4a7ba0d6b8e38.
2023-07-20 15:09:12.427 [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/12)#0] INFO  org.apache.flink.runtime.taskmanager.Task - Source: Custom Source -> Map -> Sink: Print to Std. Out (1/12)#0 (26a0e88843a2e302f733846a1bc38770) switched from CREATED to DEPLOYING.
2023-07-20 15:09:12.429 [flink-akka.actor.default-dispatcher-3] INFO  o.a.f.runtime.taskexecutor.slot.TaskSlotTableImpl - Activate slot ad84932c86454a8407f32d7980838dd3.
2023-07-20 15:09:12.430 [flink-akka.actor.default-dispatcher-3] INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor - Received task Source: Custom Source -> Map -> Sink: Print to Std. Out (2/12)#0 (3ac85efa3053001b6efe102876248b41), deploy into slot with allocation id ad84932c86454a8407f32d7980838dd3.
2023-07-20 15:09:12.430 [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/12)#0] INFO  org.apache.flink.runtime.taskmanager.Task - Loading JAR files for task Source: Custom Source -> Map -> Sink: Print to Std. Out (1/12)#0 (26a0e88843a2e302f733846a1bc38770) [DEPLOYING].
2023-07-20 15:09:12.431 [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/12)#0] INFO  org.apache.flink.runtime.taskmanager.Task - Source: Custom Source -> Map -> Sink: Print to Std. Out (2/12)#0 (3ac85efa3053001b6efe102876248b41) switched from CREATED to DEPLOYING.
2023-07-20 15:09:12.431 [flink-akka.actor.default-dispatcher-3] INFO  o.a.f.runtime.taskexecutor.slot.TaskSlotTableImpl - Activate slot 71e10da2aa6733156fa52c0139bb43fd.
2023-07-20 15:09:12.431 [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/12)#0] INFO  org.apache.flink.runtime.taskmanager.Task - Loading JAR files for task Source: Custom Source -> Map -> Sink: Print to Std. Out (2/12)#0 (3ac85efa3053001b6efe102876248b41) [DEPLOYING].
2023-07-20 15:09:12.431 [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/12)#0] INFO  org.apache.flink.runtime.taskmanager.Task - Registering task at network: Source: Custom Source -> Map -> Sink: Print to Std. Out (1/12)#0 (26a0e88843a2e302f733846a1bc38770) [DEPLOYING].
2023-07-20 15:09:12.432 [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/12)#0] INFO  org.apache.flink.runtime.taskmanager.Task - Registering task at network: Source: Custom Source -> Map -> Sink: Print to Std. Out (2/12)#0 (3ac85efa3053001b6efe102876248b41) [DEPLOYING].
2023-07-20 15:09:12.433 [flink-akka.actor.default-dispatcher-3] INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor - Received task Source: Custom Source -> Map -> Sink: Print to Std. Out (3/12)#0 (ee1f3acadf87491452e580a477c1162e), deploy into slot with allocation id 71e10da2aa6733156fa52c0139bb43fd.
2023-07-20 15:09:12.433 [flink-akka.actor.default-dispatcher-3] INFO  o.a.f.runtime.taskexecutor.slot.TaskSlotTableImpl - Activate slot b85fd339256b8f944b2ef60a232bc8d0.
2023-07-20 15:09:12.433 [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/12)#0] INFO  org.apache.flink.runtime.taskmanager.Task - Source: Custom Source -> Map -> Sink: Print to Std. Out (3/12)#0 (ee1f3acadf87491452e580a477c1162e) switched from CREATED to DEPLOYING.
2023-07-20 15:09:12.433 [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/12)#0] INFO  org.apache.flink.runtime.taskmanager.Task - Loading JAR files for task Source: Custom Source -> Map -> Sink: Print to Std. Out (3/12)#0 (ee1f3acadf87491452e580a477c1162e) [DEPLOYING].
2023-07-20 15:09:12.434 [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/12)#0] INFO  org.apache.flink.runtime.taskmanager.Task - Registering task at network: Source: Custom Source -> Map -> Sink: Print to Std. Out (3/12)#0 (ee1f3acadf87491452e580a477c1162e) [DEPLOYING].
2023-07-20 15:09:12.434 [flink-akka.actor.default-dispatcher-3] INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor - Received task Source: Custom Source -> Map -> Sink: Print to Std. Out (4/12)#0 (a613a743e9e68f31e89be68e6c650d32), deploy into slot with allocation id b85fd339256b8f944b2ef60a232bc8d0.
2023-07-20 15:09:12.434 [flink-akka.actor.default-dispatcher-3] INFO  o.a.f.runtime.taskexecutor.slot.TaskSlotTableImpl - Activate slot 8fd045c0ef2cf772b13a8c72804710f7.
2023-07-20 15:09:12.434 [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/12)#0] INFO  org.apache.flink.runtime.taskmanager.Task - Source: Custom Source -> Map -> Sink: Print to Std. Out (4/12)#0 (a613a743e9e68f31e89be68e6c650d32) switched from CREATED to DEPLOYING.
2023-07-20 15:09:12.435 [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/12)#0] INFO  org.apache.flink.runtime.taskmanager.Task - Loading JAR files for task Source: Custom Source -> Map -> Sink: Print to Std. Out (4/12)#0 (a613a743e9e68f31e89be68e6c650d32) [DEPLOYING].
2023-07-20 15:09:12.435 [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/12)#0] INFO  org.apache.flink.runtime.taskmanager.Task - Registering task at network: Source: Custom Source -> Map -> Sink: Print to Std. Out (4/12)#0 (a613a743e9e68f31e89be68e6c650d32) [DEPLOYING].
2023-07-20 15:09:12.436 [flink-akka.actor.default-dispatcher-3] INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor - Received task Source: Custom Source -> Map -> Sink: Print to Std. Out (5/12)#0 (9742eda81823099ae2ea798f963c29a1), deploy into slot with allocation id 8fd045c0ef2cf772b13a8c72804710f7.
2023-07-20 15:09:12.436 [flink-akka.actor.default-dispatcher-3] INFO  o.a.f.runtime.taskexecutor.slot.TaskSlotTableImpl - Activate slot 32d4c9fffaf7fadd2bb9d27065bcda63.
2023-07-20 15:09:12.436 [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/12)#0] INFO  org.apache.flink.runtime.taskmanager.Task - Source: Custom Source -> Map -> Sink: Print to Std. Out (5/12)#0 (9742eda81823099ae2ea798f963c29a1) switched from CREATED to DEPLOYING.
2023-07-20 15:09:12.436 [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/12)#0] INFO  org.apache.flink.runtime.taskmanager.Task - Loading JAR files for task Source: Custom Source -> Map -> Sink: Print to Std. Out (5/12)#0 (9742eda81823099ae2ea798f963c29a1) [DEPLOYING].
2023-07-20 15:09:12.437 [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/12)#0] INFO  org.apache.flink.runtime.taskmanager.Task - Registering task at network: Source: Custom Source -> Map -> Sink: Print to Std. Out (5/12)#0 (9742eda81823099ae2ea798f963c29a1) [DEPLOYING].
2023-07-20 15:09:12.437 [flink-akka.actor.default-dispatcher-3] INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor - Received task Source: Custom Source -> Map -> Sink: Print to Std. Out (6/12)#0 (5da6f0bd61008494b4ac696adfb35d7d), deploy into slot with allocation id 32d4c9fffaf7fadd2bb9d27065bcda63.
2023-07-20 15:09:12.437 [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/12)#0] INFO  org.apache.flink.runtime.taskmanager.Task - Source: Custom Source -> Map -> Sink: Print to Std. Out (6/12)#0 (5da6f0bd61008494b4ac696adfb35d7d) switched from CREATED to DEPLOYING.
2023-07-20 15:09:12.437 [flink-akka.actor.default-dispatcher-3] INFO  o.a.f.runtime.taskexecutor.slot.TaskSlotTableImpl - Activate slot abb2d60af522a7efe7c5b25971f711e7.
2023-07-20 15:09:12.437 [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/12)#0] INFO  org.apache.flink.runtime.taskmanager.Task - Loading JAR files for task Source: Custom Source -> Map -> Sink: Print to Std. Out (6/12)#0 (5da6f0bd61008494b4ac696adfb35d7d) [DEPLOYING].
2023-07-20 15:09:12.438 [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/12)#0] INFO  org.apache.flink.runtime.taskmanager.Task - Registering task at network: Source: Custom Source -> Map -> Sink: Print to Std. Out (6/12)#0 (5da6f0bd61008494b4ac696adfb35d7d) [DEPLOYING].
2023-07-20 15:09:12.439 [flink-akka.actor.default-dispatcher-3] INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor - Received task Source: Custom Source -> Map -> Sink: Print to Std. Out (7/12)#0 (8f215c8a5c31cff2d5431d5f9a1ba908), deploy into slot with allocation id abb2d60af522a7efe7c5b25971f711e7.
2023-07-20 15:09:12.439 [Source: Custom Source -> Map -> Sink: Print to Std. Out (7/12)#0] INFO  org.apache.flink.runtime.taskmanager.Task - Source: Custom Source -> Map -> Sink: Print to Std. Out (7/12)#0 (8f215c8a5c31cff2d5431d5f9a1ba908) switched from CREATED to DEPLOYING.
2023-07-20 15:09:12.439 [flink-akka.actor.default-dispatcher-3] INFO  o.a.f.runtime.taskexecutor.slot.TaskSlotTableImpl - Activate slot f476bca22bb8e802fef42a07adc89e4c.
2023-07-20 15:09:12.439 [Source: Custom Source -> Map -> Sink: Print to Std. Out (7/12)#0] INFO  org.apache.flink.runtime.taskmanager.Task - Loading JAR files for task Source: Custom Source -> Map -> Sink: Print to Std. Out (7/12)#0 (8f215c8a5c31cff2d5431d5f9a1ba908) [DEPLOYING].
2023-07-20 15:09:12.439 [Source: Custom Source -> Map -> Sink: Print to Std. Out (7/12)#0] INFO  org.apache.flink.runtime.taskmanager.Task - Registering task at network: Source: Custom Source -> Map -> Sink: Print to Std. Out (7/12)#0 (8f215c8a5c31cff2d5431d5f9a1ba908) [DEPLOYING].
2023-07-20 15:09:12.440 [flink-akka.actor.default-dispatcher-3] INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor - Received task Source: Custom Source -> Map -> Sink: Print to Std. Out (8/12)#0 (6f238e60f6fa20cad10485d0152c359a), deploy into slot with allocation id f476bca22bb8e802fef42a07adc89e4c.
2023-07-20 15:09:12.441 [Source: Custom Source -> Map -> Sink: Print to Std. Out (8/12)#0] INFO  org.apache.flink.runtime.taskmanager.Task - Source: Custom Source -> Map -> Sink: Print to Std. Out (8/12)#0 (6f238e60f6fa20cad10485d0152c359a) switched from CREATED to DEPLOYING.
2023-07-20 15:09:12.441 [flink-akka.actor.default-dispatcher-3] INFO  o.a.f.runtime.taskexecutor.slot.TaskSlotTableImpl - Activate slot cd7788e0ba34f5c0e7848f34470ee594.
2023-07-20 15:09:12.441 [Source: Custom Source -> Map -> Sink: Print to Std. Out (8/12)#0] INFO  org.apache.flink.runtime.taskmanager.Task - Loading JAR files for task Source: Custom Source -> Map -> Sink: Print to Std. Out (8/12)#0 (6f238e60f6fa20cad10485d0152c359a) [DEPLOYING].
2023-07-20 15:09:12.441 [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/12)#0] INFO  o.apache.flink.streaming.runtime.tasks.StreamTask - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2023-07-20 15:09:12.441 [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/12)#0] INFO  o.apache.flink.streaming.runtime.tasks.StreamTask - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2023-07-20 15:09:12.441 [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/12)#0] INFO  o.apache.flink.streaming.runtime.tasks.StreamTask - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2023-07-20 15:09:12.441 [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/12)#0] INFO  o.apache.flink.streaming.runtime.tasks.StreamTask - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2023-07-20 15:09:12.441 [Source: Custom Source -> Map -> Sink: Print to Std. Out (7/12)#0] INFO  o.apache.flink.streaming.runtime.tasks.StreamTask - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2023-07-20 15:09:12.441 [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/12)#0] INFO  o.apache.flink.streaming.runtime.tasks.StreamTask - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2023-07-20 15:09:12.441 [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/12)#0] INFO  o.apache.flink.streaming.runtime.tasks.StreamTask - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2023-07-20 15:09:12.442 [Source: Custom Source -> Map -> Sink: Print to Std. Out (8/12)#0] INFO  org.apache.flink.runtime.taskmanager.Task - Registering task at network: Source: Custom Source -> Map -> Sink: Print to Std. Out (8/12)#0 (6f238e60f6fa20cad10485d0152c359a) [DEPLOYING].
2023-07-20 15:09:12.442 [Source: Custom Source -> Map -> Sink: Print to Std. Out (8/12)#0] INFO  o.apache.flink.streaming.runtime.tasks.StreamTask - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2023-07-20 15:09:12.442 [flink-akka.actor.default-dispatcher-3] INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor - Received task Source: Custom Source -> Map -> Sink: Print to Std. Out (9/12)#0 (e89e791ecd165a6a950a64261f0ac9b4), deploy into slot with allocation id cd7788e0ba34f5c0e7848f34470ee594.
2023-07-20 15:09:12.442 [Source: Custom Source -> Map -> Sink: Print to Std. Out (9/12)#0] INFO  org.apache.flink.runtime.taskmanager.Task - Source: Custom Source -> Map -> Sink: Print to Std. Out (9/12)#0 (e89e791ecd165a6a950a64261f0ac9b4) switched from CREATED to DEPLOYING.
2023-07-20 15:09:12.442 [flink-akka.actor.default-dispatcher-3] INFO  o.a.f.runtime.taskexecutor.slot.TaskSlotTableImpl - Activate slot 7a84ed97655711dee0875a2bc20c2351.
2023-07-20 15:09:12.442 [Source: Custom Source -> Map -> Sink: Print to Std. Out (9/12)#0] INFO  org.apache.flink.runtime.taskmanager.Task - Loading JAR files for task Source: Custom Source -> Map -> Sink: Print to Std. Out (9/12)#0 (e89e791ecd165a6a950a64261f0ac9b4) [DEPLOYING].
2023-07-20 15:09:12.443 [Source: Custom Source -> Map -> Sink: Print to Std. Out (9/12)#0] INFO  org.apache.flink.runtime.taskmanager.Task - Registering task at network: Source: Custom Source -> Map -> Sink: Print to Std. Out (9/12)#0 (e89e791ecd165a6a950a64261f0ac9b4) [DEPLOYING].
2023-07-20 15:09:12.443 [Source: Custom Source -> Map -> Sink: Print to Std. Out (9/12)#0] INFO  o.apache.flink.streaming.runtime.tasks.StreamTask - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2023-07-20 15:09:12.444 [flink-akka.actor.default-dispatcher-3] INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor - Received task Source: Custom Source -> Map -> Sink: Print to Std. Out (10/12)#0 (045609b1983d728cbad3acf3e75eea54), deploy into slot with allocation id 7a84ed97655711dee0875a2bc20c2351.
2023-07-20 15:09:12.444 [flink-akka.actor.default-dispatcher-3] INFO  o.a.f.runtime.taskexecutor.slot.TaskSlotTableImpl - Activate slot 3d6c0534e6e91dcb38eefd21177982d0.
2023-07-20 15:09:12.444 [Source: Custom Source -> Map -> Sink: Print to Std. Out (10/12)#0] INFO  org.apache.flink.runtime.taskmanager.Task - Source: Custom Source -> Map -> Sink: Print to Std. Out (10/12)#0 (045609b1983d728cbad3acf3e75eea54) switched from CREATED to DEPLOYING.
2023-07-20 15:09:12.444 [Source: Custom Source -> Map -> Sink: Print to Std. Out (10/12)#0] INFO  org.apache.flink.runtime.taskmanager.Task - Loading JAR files for task Source: Custom Source -> Map -> Sink: Print to Std. Out (10/12)#0 (045609b1983d728cbad3acf3e75eea54) [DEPLOYING].
2023-07-20 15:09:12.445 [Source: Custom Source -> Map -> Sink: Print to Std. Out (10/12)#0] INFO  org.apache.flink.runtime.taskmanager.Task - Registering task at network: Source: Custom Source -> Map -> Sink: Print to Std. Out (10/12)#0 (045609b1983d728cbad3acf3e75eea54) [DEPLOYING].
2023-07-20 15:09:12.445 [Source: Custom Source -> Map -> Sink: Print to Std. Out (10/12)#0] INFO  o.apache.flink.streaming.runtime.tasks.StreamTask - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2023-07-20 15:09:12.445 [flink-akka.actor.default-dispatcher-3] INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor - Received task Source: Custom Source -> Map -> Sink: Print to Std. Out (11/12)#0 (5967cfdaa1c664c90b97685bf3653d8a), deploy into slot with allocation id 3d6c0534e6e91dcb38eefd21177982d0.
2023-07-20 15:09:12.446 [Source: Custom Source -> Map -> Sink: Print to Std. Out (11/12)#0] INFO  org.apache.flink.runtime.taskmanager.Task - Source: Custom Source -> Map -> Sink: Print to Std. Out (11/12)#0 (5967cfdaa1c664c90b97685bf3653d8a) switched from CREATED to DEPLOYING.
2023-07-20 15:09:12.446 [flink-akka.actor.default-dispatcher-3] INFO  o.a.f.runtime.taskexecutor.slot.TaskSlotTableImpl - Activate slot 94b1cabb3de3b9067a2bb3f0c257ec9c.
2023-07-20 15:09:12.446 [Source: Custom Source -> Map -> Sink: Print to Std. Out (11/12)#0] INFO  org.apache.flink.runtime.taskmanager.Task - Loading JAR files for task Source: Custom Source -> Map -> Sink: Print to Std. Out (11/12)#0 (5967cfdaa1c664c90b97685bf3653d8a) [DEPLOYING].
2023-07-20 15:09:12.446 [Source: Custom Source -> Map -> Sink: Print to Std. Out (11/12)#0] INFO  org.apache.flink.runtime.taskmanager.Task - Registering task at network: Source: Custom Source -> Map -> Sink: Print to Std. Out (11/12)#0 (5967cfdaa1c664c90b97685bf3653d8a) [DEPLOYING].
2023-07-20 15:09:12.446 [Source: Custom Source -> Map -> Sink: Print to Std. Out (11/12)#0] INFO  o.apache.flink.streaming.runtime.tasks.StreamTask - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2023-07-20 15:09:12.447 [Source: Custom Source -> Map -> Sink: Print to Std. Out (10/12)#0] INFO  org.apache.flink.runtime.taskmanager.Task - Source: Custom Source -> Map -> Sink: Print to Std. Out (10/12)#0 (045609b1983d728cbad3acf3e75eea54) switched from DEPLOYING to RUNNING.
2023-07-20 15:09:12.447 [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/12)#0] INFO  org.apache.flink.runtime.taskmanager.Task - Source: Custom Source -> Map -> Sink: Print to Std. Out (1/12)#0 (26a0e88843a2e302f733846a1bc38770) switched from DEPLOYING to RUNNING.
2023-07-20 15:09:12.447 [Source: Custom Source -> Map -> Sink: Print to Std. Out (9/12)#0] INFO  org.apache.flink.runtime.taskmanager.Task - Source: Custom Source -> Map -> Sink: Print to Std. Out (9/12)#0 (e89e791ecd165a6a950a64261f0ac9b4) switched from DEPLOYING to RUNNING.
2023-07-20 15:09:12.447 [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/12)#0] INFO  org.apache.flink.runtime.taskmanager.Task - Source: Custom Source -> Map -> Sink: Print to Std. Out (3/12)#0 (ee1f3acadf87491452e580a477c1162e) switched from DEPLOYING to RUNNING.
2023-07-20 15:09:12.447 [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/12)#0] INFO  org.apache.flink.runtime.taskmanager.Task - Source: Custom Source -> Map -> Sink: Print to Std. Out (2/12)#0 (3ac85efa3053001b6efe102876248b41) switched from DEPLOYING to RUNNING.
2023-07-20 15:09:12.447 [Source: Custom Source -> Map -> Sink: Print to Std. Out (8/12)#0] INFO  org.apache.flink.runtime.taskmanager.Task - Source: Custom Source -> Map -> Sink: Print to Std. Out (8/12)#0 (6f238e60f6fa20cad10485d0152c359a) switched from DEPLOYING to RUNNING.
2023-07-20 15:09:12.447 [Source: Custom Source -> Map -> Sink: Print to Std. Out (7/12)#0] INFO  org.apache.flink.runtime.taskmanager.Task - Source: Custom Source -> Map -> Sink: Print to Std. Out (7/12)#0 (8f215c8a5c31cff2d5431d5f9a1ba908) switched from DEPLOYING to RUNNING.
2023-07-20 15:09:12.447 [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/12)#0] INFO  org.apache.flink.runtime.taskmanager.Task - Source: Custom Source -> Map -> Sink: Print to Std. Out (4/12)#0 (a613a743e9e68f31e89be68e6c650d32) switched from DEPLOYING to RUNNING.
2023-07-20 15:09:12.447 [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/12)#0] INFO  org.apache.flink.runtime.taskmanager.Task - Source: Custom Source -> Map -> Sink: Print to Std. Out (6/12)#0 (5da6f0bd61008494b4ac696adfb35d7d) switched from DEPLOYING to RUNNING.
2023-07-20 15:09:12.447 [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/12)#0] INFO  org.apache.flink.runtime.taskmanager.Task - Source: Custom Source -> Map -> Sink: Print to Std. Out (5/12)#0 (9742eda81823099ae2ea798f963c29a1) switched from DEPLOYING to RUNNING.
2023-07-20 15:09:12.448 [flink-akka.actor.default-dispatcher-3] INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor - Received task Source: Custom Source -> Map -> Sink: Print to Std. Out (12/12)#0 (9c8cef33a7f5694b073ab4b1423e024b), deploy into slot with allocation id 94b1cabb3de3b9067a2bb3f0c257ec9c.
2023-07-20 15:09:12.447 [Source: Custom Source -> Map -> Sink: Print to Std. Out (11/12)#0] INFO  org.apache.flink.runtime.taskmanager.Task - Source: Custom Source -> Map -> Sink: Print to Std. Out (11/12)#0 (5967cfdaa1c664c90b97685bf3653d8a) switched from DEPLOYING to RUNNING.
2023-07-20 15:09:12.448 [Source: Custom Source -> Map -> Sink: Print to Std. Out (12/12)#0] INFO  org.apache.flink.runtime.taskmanager.Task - Source: Custom Source -> Map -> Sink: Print to Std. Out (12/12)#0 (9c8cef33a7f5694b073ab4b1423e024b) switched from CREATED to DEPLOYING.
2023-07-20 15:09:12.448 [Source: Custom Source -> Map -> Sink: Print to Std. Out (12/12)#0] INFO  org.apache.flink.runtime.taskmanager.Task - Loading JAR files for task Source: Custom Source -> Map -> Sink: Print to Std. Out (12/12)#0 (9c8cef33a7f5694b073ab4b1423e024b) [DEPLOYING].
2023-07-20 15:09:12.448 [flink-akka.actor.default-dispatcher-3] INFO  o.a.f.runtime.taskexecutor.slot.TaskSlotTableImpl - Activate slot 33a716b47d32580cabf4a7ba0d6b8e38.
2023-07-20 15:09:12.449 [flink-akka.actor.default-dispatcher-3] INFO  o.a.f.runtime.taskexecutor.slot.TaskSlotTableImpl - Activate slot ad84932c86454a8407f32d7980838dd3.
2023-07-20 15:09:12.449 [flink-akka.actor.default-dispatcher-3] INFO  o.a.f.runtime.taskexecutor.slot.TaskSlotTableImpl - Activate slot 71e10da2aa6733156fa52c0139bb43fd.
2023-07-20 15:09:12.449 [flink-akka.actor.default-dispatcher-3] INFO  o.a.f.runtime.taskexecutor.slot.TaskSlotTableImpl - Activate slot b85fd339256b8f944b2ef60a232bc8d0.
2023-07-20 15:09:12.449 [flink-akka.actor.default-dispatcher-3] INFO  o.a.f.runtime.taskexecutor.slot.TaskSlotTableImpl - Activate slot 8fd045c0ef2cf772b13a8c72804710f7.
2023-07-20 15:09:12.449 [flink-akka.actor.default-dispatcher-3] INFO  o.a.f.runtime.taskexecutor.slot.TaskSlotTableImpl - Activate slot 32d4c9fffaf7fadd2bb9d27065bcda63.
2023-07-20 15:09:12.449 [flink-akka.actor.default-dispatcher-3] INFO  o.a.f.runtime.taskexecutor.slot.TaskSlotTableImpl - Activate slot abb2d60af522a7efe7c5b25971f711e7.
2023-07-20 15:09:12.449 [flink-akka.actor.default-dispatcher-3] INFO  o.a.f.runtime.taskexecutor.slot.TaskSlotTableImpl - Activate slot f476bca22bb8e802fef42a07adc89e4c.
2023-07-20 15:09:12.449 [flink-akka.actor.default-dispatcher-3] INFO  o.a.f.runtime.taskexecutor.slot.TaskSlotTableImpl - Activate slot cd7788e0ba34f5c0e7848f34470ee594.
2023-07-20 15:09:12.449 [flink-akka.actor.default-dispatcher-6] INFO  o.a.flink.runtime.executiongraph.ExecutionGraph - Source: Custom Source -> Map -> Sink: Print to Std. Out (3/12) (ee1f3acadf87491452e580a477c1162e) switched from DEPLOYING to RUNNING.
2023-07-20 15:09:12.449 [flink-akka.actor.default-dispatcher-3] INFO  o.a.f.runtime.taskexecutor.slot.TaskSlotTableImpl - Activate slot 7a84ed97655711dee0875a2bc20c2351.
2023-07-20 15:09:12.449 [flink-akka.actor.default-dispatcher-3] INFO  o.a.f.runtime.taskexecutor.slot.TaskSlotTableImpl - Activate slot 3d6c0534e6e91dcb38eefd21177982d0.
2023-07-20 15:09:12.449 [flink-akka.actor.default-dispatcher-3] INFO  o.a.f.runtime.taskexecutor.slot.TaskSlotTableImpl - Activate slot 94b1cabb3de3b9067a2bb3f0c257ec9c.
2023-07-20 15:09:12.449 [Source: Custom Source -> Map -> Sink: Print to Std. Out (12/12)#0] INFO  org.apache.flink.runtime.taskmanager.Task - Registering task at network: Source: Custom Source -> Map -> Sink: Print to Std. Out (12/12)#0 (9c8cef33a7f5694b073ab4b1423e024b) [DEPLOYING].
2023-07-20 15:09:12.450 [flink-akka.actor.default-dispatcher-6] INFO  o.a.flink.runtime.executiongraph.ExecutionGraph - Source: Custom Source -> Map -> Sink: Print to Std. Out (10/12) (045609b1983d728cbad3acf3e75eea54) switched from DEPLOYING to RUNNING.
2023-07-20 15:09:12.450 [Source: Custom Source -> Map -> Sink: Print to Std. Out (12/12)#0] INFO  o.apache.flink.streaming.runtime.tasks.StreamTask - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2023-07-20 15:09:12.450 [flink-akka.actor.default-dispatcher-6] INFO  o.a.flink.runtime.executiongraph.ExecutionGraph - Source: Custom Source -> Map -> Sink: Print to Std. Out (9/12) (e89e791ecd165a6a950a64261f0ac9b4) switched from DEPLOYING to RUNNING.
2023-07-20 15:09:12.450 [flink-akka.actor.default-dispatcher-6] INFO  o.a.flink.runtime.executiongraph.ExecutionGraph - Source: Custom Source -> Map -> Sink: Print to Std. Out (2/12) (3ac85efa3053001b6efe102876248b41) switched from DEPLOYING to RUNNING.
2023-07-20 15:09:12.450 [Source: Custom Source -> Map -> Sink: Print to Std. Out (12/12)#0] INFO  org.apache.flink.runtime.taskmanager.Task - Source: Custom Source -> Map -> Sink: Print to Std. Out (12/12)#0 (9c8cef33a7f5694b073ab4b1423e024b) switched from DEPLOYING to RUNNING.
2023-07-20 15:09:12.450 [flink-akka.actor.default-dispatcher-6] INFO  o.a.flink.runtime.executiongraph.ExecutionGraph - Source: Custom Source -> Map -> Sink: Print to Std. Out (1/12) (26a0e88843a2e302f733846a1bc38770) switched from DEPLOYING to RUNNING.
2023-07-20 15:09:12.450 [flink-akka.actor.default-dispatcher-6] INFO  o.a.flink.runtime.executiongraph.ExecutionGraph - Source: Custom Source -> Map -> Sink: Print to Std. Out (8/12) (6f238e60f6fa20cad10485d0152c359a) switched from DEPLOYING to RUNNING.
2023-07-20 15:09:12.450 [flink-akka.actor.default-dispatcher-6] INFO  o.a.flink.runtime.executiongraph.ExecutionGraph - Source: Custom Source -> Map -> Sink: Print to Std. Out (7/12) (8f215c8a5c31cff2d5431d5f9a1ba908) switched from DEPLOYING to RUNNING.
2023-07-20 15:09:12.451 [flink-akka.actor.default-dispatcher-6] INFO  o.a.flink.runtime.executiongraph.ExecutionGraph - Source: Custom Source -> Map -> Sink: Print to Std. Out (4/12) (a613a743e9e68f31e89be68e6c650d32) switched from DEPLOYING to RUNNING.
2023-07-20 15:09:12.451 [flink-akka.actor.default-dispatcher-6] INFO  o.a.flink.runtime.executiongraph.ExecutionGraph - Source: Custom Source -> Map -> Sink: Print to Std. Out (6/12) (5da6f0bd61008494b4ac696adfb35d7d) switched from DEPLOYING to RUNNING.
2023-07-20 15:09:12.451 [flink-akka.actor.default-dispatcher-6] INFO  o.a.flink.runtime.executiongraph.ExecutionGraph - Source: Custom Source -> Map -> Sink: Print to Std. Out (5/12) (9742eda81823099ae2ea798f963c29a1) switched from DEPLOYING to RUNNING.
2023-07-20 15:09:12.451 [flink-akka.actor.default-dispatcher-6] INFO  o.a.flink.runtime.executiongraph.ExecutionGraph - Source: Custom Source -> Map -> Sink: Print to Std. Out (11/12) (5967cfdaa1c664c90b97685bf3653d8a) switched from DEPLOYING to RUNNING.
2023-07-20 15:09:12.451 [flink-akka.actor.default-dispatcher-6] INFO  o.a.flink.runtime.executiongraph.ExecutionGraph - Source: Custom Source -> Map -> Sink: Print to Std. Out (12/12) (9c8cef33a7f5694b073ab4b1423e024b) switched from DEPLOYING to RUNNING.
2023-07-20 15:09:12.549 [Source: Custom Source -> Map -> Sink: Print to Std. Out (7/12)#0] INFO  o.a.f.s.connectors.kafka.FlinkKafkaConsumerBase - Consumer subtask 6 has no restore state.
2023-07-20 15:09:12.549 [Source: Custom Source -> Map -> Sink: Print to Std. Out (11/12)#0] INFO  o.a.f.s.connectors.kafka.FlinkKafkaConsumerBase - Consumer subtask 10 has no restore state.
2023-07-20 15:09:12.549 [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/12)#0] INFO  o.a.f.s.connectors.kafka.FlinkKafkaConsumerBase - Consumer subtask 4 has no restore state.
2023-07-20 15:09:12.549 [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/12)#0] INFO  o.a.f.s.connectors.kafka.FlinkKafkaConsumerBase - Consumer subtask 3 has no restore state.
2023-07-20 15:09:12.549 [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/12)#0] INFO  o.a.f.s.connectors.kafka.FlinkKafkaConsumerBase - Consumer subtask 2 has no restore state.
2023-07-20 15:09:12.549 [Source: Custom Source -> Map -> Sink: Print to Std. Out (12/12)#0] INFO  o.a.f.s.connectors.kafka.FlinkKafkaConsumerBase - Consumer subtask 11 has no restore state.
2023-07-20 15:09:12.549 [Source: Custom Source -> Map -> Sink: Print to Std. Out (8/12)#0] INFO  o.a.f.s.connectors.kafka.FlinkKafkaConsumerBase - Consumer subtask 7 has no restore state.
2023-07-20 15:09:12.549 [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/12)#0] INFO  o.a.f.s.connectors.kafka.FlinkKafkaConsumerBase - Consumer subtask 1 has no restore state.
2023-07-20 15:09:12.549 [Source: Custom Source -> Map -> Sink: Print to Std. Out (9/12)#0] INFO  o.a.f.s.connectors.kafka.FlinkKafkaConsumerBase - Consumer subtask 8 has no restore state.
2023-07-20 15:09:12.549 [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/12)#0] INFO  o.a.f.s.connectors.kafka.FlinkKafkaConsumerBase - Consumer subtask 5 has no restore state.
2023-07-20 15:09:12.549 [Source: Custom Source -> Map -> Sink: Print to Std. Out (10/12)#0] INFO  o.a.f.s.connectors.kafka.FlinkKafkaConsumerBase - Consumer subtask 9 has no restore state.
2023-07-20 15:09:12.549 [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/12)#0] INFO  o.a.f.s.connectors.kafka.FlinkKafkaConsumerBase - Consumer subtask 0 has no restore state.
2023-07-20 15:09:12.604 [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/12)#0] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-flink-11
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2023-07-20 15:09:12.604 [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/12)#0] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-flink-10
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2023-07-20 15:09:12.604 [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/12)#0] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-flink-4
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2023-07-20 15:09:12.604 [Source: Custom Source -> Map -> Sink: Print to Std. Out (12/12)#0] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-flink-9
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2023-07-20 15:09:12.605 [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/12)#0] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-flink-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2023-07-20 15:09:12.604 [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/12)#0] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-flink-7
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2023-07-20 15:09:12.604 [Source: Custom Source -> Map -> Sink: Print to Std. Out (9/12)#0] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-flink-6
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2023-07-20 15:09:12.604 [Source: Custom Source -> Map -> Sink: Print to Std. Out (7/12)#0] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-flink-12
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2023-07-20 15:09:12.604 [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/12)#0] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-flink-8
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2023-07-20 15:09:12.604 [Source: Custom Source -> Map -> Sink: Print to Std. Out (8/12)#0] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-flink-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2023-07-20 15:09:12.604 [Source: Custom Source -> Map -> Sink: Print to Std. Out (10/12)#0] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-flink-3
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2023-07-20 15:09:12.604 [Source: Custom Source -> Map -> Sink: Print to Std. Out (11/12)#0] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-flink-5
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2023-07-20 15:09:12.709 [Source: Custom Source -> Map -> Sink: Print to Std. Out (11/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.7.1
2023-07-20 15:09:12.710 [Source: Custom Source -> Map -> Sink: Print to Std. Out (11/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 61dbce85d0d41457
2023-07-20 15:09:12.710 [Source: Custom Source -> Map -> Sink: Print to Std. Out (11/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1689836952708
2023-07-20 15:09:12.711 [Source: Custom Source -> Map -> Sink: Print to Std. Out (12/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.7.1
2023-07-20 15:09:12.711 [Source: Custom Source -> Map -> Sink: Print to Std. Out (12/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 61dbce85d0d41457
2023-07-20 15:09:12.711 [Source: Custom Source -> Map -> Sink: Print to Std. Out (12/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1689836952708
2023-07-20 15:09:12.711 [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.7.1
2023-07-20 15:09:12.711 [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 61dbce85d0d41457
2023-07-20 15:09:12.711 [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1689836952708
2023-07-20 15:09:12.711 [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.7.1
2023-07-20 15:09:12.711 [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 61dbce85d0d41457
2023-07-20 15:09:12.711 [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1689836952708
2023-07-20 15:09:12.711 [Source: Custom Source -> Map -> Sink: Print to Std. Out (9/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.7.1
2023-07-20 15:09:12.712 [Source: Custom Source -> Map -> Sink: Print to Std. Out (9/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 61dbce85d0d41457
2023-07-20 15:09:12.712 [Source: Custom Source -> Map -> Sink: Print to Std. Out (9/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1689836952708
2023-07-20 15:09:12.712 [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.7.1
2023-07-20 15:09:12.712 [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 61dbce85d0d41457
2023-07-20 15:09:12.712 [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1689836952708
2023-07-20 15:09:12.712 [Source: Custom Source -> Map -> Sink: Print to Std. Out (10/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.7.1
2023-07-20 15:09:12.712 [Source: Custom Source -> Map -> Sink: Print to Std. Out (10/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 61dbce85d0d41457
2023-07-20 15:09:12.712 [Source: Custom Source -> Map -> Sink: Print to Std. Out (10/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1689836952709
2023-07-20 15:09:12.712 [Source: Custom Source -> Map -> Sink: Print to Std. Out (8/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.7.1
2023-07-20 15:09:12.712 [Source: Custom Source -> Map -> Sink: Print to Std. Out (8/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 61dbce85d0d41457
2023-07-20 15:09:12.712 [Source: Custom Source -> Map -> Sink: Print to Std. Out (8/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1689836952708
2023-07-20 15:09:12.712 [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.7.1
2023-07-20 15:09:12.712 [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 61dbce85d0d41457
2023-07-20 15:09:12.712 [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1689836952708
2023-07-20 15:09:12.712 [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.7.1
2023-07-20 15:09:12.712 [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 61dbce85d0d41457
2023-07-20 15:09:12.712 [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1689836952708
2023-07-20 15:09:12.712 [Source: Custom Source -> Map -> Sink: Print to Std. Out (7/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.7.1
2023-07-20 15:09:12.712 [Source: Custom Source -> Map -> Sink: Print to Std. Out (7/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 61dbce85d0d41457
2023-07-20 15:09:12.713 [Source: Custom Source -> Map -> Sink: Print to Std. Out (7/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1689836952708
2023-07-20 15:09:12.713 [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.7.1
2023-07-20 15:09:12.713 [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 61dbce85d0d41457
2023-07-20 15:09:12.713 [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1689836952709
2023-07-20 15:09:13.077 [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/12)#0] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-flink-2, groupId=flink] Cluster ID: qYheim3NRmyUgYYzRu7BeQ
2023-07-20 15:09:13.077 [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/12)#0] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-flink-8, groupId=flink] Cluster ID: qYheim3NRmyUgYYzRu7BeQ
2023-07-20 15:09:13.077 [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/12)#0] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-flink-7, groupId=flink] Cluster ID: qYheim3NRmyUgYYzRu7BeQ
2023-07-20 15:09:13.077 [Source: Custom Source -> Map -> Sink: Print to Std. Out (9/12)#0] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-flink-6, groupId=flink] Cluster ID: qYheim3NRmyUgYYzRu7BeQ
2023-07-20 15:09:13.077 [Source: Custom Source -> Map -> Sink: Print to Std. Out (8/12)#0] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-flink-1, groupId=flink] Cluster ID: qYheim3NRmyUgYYzRu7BeQ
2023-07-20 15:09:13.077 [Source: Custom Source -> Map -> Sink: Print to Std. Out (7/12)#0] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-flink-12, groupId=flink] Cluster ID: qYheim3NRmyUgYYzRu7BeQ
2023-07-20 15:09:13.077 [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/12)#0] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-flink-10, groupId=flink] Cluster ID: qYheim3NRmyUgYYzRu7BeQ
2023-07-20 15:09:13.077 [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/12)#0] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-flink-11, groupId=flink] Cluster ID: qYheim3NRmyUgYYzRu7BeQ
2023-07-20 15:09:13.077 [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/12)#0] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-flink-4, groupId=flink] Cluster ID: qYheim3NRmyUgYYzRu7BeQ
2023-07-20 15:09:13.077 [Source: Custom Source -> Map -> Sink: Print to Std. Out (10/12)#0] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-flink-3, groupId=flink] Cluster ID: qYheim3NRmyUgYYzRu7BeQ
2023-07-20 15:09:13.077 [Source: Custom Source -> Map -> Sink: Print to Std. Out (11/12)#0] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-flink-5, groupId=flink] Cluster ID: qYheim3NRmyUgYYzRu7BeQ
2023-07-20 15:09:13.077 [Source: Custom Source -> Map -> Sink: Print to Std. Out (12/12)#0] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-flink-9, groupId=flink] Cluster ID: qYheim3NRmyUgYYzRu7BeQ
2023-07-20 15:09:13.081 [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/12)#0] INFO  o.a.f.s.connectors.kafka.FlinkKafkaConsumerBase - Consumer subtask 5 initially has no partitions to read from.
2023-07-20 15:09:13.081 [Source: Custom Source -> Map -> Sink: Print to Std. Out (12/12)#0] INFO  o.a.f.s.connectors.kafka.FlinkKafkaConsumerBase - Consumer subtask 11 initially has no partitions to read from.
2023-07-20 15:09:13.081 [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/12)#0] INFO  o.a.f.s.connectors.kafka.FlinkKafkaConsumerBase - Consumer subtask 3 initially has no partitions to read from.
2023-07-20 15:09:13.081 [Source: Custom Source -> Map -> Sink: Print to Std. Out (7/12)#0] INFO  o.a.f.s.connectors.kafka.FlinkKafkaConsumerBase - Consumer subtask 6 will start reading the following 1 partitions from the committed group offsets in Kafka: [KafkaTopicPartition{topic='topic001', partition=0}]
2023-07-20 15:09:13.081 [Source: Custom Source -> Map -> Sink: Print to Std. Out (8/12)#0] INFO  o.a.f.s.connectors.kafka.FlinkKafkaConsumerBase - Consumer subtask 7 initially has no partitions to read from.
2023-07-20 15:09:13.081 [Source: Custom Source -> Map -> Sink: Print to Std. Out (11/12)#0] INFO  o.a.f.s.connectors.kafka.FlinkKafkaConsumerBase - Consumer subtask 10 initially has no partitions to read from.
2023-07-20 15:09:13.081 [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/12)#0] INFO  o.a.f.s.connectors.kafka.FlinkKafkaConsumerBase - Consumer subtask 2 initially has no partitions to read from.
2023-07-20 15:09:13.081 [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/12)#0] INFO  o.a.f.s.connectors.kafka.FlinkKafkaConsumerBase - Consumer subtask 4 initially has no partitions to read from.
2023-07-20 15:09:13.081 [Source: Custom Source -> Map -> Sink: Print to Std. Out (10/12)#0] INFO  o.a.f.s.connectors.kafka.FlinkKafkaConsumerBase - Consumer subtask 9 initially has no partitions to read from.
2023-07-20 15:09:13.081 [Source: Custom Source -> Map -> Sink: Print to Std. Out (9/12)#0] INFO  o.a.f.s.connectors.kafka.FlinkKafkaConsumerBase - Consumer subtask 8 initially has no partitions to read from.
2023-07-20 15:09:13.081 [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/12)#0] INFO  o.a.f.s.connectors.kafka.FlinkKafkaConsumerBase - Consumer subtask 0 initially has no partitions to read from.
2023-07-20 15:09:13.081 [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/12)#0] INFO  o.a.f.s.connectors.kafka.FlinkKafkaConsumerBase - Consumer subtask 1 initially has no partitions to read from.
2023-07-20 15:09:13.097 [Legacy Source Thread - Source: Custom Source -> Map -> Sink: Print to Std. Out (3/12)#0] INFO  o.a.f.s.connectors.kafka.FlinkKafkaConsumerBase - Consumer subtask 2 creating fetcher with offsets {}.
2023-07-20 15:09:13.098 [Legacy Source Thread - Source: Custom Source -> Map -> Sink: Print to Std. Out (11/12)#0] INFO  o.a.f.s.connectors.kafka.FlinkKafkaConsumerBase - Consumer subtask 10 creating fetcher with offsets {}.
2023-07-20 15:09:13.097 [Legacy Source Thread - Source: Custom Source -> Map -> Sink: Print to Std. Out (2/12)#0] INFO  o.a.f.s.connectors.kafka.FlinkKafkaConsumerBase - Consumer subtask 1 creating fetcher with offsets {}.
2023-07-20 15:09:13.097 [Legacy Source Thread - Source: Custom Source -> Map -> Sink: Print to Std. Out (7/12)#0] INFO  o.a.f.s.connectors.kafka.FlinkKafkaConsumerBase - Consumer subtask 6 creating fetcher with offsets {KafkaTopicPartition{topic='topic001', partition=0}=-915623761773}.
2023-07-20 15:09:13.097 [Legacy Source Thread - Source: Custom Source -> Map -> Sink: Print to Std. Out (8/12)#0] INFO  o.a.f.s.connectors.kafka.FlinkKafkaConsumerBase - Consumer subtask 7 creating fetcher with offsets {}.
2023-07-20 15:09:13.097 [Legacy Source Thread - Source: Custom Source -> Map -> Sink: Print to Std. Out (12/12)#0] INFO  o.a.f.s.connectors.kafka.FlinkKafkaConsumerBase - Consumer subtask 11 creating fetcher with offsets {}.
2023-07-20 15:09:13.097 [Legacy Source Thread - Source: Custom Source -> Map -> Sink: Print to Std. Out (5/12)#0] INFO  o.a.f.s.connectors.kafka.FlinkKafkaConsumerBase - Consumer subtask 4 creating fetcher with offsets {}.
2023-07-20 15:09:13.097 [Legacy Source Thread - Source: Custom Source -> Map -> Sink: Print to Std. Out (4/12)#0] INFO  o.a.f.s.connectors.kafka.FlinkKafkaConsumerBase - Consumer subtask 3 creating fetcher with offsets {}.
2023-07-20 15:09:13.097 [Legacy Source Thread - Source: Custom Source -> Map -> Sink: Print to Std. Out (9/12)#0] INFO  o.a.f.s.connectors.kafka.FlinkKafkaConsumerBase - Consumer subtask 8 creating fetcher with offsets {}.
2023-07-20 15:09:13.097 [Legacy Source Thread - Source: Custom Source -> Map -> Sink: Print to Std. Out (10/12)#0] INFO  o.a.f.s.connectors.kafka.FlinkKafkaConsumerBase - Consumer subtask 9 creating fetcher with offsets {}.
2023-07-20 15:09:13.097 [Legacy Source Thread - Source: Custom Source -> Map -> Sink: Print to Std. Out (1/12)#0] INFO  o.a.f.s.connectors.kafka.FlinkKafkaConsumerBase - Consumer subtask 0 creating fetcher with offsets {}.
2023-07-20 15:09:13.098 [Legacy Source Thread - Source: Custom Source -> Map -> Sink: Print to Std. Out (6/12)#0] INFO  o.a.f.s.connectors.kafka.FlinkKafkaConsumerBase - Consumer subtask 5 creating fetcher with offsets {}.
2023-07-20 15:09:13.105 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (6/12)#0] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-flink-14
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2023-07-20 15:09:13.105 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (8/12)#0] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-flink-15
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2023-07-20 15:09:13.105 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (11/12)#0] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-flink-16
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2023-07-20 15:09:13.105 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (10/12)#0] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-flink-13
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2023-07-20 15:09:13.105 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (7/12)#0] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-flink-20
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2023-07-20 15:09:13.105 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (5/12)#0] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-flink-22
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2023-07-20 15:09:13.105 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (2/12)#0] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-flink-19
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2023-07-20 15:09:13.105 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (4/12)#0] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-flink-17
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2023-07-20 15:09:13.105 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (12/12)#0] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-flink-23
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2023-07-20 15:09:13.105 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (1/12)#0] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-flink-18
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2023-07-20 15:09:13.105 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (3/12)#0] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-flink-24
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2023-07-20 15:09:13.105 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (9/12)#0] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-flink-21
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2023-07-20 15:09:13.121 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (1/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.7.1
2023-07-20 15:09:13.121 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (1/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 61dbce85d0d41457
2023-07-20 15:09:13.121 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (1/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1689836953121
2023-07-20 15:09:13.124 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (6/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.7.1
2023-07-20 15:09:13.124 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (6/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 61dbce85d0d41457
2023-07-20 15:09:13.124 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (6/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1689836953124
2023-07-20 15:09:13.124 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (7/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.7.1
2023-07-20 15:09:13.125 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (7/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 61dbce85d0d41457
2023-07-20 15:09:13.125 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (7/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1689836953124
2023-07-20 15:09:13.125 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (11/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.7.1
2023-07-20 15:09:13.126 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (11/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 61dbce85d0d41457
2023-07-20 15:09:13.126 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (11/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1689836953125
2023-07-20 15:09:13.126 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (9/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.7.1
2023-07-20 15:09:13.126 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (9/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 61dbce85d0d41457
2023-07-20 15:09:13.126 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (9/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1689836953125
2023-07-20 15:09:13.127 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (4/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.7.1
2023-07-20 15:09:13.127 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (4/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 61dbce85d0d41457
2023-07-20 15:09:13.127 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (4/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1689836953125
2023-07-20 15:09:13.128 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (8/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.7.1
2023-07-20 15:09:13.128 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (8/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 61dbce85d0d41457
2023-07-20 15:09:13.128 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (8/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1689836953127
2023-07-20 15:09:13.128 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (10/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.7.1
2023-07-20 15:09:13.128 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (10/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 61dbce85d0d41457
2023-07-20 15:09:13.128 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (10/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1689836953127
2023-07-20 15:09:13.129 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (5/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.7.1
2023-07-20 15:09:13.129 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (5/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 61dbce85d0d41457
2023-07-20 15:09:13.129 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (5/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1689836953126
2023-07-20 15:09:13.129 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (2/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.7.1
2023-07-20 15:09:13.129 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (2/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 61dbce85d0d41457
2023-07-20 15:09:13.129 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (2/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1689836953126
2023-07-20 15:09:13.129 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (12/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.7.1
2023-07-20 15:09:13.129 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (12/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 61dbce85d0d41457
2023-07-20 15:09:13.129 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (12/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1689836953128
2023-07-20 15:09:13.129 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (3/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.7.1
2023-07-20 15:09:13.130 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (3/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 61dbce85d0d41457
2023-07-20 15:09:13.130 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (3/12)#0] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1689836953128
2023-07-20 15:09:13.133 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (7/12)#0] INFO  org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-flink-20, groupId=flink] Subscribed to partition(s): topic001-0
2023-07-20 15:09:13.142 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (7/12)#0] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-flink-20, groupId=flink] Cluster ID: qYheim3NRmyUgYYzRu7BeQ
2023-07-20 15:09:13.142 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (7/12)#0] INFO  o.a.k.c.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-flink-20, groupId=flink] Discovered group coordinator localhost:9092 (id: 2147483647 rack: null)
2023-07-20 15:09:13.148 [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (7/12)#0] INFO  o.a.k.c.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-flink-20, groupId=flink] Setting offset for partition topic001-0 to the committed offset FetchPosition{offset=4, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 0 rack: null)], epoch=0}}
2023-07-20 15:09:19.026 [TransientBlobCache shutdown hook] INFO  org.apache.flink.runtime.blob.TransientBlobCache - Shutting down BLOB cache
2023-07-20 15:09:19.026 [TaskExecutorLocalStateStoresManager shutdown hook] INFO  o.a.f.r.state.TaskExecutorLocalStateStoresManager - Shutting down TaskExecutorLocalStateStoresManager.
2023-07-20 15:09:19.027 [PermanentBlobCache shutdown hook] INFO  org.apache.flink.runtime.blob.PermanentBlobCache - Shutting down BLOB cache
2023-07-20 15:09:19.031 [FileCache shutdown hook] INFO  org.apache.flink.runtime.filecache.FileCache - removed file cache directory C:\Users\DELL\AppData\Local\Temp\flink-dist-cache-2ccfe79c-d5e7-4935-bc1a-bc2f5e11fcd0
2023-07-20 15:09:19.031 [FileChannelManagerImpl-netty-shuffle shutdown hook] INFO  o.a.flink.runtime.io.disk.FileChannelManagerImpl - FileChannelManager removed spill file directory C:\Users\DELL\AppData\Local\Temp\flink-netty-shuffle-8528dd11-7560-4b13-841f-c628e5b1945d
2023-07-20 15:09:19.032 [BlobServer shutdown hook] INFO  org.apache.flink.runtime.blob.BlobServer - Stopped BLOB server at 0.0.0.0:56778
2023-07-20 15:09:19.032 [FileChannelManagerImpl-io shutdown hook] INFO  o.a.flink.runtime.io.disk.FileChannelManagerImpl - FileChannelManager removed spill file directory C:\Users\DELL\AppData\Local\Temp\flink-io-5a260558-4faf-43eb-a225-926f434f4e71
